[{"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394997500011 ISSN: 1432-7643 eISSN: 1433-7479","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications","Journal Information":"SOFT COMPUTING Volume: 21 Issue: 5 Pages: 1245-1252 DOI: 10.1007/s00500-015-1857-4 Published: MAR 2017","Abstract":"In this paper, we describe the challenges in the realization of a semantic search engine, suited to help law enforcements in the fight against the online drug marketplaces, where new psychoactive substances are sold. This search engine has been developed under the Semantic Illegal Content Hunter (SICH) Project, with the financial support of the Prevention of and Fight Against Crime Programme ISEC 2012 European Commission. The SICH Project-specific objective is to develop new strategic tools and assessment techniques, based on semantic analysis on texts, to support the dynamic mapping and the automatic identification of illegal content over the Net. In particular, a Web search engine can be roughly divided into three main components: (a) the crawler that is in charge of collecting the Web pages to be indexed, (b) the indexer that parses and stores the collected data and (c) the query processor that interacts with the user parsing a query and returning the relevant document; in this paper, we detail each of these components of the SICH search engine, highlighting the differences from a traditional Web search engine.","Authors":"Laura, L (Laura, Luigi) ; Me, G (Me, Gianluigi)","Title":"Searching the Web for illegal content: the anatomy of a semantic search engine"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394421800005 ISSN: 0920-5691 eISSN: 1573-1405","Keywords":"Semantic decomposition; Temporal segmentation; Action recognition; Manipulation action; Semantic event chain KeyWords Plus:CLASSIFICATION; MODELS; VIDEOS; HMMS; TIME","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"INTERNATIONAL JOURNAL OF COMPUTER VISION Volume: 122 Issue: 1 Pages: 84-115 DOI: 10.1007/s11263-016-0956-8 Published: MAR 2017","Abstract":"Understanding continuous human actions is a non-trivial but important problem in computer vision. Although there exists a large corpus of work in the recognition of action sequences, most approaches suffer from problems relating to vast variations in motions, action combinations, and scene contexts. In this paper, we introduce a novel method for semantic segmentation and recognition of long and complex manipulation action tasks, such as \"preparing a breakfast\" or \"making a sandwich\". We represent manipulations with our recently introduced \"Semantic Event Chain\" (SEC) concept, which captures the underlying spatiotemporal structure of an action invariant to motion, velocity, and scene context. Solely based on the spatiotemporal interactions between manipulated objects and hands in the extracted SEC, the framework automatically parses individual manipulation streams performed either sequentially or concurrently. Using event chains, our method further extracts basic primitive elements of each parsed manipulation. Without requiring any prior object knowledge, the proposed framework can also extract object-like scene entities that exhibit the same role in semantically similar manipulations. We conduct extensive experiments on various recent datasets to validate the robustness of the framework.","Authors":"Aksoy, EE (Aksoy, Eren Erdal) ; Orhan, A (Orhan, Adil) ; Worgotter, F (Woergoetter, Florentin)","Title":"Semantic Decomposition and Recognition of Long and Complex Manipulation Action Sequences"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395563900003 ISSN: 1041-4347 eISSN: 1558-2191","Keywords":"Short text understanding; text segmentation; type detection; concept labeling; semantic knowledge","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING Volume: 29 Issue: 3 Pages: 499-512 DOI: 10.1109/TKDE.2016.2571687 Published: MAR 1 2017","Abstract":"Understanding short texts is crucial to many applications, but challenges abound. First, short texts do not always observe the syntax of a written language. As a result, traditional natural language processing tools, ranging from part-of-speech tagging to dependency parsing, cannot be easily applied. Second, short texts usually do not contain sufficient statistical signals to support many state-of-the-art approaches for text mining such as topic modeling. Third, short texts are more ambiguous and noisy, and are generated in an enormous volume, which further increases the difficulty to handle them. We argue that semantic knowledge is required in order to better understand short texts. In this work, we build a prototype system for short text understanding which exploits semantic knowledge provided by a well-known knowledge ase and automatically harvested from a web corpus. Our knowledge-intensive approaches disrupt traditional methods for tasks such as text segmentation, part-of-speech tagging, and concept labeling, in the sense that we focus on semantics in all these tasks. We conduct a comprehensive performance evaluation on real-life data. The results show that semantic knowledge is indispensable for short text understanding, and our knowledge-intensive approaches are both effective and efficient in discovering semantics of short texts.","Authors":"Hua, W (Hua, Wen) ; Wang, ZY (Wang, Zhongyuan) ; Wang, HX (Wang, Haixun) ; Zheng, K (Zheng, Kai) ; Zhou, XF (Zhou, Xiaofang)","Title":"Understand Short Texts by Harvesting and Analyzing Semantic Knowledge"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395869400018 ISSN: 1520-9210 eISSN: 1941-0077","Keywords":"Human activity; human memory; instance-based learning; one-shot learning; prediction; recognition KeyWords Plus:VIDEO","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications","Journal Information":"IEEE TRANSACTIONS ON MULTIMEDIA Volume: 19 Issue: 3 Pages: 646-659 DOI: 10.1109/TMM.2016.2617079 Published: MAR 2017","Abstract":"Human activity recognition is a challenging high-level vision task, for which multiple factors, such as subject, object, and their diverse interactions, have to be considered and modeled. Current learning-based methods are limited in the capability to integrate human-level concepts into an easily extensible computational framework. Inspired by the existing human memory model, we present a context-associative approach to recognize activity with human-object interaction. The proposed system can recognize incoming visual content based on the previous experienced activities. The high-level activity is parsed into consecutive subactivities, and we build a context cluster to model the temporal relations. The semantic attributes of the subactivity are organized by a concept hierarchy. Based on the hierarchy, a series of similarity functions are defined to turn the recognition computing into retrievals over the contextual memory, similar to the auto-associative characteristics of human memory. Partially matching in retrieval and stored memory make the activity prediction possible. The dynamical evolution of the brain memory is mimicked to allow decay and reinforcement of the input information, providing a natural way to maintain data and save computational time. We evaluate our approach on three data sets: CAD-120, MHOI, and OPPORTUNITY. The proposed method demonstrates promising results comparedwith other state of-the-art techniques.","Authors":"Wang, L (Wang, Lei) ; Zhao, X (Zhao, Xu) ; Si, YF (Si, Yunfei) ; Cao, LL (Cao, Liangliang) ; Liu, YC (Liu, Yuncai)","Title":"Context-Associative Hierarchical Memory Model for Human Activity Recognition and Prediction"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394560600004 PubMed ID: 27903440 ISSN: 1053-8119 eISSN: 1095-9572","Keywords":"Auditory entrainment; Speech processing; MEG; Delta band; Prosodic parsing KeyWords Plus:LOW-FREQUENCY OSCILLATIONS; NEURAL OSCILLATIONS; THETA-OSCILLATIONS; LANGUAGE COMPREHENSION; NEURONAL OSCILLATIONS; SPEECH COMPREHENSION; RIGHT-HEMISPHERE; WORKING-MEMORY; PHASE PATTERNS; MOTOR CORTEX","Categories":"Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging Web of Science Categories:Neurosciences; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging","Journal Information":"NEUROIMAGE Volume: 147 Pages: 32-42 DOI: 10.1016/j.neuroimage.2016.11.062 Published: FEB 15 2017","Abstract":"The timing of slow auditory cortical activity aligns to the rhythmic fluctuations in speech. This entrainment is considered to be a marker of the prosodic and syllabic encoding of speech, and has been shown to correlate with intelligibility. Yet, whether and how auditory cortical entrainment is influenced by the activity in other speech relevant areas remains unknown. Using source-localized MEG data, we quantified the dependency of auditory entrainment on the state of oscillatory activity in fronto-parietal regions. We found that delta band entrainment interacted with the oscillatory activity in three distinct networks. First, entrainment in the left anterior superior temporal gyrus (STG) was modulated by beta power in orbitofrontal areas, possibly reflecting predictive top down modulations of auditory encoding. Second, entrainment in the left Heschl's Gyrus and anterior STG was dependent on alpha power in central areas, in line with the importance of motor structures for phonological analysis. And third, entrainment in the right posterior STG modulated theta power in parietal areas, consistent with the engagement of semantic memory. These results illustrate the topographical network interactions of auditory delta entrainment and reveal distinct cross-frequency mechanisms by which entrainment can interact with different cognitive processes underlying speech perception.","Authors":"Keitel, A (Keitel, Anne) ; Ince, RAA (Ince, Robin A. A.) ; Gross, J (Gross, Joachim) ; Kayser, C (Kayser, Christoph)","Title":"Auditory cortical delta-entrainment interacts with oscillatory power in multiple fronto-parietal networks"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393916800001 PubMed ID: 28261133 ISSN: 1664-1078","Keywords":"retrieval interference; working memory capacity; cue-based retrieval; sentence comprehension KeyWords Plus:SHORT-TERM-MEMORY; GENERAL FLUID INTELLIGENCE; LATENT-VARIABLE ANALYSIS; INDIVIDUAL-DIFFERENCES; LANGUAGE COMPREHENSION; EXECUTIVE ATTENTION; PREFRONTAL CORTEX; COGNITIVE CONTROL; TIME-COURSE; READING-COMPREHENSION","Categories":"Psychology Web of Science Categories:Psychology, Multidisciplinary","Journal Information":"FRONTIERS IN PSYCHOLOGY Volume: 8 Article Number: 198 DOI: 10.3389/fpsyg.2017.00198 Published: FEB 15 2017","Abstract":"This study investigated the nature of the underlying working memory system supporting sentence processing through examining individual differences in sensitivity to retrieval interference effects during sentence comprehension. Interference effects occur when readers incorrectly retrieve sentence constituents which are similar to those required during integrative processes. We examined interference arising from a partial match between distracting constituents and syntactic and semantic cues, and related these interference effects to performance on working memory, short-term memory (STM), vocabulary, and executive function tasks. For online sentence comprehension, as measured by self-paced reading, the magnitude of individuals' syntactic interference effects was predicted by general WM capacity and the relation remained significant when partialling out vocabulary, indicating that the effects were not due to verbal knowledge. For offline sentence comprehension, as measured by responses to comprehension questions, both general WM capacity and vocabulary knowledge interacted with semantic interference for comprehension accuracy, suggesting that both general WM capacity and the quality of semantic representations played a role in determining how well interference was resolved offline. For comprehension question reaction times, a measure of semantic STM capacity interacted with semantic but not syntactic interference. However, a measure of phonological capacity (digit span) and a general measure of resistance to response interference (Stroop effect) did not predict individuals' interference resolution abilities in either online or offline sentence comprehension. The results are discussed in relation to the multiple capacities account of working memory (e.g., Martin and Romani, 1994; Martin and He, 2004), and the cue-based retrieval parsing approach (e.g., Lewis et al., 2006; Van Dyke et al., 2014). While neither approach was fully supported, a possible means of reconciling the two approaches and directions for future research are proposed.","Authors":"Tan, YY (Tan, Yingying) ; Martin, RC (Martin, Randi C.) ; Van Dyke, JA (Van Dyke, Julie A.)","Title":"Semanticand Syntactic Interference in Sentence Comprehension: A Comparison of Working Memory Models"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000399116400012 ISSN: 0360-0300 eISSN: 1557-7341","Keywords":"Computer Vision; Natural Language Processing; Robotics; Language and vision; survey; multimedia; robotics; symbol grounding; distributional semantics; computer vision; natural language processing; visual attribute; image captioning; imitation learning; word2vec; word embedding; image embedding; semantic parsing; lexical semantics KeyWords Plus:WEB DATA; DISTRIBUTIONAL SEMANTICS; RECOGNITION; MODELS; IMAGES; COMMUNICATION; ANNOTATION; PERCEPTION; GRAMMAR; NORMS","Categories":"Computer Science Web of Science Categories:Computer Science, Theory & Methods","Journal Information":"ACM COMPUTING SURVEYS Volume: 49 Issue: 4 Article Number: 71 DOI: 10.1145/3009906 Published: FEB 2017","Abstract":"Integrating computer vision and natural language processing is a novel interdisciplinary field that has received a lot of attention recently. In this survey, we provide a comprehensive introduction of the integration of computer vision and natural language processing in multimedia and robotics applications with more than 200 key references. The tasks that we survey include visual attributes, image captioning, video captioning, visual question answering, visual retrieval, human-robot interaction, robotic actions, and robot navigation. We also emphasize strategies to integrate computer vision and natural language processing models as a unified theme of distributional semantics. We make an analog of distributional semantics in computer vision and natural language processing as image embedding and word embedding, respectively. We also present a unified view for the field and propose possible future directions.","Authors":"Wiriyathammabhum, P (Wiriyathammabhum, Peratham) ; Summers-Stay, D (Summers-Stay, Douglas) ; Fermuller, C (Fermuller, Cornelia) ; Aloimonos, Y (Aloimonos, Yiannis)","Title":"Computer Vision and Natural Language Processing: Recent Approaches in Multimedia and Robotics"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394317500007 ISSN: 1432-7643 eISSN: 1433-7479","Keywords":"Distributed representation; Authorship attribution; Author identification; Embeddings; Word embeddings; Stylometry; Machine learning; SVM; Scarce training data KeyWords Plus:N-GRAMS; TEXT; IDENTIFICATION","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications","Journal Information":"SOFT COMPUTING Volume: 21 Issue: 3 Pages: 627-639 Special Issue: SI DOI: 10.1007/s00500-016-2446-x Published: FEB 2017","Abstract":"Distributed word representation in a vector space (word embeddings) is a novel technique that allows to represent words in terms of the elements in the neighborhood. Distributed representations can be extended to larger language structures like phrases, sentences, paragraphs and documents. The capability to encode semantic information of texts and the ability to handle high-dimensional datasets are the reasons why this representation is widely used in various natural language processing tasks such as text summarization, sentiment analysis and syntactic parsing. In this paper, we propose to use the distributed representation at the document level to solve the task of the authorship attribution. The proposed method learns distributed vector representations at the document level and then uses the SVM classifier to perform the automatic authorship attribution. We also propose to use the word n-grams (instead of the words) as the input data type for learning the distributed representation model. We conducted experiments over six datasets used in the state-of-the-art works, and for the majority of the datasets, we obtained comparable or better results. Our best results were obtained using the combination of words and n-grams of words as the input data types. Training data are relatively scarce, which did not affect the distributed representation.","Authors":"Posadas-Duran, JP (Posadas-Duran, Juan-Pablo) ; Gomez-Adorno, H (Gomez-Adorno, Helena) ; Sidorov, G (Sidorov, Grigori) ; Batyrshin, I (Batyrshin, Ildar) ; Pinto, D (Pinto, David) ; Chanona-Hernandez, L (Chanona-Hernandez, Liliana)","Title":"Application of the distributed document representation in the authorship attribution task for small corpora"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393065100001 PubMed ID: 28203214 ISSN: 1664-1078","Keywords":"syntactic ambiguity; prosody; relative clause attachment; Spanish; syntactic parsing KeyWords Plus:SPANISH; ATTACHMENT; ENGLISH; COMPREHENSION; BOUNDARIES; ARGUMENT; SPEAKERS; MODELS; LENGTH; DUTCH","Categories":"Psychology Web of Science Categories:Psychology, Multidisciplinary","Journal Information":"FRONTIERS IN PSYCHOLOGY Volume: 8 Article Number: 96 DOI: 10.3389/fpsyg.2017.00096 Published: FEB 1 2017","Abstract":"During natural speech perception, listeners rely on a wide range of cues to support comprehension, from semantic context to prosodic information. There is a general consensus that prosody plays a role in syntactic parsing, but most studies focusing on ambiguous relative clauses (RC) show that prosodic cues, alone, are insufficient to reverse the preferred interpretation of sentence. These findings suggest that universally preferred structures (e.g., Late Closure principle) matter far more than prosodic cues in such cases. This study explores an alternative hypothesis: that the weak effect of prosody might be due to the influence of various syntactic, lexical-semantic, and acoustic confounding factors, and investigate the consequences of prosodic breaks while controlling these variables. We used Spanish RC sentences in three experimental conditions where the presence and position (following the first or second noun phrase) of prosodic breaks was manipulated. The results showed that the placement of a prosodic break determined sentence interpretation by changing the preferred attachment of the RC. Listeners natural preference for low attachment (in the absence of break) was reinforced when a prosodic break was placed after the first noun. In contrast, a prosodic break placed after the second noun reversed the preferred interpretation of the sentence, toward high attachment. We argue that, in addition to other factors, listeners indeed use prosodic breaks as robust cues to syntactic parsing during speech processing, as these cues may direct listeners toward one interpretation or another.","Authors":"Fromont, LA (Fromont, Lauren A.) ; Soto-Faraco, S (Soto-Faraco, Salvador) ; Biau, E (Biau, Emmanuel)","Title":"Searching High and Low: Prosodic Breaks Disambiguate Relative Clauses"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000397715700009 ISSN: 2255-8942 eISSN: 2255-8950","Keywords":"programming languages; compilers; extensible parsing; semantic analysis; reflective grammars; survey","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"BALTIC JOURNAL OF MODERN COMPUTING Volume: 5 Issue: 1 Pages: 136-145 DOI: 10.22364/bjmc.2017.5.1.09 Published: 2017","Abstract":"In recent years, a new type of compilers and programming languages has emerged, called extensible compilers and programming languages. These new tools are created in hope to extend lifetime and usability of programming languages by allowing users to define new language constructs with their own syntax and semantics. In this paper we focus on a subset of extensible programming languages, called reflectively extensible programming languages that allow definition of syntax and semantics extensions to be mixed with regular code. To facilitate the creation of such compilers and languages, new parsing and semantic analysis algorithms are required. This paper analyses available extensible parsers, semantic analysers, compilers and highlights further possible research directions in this field. We find that existing parsing, semantic analysis methods, compilers and compiler generators are insufficient for implementation of reflectively extensible programming languages and that creation of new parsing and semantic analysis methods with specific qualities is required to facilitate such implementations.","Authors":"Saikunas, A (Saikunas, Audrius)","Title":"Critical Analysis of Extensible Parsing Tools and Techniques"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397302900040 ISSN: 1875-6891 eISSN: 1875-6883","Keywords":"Semantic Analysis; Technology Intelligence; Computational Intelligence; Topic Model; Subject-Action Object KeyWords Plus:SENSITIZED SOLAR-CELLS; PATENT ANALYSIS; TECHNOLOGY; KNOWLEDGE; SCIENCE; INTELLIGENCE; INNOVATION; RETRIEVAL","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications","Journal Information":"INTERNATIONAL JOURNAL OF COMPUTATIONAL INTELLIGENCE SYSTEMS Volume: 10 Issue: 1 Pages: 593-604 Published: JAN 2017","Abstract":"A Subject-Action-Object (SAO) is a triple structure which can be used to both describe topics in detail and explore the relationship between them. SAO analysis has become popular in bibliometrics, however there are two challenges in the identification of SAO structures: low relevance of SAOs to domain topics; and synonyms in SAO. These problems make the identification of SAO greatly dependent upon domain experts, limiting the further usage of SAO and influencing further the mining of SAO characteristics. This paper proposes a parse tree-based SAO identification method that includes (1) a model to identify the core components (candidate terms for subject & object) of SAO structures, where term clumping processes and co-word analysis are involved; (2) a parse tree-based hierarchical SAO extraction model to divide entire SAO structures into a collection of simpler sub-tasks for separate subject, action, and object identification; and (3) an SAO weighting model to rank SAO structures for result selection. The proposed method is applied to publications in the Journal of Scientometrics (SCIM), to identify and rank significant SAO structures. Our experiment results demonstrate the validity and feasibility of the proposed method.","Authors":"Yang, C (Yang, Chao) ; Zhu, DH (Zhu, Donghua) ; Wang, XF (Wang, Xuefeng)","Title":"SAO Semantic Information Identification for Text Mining"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393978600002 ISSN: 0943-7444","Keywords":"semantic structure analysis; Chinese term association; morphemes; similarity; relatedness KeyWords Plus:KNOWLEDGE ORGANIZATION","Categories":"Information Science & Library Science Web of Science Categories:Information Science & Library Science","Journal Information":"KNOWLEDGE ORGANIZATION Volume: 44 Issue: 1 Pages: 13-23 Published: 2017","Abstract":"The study aims to solve how to construct the semantic relations of specific domain terms by applying linguistic rules. The semantic structure analysis at the morpheme level was used for semantic measure, and a morpheme-based term association model was proposed by improving and combining the literal-based similarity algorithm and co-occurrence relatedness methods. This study provides a novel insight into the method of semantic analysis and calculation by morpheme parsing, and the proposed solution is feasible for the automatic association of compound terms. The results show that this approach could be used to construct appropriate term association and form a reasonable structural knowledge graph. However, due to linguistic differences, the viability and effectiveness of the use of our method in non-Chinese linguistic environments should be verified.","Authors":"Li, N (Li, Nan) ; Sun, JQ (Sun, Jiqing)","Title":"Improving Chinese Term Association from the Linguistic Perspective"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396826100006 PubMed ID: 27094855 ISSN: 1747-0218 eISSN: 1747-0226","Keywords":"Auditory necklaces; Complexity; Rhythmic organization; Sentence processing; Stroop effect KeyWords Plus:AUDITORY TEMPORAL PATTERNS; MODEL SELECTION; BEHAVIORAL ECOLOGY; PERCEPTUAL ORGANIZATION; INFORMATION CRITERION; MULTIMODEL INFERENCE","Categories":"Psychology; Physiology Web of Science Categories:Psychology, Biological; Physiology; Psychology; Psychology, Experimental","Journal Information":"QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY Volume: 70 Issue: 7 Pages: 1151-1165 DOI: 10.1080/17470218.2016.1173078 Published: 2017","Abstract":"This paper revisits the conclusion of our previous work regarding the dominance of meaning in the competition between rhythmic parsing and linguistic parsing. We played five-note rhythm patterns in which each sound is a spoken word of a fiveword sentence. We asked listeners to indicate the starting point of the rhythm while disregarding which word would normally be heard as the first word of the sentence. In four studies, we varied task demands by introducing differences in rhythm complexity, rhythm ambiguity, rhythm pairing, and semantic coherence. We found that task complexity affects the dominance of meaning. We therefore amend our previous conclusion: when processing resources are taxed, listeners do not always primarily attend to meaning; instead, they primarily attend to the aspect of the pattern (rhythm or meaning) that is more salient.","Authors":"Getz, LM (Getz, Laura M.) ; Wohltjen, S (Wohltjen, Sophie) ; Kubovy, M (Kubovy, Michael)","Title":"Competition between rhythmic and linguistic meaning revisited: the effect of task demands"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394149300003 ISSN: 1088-467X eISSN: 1571-4128","Keywords":"Ontology learning; semantic parsing; grammar induction; context-free grammar","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"INTELLIGENT DATA ANALYSIS Volume: 21 Issue: 1 Pages: 19-38 DOI: 10.3233/IDA-150452 Published: 2017","Abstract":"Semantic parsing methods are used for capturing and representing semantic meaning of text. Meaning representation capturing all the concepts in the text may not always be available or may not be sufficiently complete. Ontologies provide a structured and reasoning-capable way to model the content of a collection of texts. In this work, we present a novel approach to joint learning of ontology and semantic parser from text. The method is based on semi-automatic induction of a contextfree grammar from semantically annotated text. The grammar parses the text into semantic trees. Both, the grammar and the semantic trees are used to learn the ontology on several levels -classes, instances, taxonomic and non-taxonomic relations. The approach was evaluated on the first sentences of Wikipedia pages describing people.","Authors":"Starc, J (Starc, Janez) ; Mladenic, D (Mladenic, Dunja)","Title":"Joint learning of ontology and semantic parser from text"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000392780200006 ISSN: 0924-2716 eISSN: 1872-8235","Keywords":"TLS point cloud; Facade parsing; Layer decomposition; Semantic segmentation; 3D modeling KeyWords Plus:BUILDING MODELS; RECONSTRUCTION; SEGMENTATION; SHAPE; EXTRACTION; IMAGES; RANSAC","Categories":"Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology Web of Science Categories:Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology","Journal Information":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING Volume: 123 Pages: 75-93 DOI: 10.1016/j.isprsjprs.2016.11.008 Published: JAN 2017","Abstract":"The effective and automated parsing of building facades from terrestrial laser scanning (TLS) point clouds of urban environments is an important research topic in the GIS and remote sensing fields. It is also challenging because of the complexity and great variety of the available 3D building facade layouts as well as the noise and data missing of the input TLS point clouds. In this paper, we introduce a novel methodology for the accurate and computationally efficient parsing of urban building facades from TLS point clouds. The main novelty of the proposed methodology is that it is a systematic and hierarchical approach that considers, in an adaptive way, the semantic and underlying structures of the urban facades for segmentation and subsequent accurate modeling. Firstly, the available input point cloud is decomposed into depth planes based on a data-driven method; such layer decomposition enables similarity detection in each depth plane layer. Secondly, the labeling of the facade elements is performed using the SVM classifier in combination with our proposed BieS-ScSPM algorithm. The labeling outcome is then augmented with weak architectural knowledge. Thirdly, least-squares fitted normalized gray accumulative curves are applied to detect regular structures, and a binarization dilation extraction algorithm is used to partition facade elements. A dynamic line-by-line division is further applied to extract the boundaries of the elements. The 3D geometrical facade models are then reconstructed by optimizing facade elements across depth plane layers. We have evaluated the performance of the proposed method using several TLS facade datasets. Qualitative and quantitative performance comparisons with several other state-ofthe-art methods dealing with the same facade parsing problem have demonstrated its superiority in performance and its effectiveness in improving segmentation accuracy. (C) 2016 Published by Elsevier B.V. on behalf of International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS).","Authors":"Li, ZQ (Li, Zhuqiang) ; Zhang, LQ (Zhang, Liqiang) ; Mathiopoulos, PT (Mathiopoulos, P. Takis) ; Liu, FY (Liu, Fangyu) ; Zhang, L (Zhang, Liang) ; Li, SP (Li, Shuaipeng) ; Liu, H (Liu, Hao)","Title":"A hierarchical methodology for urban facade parsing from TLS point clouds"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000392116800007 PubMed ID: 27504678 ISSN: 0278-7393 eISSN: 1939-1285","Keywords":"autism spectrum disorder; reading; eye movements; lexical identification; syntactic ambiguity resolution KeyWords Plus:HIGH-FUNCTIONING ADULTS; VISUAL WORD RECOGNITION; AMBIGUITY RESOLUTION; CENTRAL COHERENCE; BRIDGING INFERENCES; HYPERLEXIC READERS; TEXT COMPREHENSION; LEXICAL AMBIGUITY; BAYES FACTORS; CHILDREN","Categories":"Psychology Web of Science Categories:Psychology; Psychology, Experimental","Journal Information":"JOURNAL OF EXPERIMENTAL PSYCHOLOGY-LEARNING MEMORY AND COGNITION Volume: 43 Issue: 1 Pages: 109-127 DOI: 10.1037/xlm0000289 Published: JAN 2017","Abstract":"In 2 experiments, eye tracking methodology was used to assess on-line lexical, syntactic and semantic processing in autism spectrum disorder (ASD). In Experiment 1, lexical identification was examined by manipulating the frequency of target words. Both typically developed (TD) and ASD readers showed normal frequency effects, suggesting that the processes TD and ASD readers engage in to identify words are comparable. In Experiment 2, syntactic parsing and semantic interpretation requiring the on-line use of world knowledge were examined, by having participants read garden path sentences containing an ambiguous prepositional phrase. Both groups showed normal garden path effects when reading low-attached sentences and the time course of reading disruption was comparable between groups. This suggests that not only do ASD readers hold similar syntactic preferences to TD readers, but also that they use world knowledge on-line during reading. Together, these experiments demonstrate that the initial construction of sentence interpretation appears to be intact in ASD. However, the finding that ASD readers skip target words less often in Experiment 2, and take longer to read sentences during second pass for both experiments, suggests that they adopt a more cautious reading strategy and take longer to evaluate their sentence interpretation prior to making a manual response.","Authors":"Howard, PL (Howard, Philippa L.) ; Liversedge, SP (Liversedge, Simon P.) ; Benson, V (Benson, Valerie)","Title":"Benchmark Eye Movement Effects During Natural Reading in Autism Spectrum Disorder"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000392274300006 ISSN: 1351-3249 eISSN: 1469-8110","Categories":"Computer Science; Linguistics Web of Science Categories:Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics","Journal Information":"NATURAL LANGUAGE ENGINEERING Volume: 23 Issue: 1 Pages: 131-153 DOI: 10.1017/S1351324915000297 Published: JAN 2017","Abstract":"Logic Forms (LF) are simple, first-order logic knowledge representations of natural language sentences. Each noun, verb, adjective, adverb, pronoun, preposition and conjunction generates a predicate. LF systems usually identify the syntactic function by means of syntactic rules but this approach is difficult to apply to languages with a high syntax flexibility and ambiguity, for example, Spanish. In this study, we present a mixed method for the derivation of the LF of sentences in Spanish that allows the combination of hard-coded rules and a classifier inspired on semantic role labeling. Thus, the main novelty of our proposal is the way the classifier is applied to generate the predicates of the verbs, while rules are used to translate the rest of the predicates, which are more straightforward and unambiguous than the verbal ones. The proposed mixed system uses a supervised classifier to integrate syntactic and semantic information in order to help overcome the inherent ambiguity of Spanish syntax. This task is accomplished in a similar way to the semantic role labeling task. We use properties extracted from the AnCora-ES corpus in order to train a classifier. A rule-based system is used in order to obtain the LF from the rest of the phrase. The rules are obtained by exploring the syntactic tree of the phrase and encoding the syntactic production rules. The LF algorithm has been evaluated by using shallow parsing with some straightforward Spanish phrases. The verb argument labeling task achieves 84% precision and the proposed mixed LFi method surpasses 11% a system based only on rules.","Authors":"Martinez-Santiago, F (Martinez-Santiago, F.) ; Diaz-Galiano, MC (Diaz-Galiano, M. C.) ; Garcia-Cumbreras, MA (Garcia-Cumbreras, M. A.) ; Montejo-Raez, A (Montejo-Raez, A.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Diaz-Galiano, Manuel-Carlos  http://orcid.org/0000-0001-9298-1376","Title":"A method based on rules and machine learning for logic form identification in Spanish"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000392533000004 ISSN: 1432-7643 eISSN: 1433-7479","Keywords":"Textual entailment recognition; Negation and antonyms; Near synonym recognition; Named-entity recognition; Dependency parsing; Trained heuristic functions; Support-vector machines; Linearly weighted models; Decision trees KeyWords Plus:FRAME SEMANTICS; SEGMENTATION","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications","Journal Information":"SOFT COMPUTING Volume: 21 Issue: 2 Pages: 311-330 Special Issue: SI DOI: 10.1007/s00500-015-1629-1 Published: JAN 2017","Abstract":"We computed linguistic information at the lexical, syntactic, and semantic levels for Recognizing Inference in Text (RITE) tasks for both traditional and simplified Chinese in NTCIR-9 and NTCIR-10. Techniques for syntactic parsing, named-entity recognition, and near synonym recognition were employed, and features like counts of common words, statement lengths, negation words, and antonyms were considered to judge the entailment relationships of two statements, while we explored both heuristics-based functions and machine-learning approaches. The reported systems showed their robustness by simultaneously achieving second positions in the binary-classification subtasks for both simplified and traditional Chinese in NTCIR-10 RITE-2. We conducted more experiments with the test data of NTCIR-9 RITE, with good results. We also extended our work to search for better configurations of our classifiers and investigated contributions of individual features. This extended work showed interesting results and should encourage further discussions.","Authors":"Huang, WJ (Huang, Wei-Jie) ; Liu, CL (Liu, Chao-Lin)","Title":"Exploring lexical, syntactic, and semantic features for Chinese textual entailment in NTCIR RITE evaluation tasks"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000390421300011 ISSN: 0162-8828 eISSN: 1939-3539","Keywords":"Human parsing; fully convolutional network; context modeling; semantic labeling","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic","Journal Information":"IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE Volume: 39 Issue: 1 Pages: 115-127 DOI: 10.1109/TPAMI.2016.2537339 Published: JAN 2017","Abstract":"In this work, we address the human parsing task with a novel Contextualized Convolutional Neural Network (Co-CNN) architecture, which well integrates the cross-layer context, global image-level context, semantic edge context, within-super-pixel context and cross-super-pixel neighborhood context into a unified network. Given an input human image, Co-CNN produces the pixel-wise categorization in an end-to-end way. First, the cross-layer context is captured by our basic local-to-global-to-local structure, which hierarchically combines the global semantic information and the local fine details across different convolutional layers. Second, the global image-level label prediction is used as an auxiliary objective in the intermediate layer of the Co-CNN, and its outputs are further used for guiding the feature learning in subsequent convolutional layers to leverage the global image-level context. Third, semantic edge context is further incorporated into Co-CNN, where the high-level semantic boundaries are leveraged to guide pixel-wise labeling. Finally, to further utilize the local super-pixel contexts, the within-super-pixel smoothing and cross-super-pixel neighbourhood voting are formulated as natural sub-components of the Co-CNN to achieve the local label consistency in both training and testing process. Comprehensive evaluations on two public datasets well demonstrate the significant superiority of our Co-CNN over other state-of-the-arts for human parsing. In particular, the F-1 score on the large dataset [1] reaches 81: 72 percent by Co-CNN, significantly higher than 62: 81 percent and 64: 38 percent by the state-of-the-art algorithms, M-CNN [2] and ATR [1], respectively. By utilizing our newly collected large dataset for training, our Co-CNN can achieve 85: 36 percent in F-1 score.","Authors":"Liang, XD (Liang, Xiaodan) ; Xu, CY (Xu, Chunyan) ; Shen, XH (Shen, Xiaohui) ; Yang, JC (Yang, Jianchao) ; Tang, JH (Tang, Jinhui) ; Lin, L (Lin, Liang) ; Yan, SC (Yan, Shuicheng)","Title":"Human Parsing with Contextualized Convolutional Neural Network"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000388061900007 ISSN: 0167-6423 eISSN: 1872-7964","Keywords":"Parsing; Error reporting; Parsing expression grammars; Packrat parsing; Parser combinators","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"SCIENCE OF COMPUTER PROGRAMMING Volume: 132 Pages: 129-140 Part: 1 DOI: 10.1016/j.scico.2016.08.004 Published: DEC 15 2016","Abstract":"Parsing Expression Grammars (PEGs) describe top-down parsers. Unfortunately, the error reporting techniques used in conventional top-down parsers do not directly apply to parsers based on Parsing Expression Grammars (PEGs), so they have to be somehow simulated. While the PEG formalism has no account of semantic actions, actual PEG implementations add them, and we show how to simulate an error-reporting heuristic through these semantic actions. We also propose a complementary error reporting strategy that may lead to better error messages: labeled failures. This approach is inspired by exception handling of programming languages, and lets a PEG define different kinds of failure, with each ordered choice operator specifying which kinds it catches. Labeled failures give a way to annotate grammars for better error reporting, to express some of the error reporting strategies used by deterministic parser combinators, and to encode predictive top-down parsing in a PEG. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Maidl, AM (Maidl, Andre Murbach) ; Mascarenhas, F (Mascarenhas, Fabio) ; Medeiros, S (Medeiros, Sergio) ; Ierusalimschy, R (Ierusalimschy, Roberto)","Title":"Error reporting in Parsing Expression Grammars"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393184000002 ISSN: 1556-4681 eISSN: 1556-472X","Keywords":"World knowledge; heterogeneous information network; document clustering; knowledge base; knowledge graph KeyWords Plus:NETWORKS; MODELS","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA Volume: 11 Issue: 2 Article Number: 13 DOI: 10.1145/2953881 Published: DEC 2016","Abstract":"One of the key obstacles in making learning protocols realistic in applications is the need to supervise them, a costly process that often requires hiring domain experts. We consider the framework to use the world knowledge as indirect supervision. World knowledge is general-purpose knowledge, which is not designed for any specific domain. Then, the key challenges are how to adapt the world knowledge to domains and how to represent it for learning. In this article, we provide an example of using world knowledge for domain-dependent document clustering. We provide three ways to specify the world knowledge to domains by resolving the ambiguity of the entities and their types, and represent the data with world knowledge as a heterogeneous information network. Then, we propose a clustering algorithm that can cluster multiple types and incorporate the sub-type information as constraints. In the experiments, we use two existing knowledge bases as our sources of world knowledge. One is Freebase, which is collaboratively collected knowledge about entities and their organizations. The other is YAGO2, a knowledge base automatically extracted from Wikipedia and maps knowledge to the linguistic knowledge base, WordNet. Experimental results on two text benchmark datasets (20newsgroups and RCV1) show that incorporating world knowledge as indirect supervision can significantly outperform the state-of-the-art clustering algorithms as well as clustering algorithms enhanced with world knowledge features. A preliminary version of this work appeared in the proceedings of KDD 2015 [Wang et al. 2015a]. This journal version has made several major improvements. First, we have proposed a new and general learning framework for machine learning with world knowledge as indirect supervision, where document clustering is a special case in the original paper. Second, in order to make our unsupervised semantic parsing method more understandable, we add several real cases from the original sentences to the resulting logic forms with all the necessary information. Third, we add details of the three semantic filtering methods and conduct deep analysis of the three semantic filters, by using case studies to show why the conceptualization-based semantic filter can produce more accurate indirect supervision. Finally, in addition to the experiment on 20 newsgroup data and Freebase, we have extended the experiments on clustering results by using all the combinations of text (20 newsgroup, MCAT, CCAT, ECAT) and world knowledge sources (Freebase, YAGO2).","Authors":"Wang, CG (Wang, Chenguang) ; Song, YQ (Song, Yangqiu) ; Roth, D (Roth, Dan) ; Zhang, M (Zhang, Ming) ; Han, JW (Han, Jiawei)","Title":"World Knowledge as Indirect Supervision for Document Clustering"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000391438500006 ISSN: 2375-4699 eISSN: 2375-4702","Keywords":"Semantic parsing; statistical machine translation; enriched synchronous context-free grammars; word alignment","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"ACM TRANSACTIONS ON ASIAN AND LOW-RESOURCE LANGUAGE INFORMATION PROCESSING Volume: 16 Issue: 1 Article Number: 6 DOI: 10.1145/2963099 Published: DEC 2016","Abstract":"Semantic parsing maps a sentence in natural language into a structured meaning representation. Previous studies show that semantic parsing with synchronous context-free grammars (SCFGs) achieves favorable performance over most other alternatives. Motivated by the observation that the performance of semantic parsing with SCFGs is closely tied to the translation rules, this article explores to extend translation rules with high quality and increased coverage in three ways. First, we examine the difference between word alignments for semantic parsing and statistical machine translation (SMT) to better adapt word alignment in SMT to semantic parsing. Second, we introduce both structure and syntax informed nonterminals, better guiding the parsing in favor of well-formed structure, instead of using a uninformed nonterminal in SCFGs. Third, we address the unknown word translation issue via synthetic translation rules. Last but not least, we use a filtering approach to improve performance via predicting answer type. Evaluation on the standard GeoQuery benchmark dataset shows that our approach greatly outperforms the state of the art across various languages, including English, Chinese, Thai, German, and Greek.","Authors":"Li, JH (Li, Junhui) ; Zhu, MH (Zhu, Muhua) ; Lu, W (Lu, Wei) ; Zhou, GD (Zhou, Guodong)","Title":"Improving Semantic Parsing with Enriched Synchronous Context-Free Grammars in Statistical Machine Translation"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000390719600011 ISSN: 0924-2716 eISSN: 1872-8235","Keywords":"Building/road extraction; Satellite images; Image segmentation; Feature analysis; Random Forest; Unsupervised classification KeyWords Plus:REMOTE-SENSING IMAGES; MAN-MADE OBJECTS; AUTOMATED DETECTION; NETWORK EXTRACTION; AERIAL IMAGERY; MEAN SHIFT; GRAPH CUTS; URBAN-AREA; ENVIRONMENTS; RECOGNITION","Categories":"Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology Web of Science Categories:Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology","Journal Information":"ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING Volume: 122 Pages: 145-166 DOI: 10.1016/j.isprsjprs.2016.10.010 Published: DEC 2016","Abstract":"We present in this article a new method on unsupervised semantic parsing and structure recognition in peri-urban areas using satellite images. The automatic \"building\" and \"road\" detection is based on regions extracted by an unsupervised segmentation method. We propose a novel segmentation algorithm based on a Marlcov random field model and we give an extensive data analysis for determining relevant features for the classification problem. The novelty of the segmentation algorithm lies on the class -driven vector data quantization and clustering and the estimation of the likelihoods given the resulting clusters. We have evaluated the reachability of a good classification rate using the Random Forest method. We found that, with a limited number of features, among them some new defined in this article, we can obtain good classification performance. Our main contribution lies again on the data analysis and the estimation of likelihoods. Finally, we propose a new method for completing the road network exploiting its connectivity, and the local and global properties of the road network. (C) 2016 International Society for Photogrammetry and Remote Sensing, Inc. (ISPRS). Published by Elsevier B.V. All rights reserved.","Authors":"Grinias, I (Grinias, Ilias) ; Panagiotakis, C (Panagiotakis, Costas) ; Tziritas, G (Tziritas, Georgios)","Title":"MRF-based segmentation and unsupervised classification for building and road detection in peri-urban areas of high -resolution satellite images"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395016700001 ISSN: 1070-9908 eISSN: 1558-2361","Keywords":"Nonnegative matrix factorization; semantic segmentation; weakly supervised image parsing KeyWords Plus:FACTORIZATION; SEGMENTATION","Categories":"Engineering Web of Science Categories:Engineering, Electrical & Electronic","Journal Information":"IEEE SIGNAL PROCESSING LETTERS Volume: 23 Issue: 11 Pages: 1682-1686 DOI: 10.1109/LSP.2016.2614704 Published: NOV 2016","Abstract":"Image parsing, which is the task of assigning each pixel with a semantic label, is a challenging problem when only supervised under image-level tags. In this letter, we propose a Non-negative Matrix Cofactorization method to perform image parsing with noisy tags, i.e., some tags may be incorrect or missing. Given a collection of noisily tagged images, we first oversegment them into superpixels. Then, the superpixels' label matrix, which is aimed to estimate, and the feature matrix are simultaneously decomposed into nonnegative factormatrices with a graph Laplacian constraint and an orthogonal constraint. This cofactorization is able to jointly learn a discriminative dictionary and a linear classifier. The proposed approach therefore is robust to noise. Experimental results on two real-world image datasets MSRC-21 and LabelMe demonstrate the encouraging performance of our approach in comparison with the state of the arts.","Authors":"Zhang, GD (Zhang, Guodong) ; Gong, XJ (Gong, Xiaojin)","Title":"Nonnegative Matrix Cofactorization for Weakly Supervised Image Parsing"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000389566100001 ISSN: 0024-3841 eISSN: 1872-6135","Keywords":"Sentential parsing; Inflection; Vowel deletion; Vowel addition; Head marking; Dependent marking; Grammatical relations","Categories":"Linguistics Web of Science Categories:Linguistics; Language & Linguistics","Journal Information":"LINGUA Volume: 183 Pages: 1-33 DOI: 10.1016/j.lingua.2016.05.004 Published: NOV 2016","Abstract":"The present study demonstrates the existence in Wandala (Central Chadic) of two inflectional markers which, although they change the form of the word, are notword-formation means but rather sentence-formation means. While neither of the forms indicates any specific semantic relation, they both enable the listener to parse the sentence into units that can undergo further analysis and allow for inferences about a large number of semantic relations within the clause and within the sentence. The types of inflectional marking described in this study are unrelated to the dichotomy of head marking and dependent marking. Although this study is based on data from a single language, it has implications for the typology of coding means and for theories of clausal structures. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Frajzyngier, Z (Frajzyngier, Zygmunt)","Title":"Inflectional markers of sentential parsing"}, {"Document Information":"Document Type:Article; Proceedings Paper Language:English Accession Number: WOS:000388446200014 ISSN: 0730-0301 eISSN: 1557-7368","Keywords":"Assembly instructions; furniture modeling; supervised learning; personalized fabrication KeyWords Plus:SHAPES; DIAGRAMS","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"ACM TRANSACTIONS ON GRAPHICS Volume: 35 Issue: 6 Article Number: 172 DOI: 10.1145/2980179.2982416 Published: NOV 2016","Abstract":"We present a technique for parsing widely used furniture assembly instructions, and reconstructing the 3D models of furniture components and their dynamic assembly process. Our technique takes as input a multi-step assembly instruction in a vector graphic format and starts to group the vector graphic primitives into semantic elements representing individual furniture parts, mechanical connectors (e.g., screws, bolts and hinges), arrows, visual highlights, and numbers. To reconstruct the dynamic assembly process depicted over multiple steps, our system identifies previously built 3D furniture components when parsing a new step, and uses them to address the challenge of occlusions while generating new 3D components incrementally. With a wide range of examples covering a variety of furniture types, we demonstrate the use of our system to animate the 3D furniture assembly process and, beyond that, the semantic-aware furniture editing as well as the fabrication of personalized furnitures.","Authors":"Shao, TJ (Shao, Tianjia) ; Li, DP (Li, Dongping) ; Rong, YL (Rong, Yuliang) ; Zheng, CX (Zheng, Changxi) ; Zhou, K (Zhou, Kun)","Title":"Dynamic Furniture Modeling Through Assembly Instructions"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000387335600008 ISSN: 1000-9000 eISSN: 1860-4749","Keywords":"artificial intelligence; language parsing and understanding; machine learning","Categories":"Computer Science Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Software Engineering","Journal Information":"JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY Volume: 31 Issue: 6 Pages: 1151-1160 DOI: 10.1007/s11390-016-1689-4 Published: NOV 2016","Abstract":"In this paper we address the answer retrieval problem in community-based question answering. To fully capture the interactions between question-answer pairs, we propose an original tensor neural network to model the relevance between them. The question and candidate answers are separately embedded into different latent semantic spaces, and a 3-way tensor is then utilized to model the interactions between latent semantics. To initialize the network layers properly, we propose a novel algorithm called denoising tensor autoencoder (DTAE), and then implement a layerwise pretraining strategy using denoising autoencoders (DAE) on word embedding layers and DTAE on the tensor layer. The experimental results show that our tensor neural network outperforms various baselines with other competitive neural network methods, and our pretraining DTAE strategy improves the system's performance and robustness.","Authors":"Bao, XQ (Bao, Xin-Qi) ; Wu, YF (Wu, Yun-Fang)","Title":"A Tensor Neural Network with Layerwise Pretraining: Towards Effective Answer Retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000386436900005 ISSN: 1351-3249 eISSN: 1469-8110","Categories":"Computer Science; Linguistics Web of Science Categories:Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics","Journal Information":"NATURAL LANGUAGE ENGINEERING Volume: 22 Issue: 6 Pages: 939-974 DOI: 10.1017/S1351324915000285 Published: NOV 2016","Abstract":"Deep-syntactic' dependency structures that capture the argumentative, attributive and coordinative relations between full words of a sentence have a great potential for a number of NLP-applications. The abstraction degree of these structures is in between the output of a syntactic dependency parser (connected trees defined over all words of a sentence and language-specific grammatical functions) and the output of a semantic parser (forests of trees defined over individual lexemes or phrasal chunks and abstract semantic role labels which capture the frame structures of predicative elements and drop all attributive and coordinative dependencies). We propose a parser that provides deep-syntactic structures. The parser has been tested on Spanish, English and Chinese.","Authors":"Ballesteros, M (Ballesteros, Miguel) ; Bohnet, B (Bohnet, Bernd) ; Mille, S (Mille, Simon) ; Wanner, L (Wanner, Leo)","Title":"Data-driven deep-syntactic dependency parsing"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000384872000011 ISSN: 0926-5805 eISSN: 1872-7891","Keywords":"Construction site; Computer vision; Scene parsing; Object recognition; Label transfer KeyWords Plus:CONCRETE PIPE IMAGES; TRACKING METHODS; RECOGNITION; VISION; RESOURCES; PROGRESS; MODEL; CLASSIFICATION; SEGMENTATION; RETRIEVAL","Categories":"Construction & Building Technology; Engineering Web of Science Categories:Construction & Building Technology; Engineering, Civil","Journal Information":"AUTOMATION IN CONSTRUCTION Volume: 71 Pages: 271-282 Part: 2 DOI: 10.1016/j.autcon.2016.08.018 Published: NOV 2016","Abstract":"Although efforts have been made for automated monitoring of construction sites, comprehensive understanding of a whole image remains to be a difficult task. Conventional vision-based monitoring methods have shortcomings in obtaining semantic information regarding an entire image because these methods are not scalable to the number of recognizable objects and training data. Most methods use a parametric model to recognize objects, involving cumbersome parameter tuning. This study presents the data-driven scene parsing method to recognize various objects in a construction site image. For identifying object information of a query image, the monitoring system retrieves the most relevant images to a query image using nearest neighbors and scale invariant feature transform flow matching and transfers relevant image labels to a query image. This study demonstrated the reasonable system performance in construction site images, recording 81.48% of average pixel-wise recognition rate with a small amount of similar images. The scene parsing method would enrich the raw information of a construction site image, thereby facilitating information use for various management applications. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Kim, H (Kim, Hongjo) ; Kim, K (Kim, Kinam) ; Kim, H (Kim, Hyoungkwan)","Title":"Data-driven scene parsing method for recognizing construction site objects in the whole image"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000386171700001 ISSN: 1756-0381","Keywords":"Diagnostic Criteria; Ontology; ICD-11; QDM; SWRL KeyWords Plus:ELIGIBILITY CRITERIA; GUIDELINES; REPRESENTATION; CHALLENGES; ONTOLOGY; SUPPORT","Categories":"Mathematical & Computational Biology Web of Science Categories:Mathematical & Computational Biology","Journal Information":"BIODATA MINING Volume: 9 Article Number: 33 DOI: 10.1186/s13040-016-0113-5 Published: OCT 21 2016","Abstract":"Background: With recent advances in computerized patient records system, there is an urgent need for producing computable and standards-based clinical diagnostic criteria. Notably, constructing rule-based clinical diagnosis criteria has become one of the goals in the International Classification of Diseases (ICD)-11 revision. However, few studies have been done in building a unified architecture to support the need for diagnostic criteria computerization. In this study, we present a modular architecture for enabling the creation of rule-based clinical diagnostic criteria leveraging Semantic Web technologies. Methods and results: The architecture consists of two modules: an authoring module that utilizes a standards-based information model and a translation module that leverages Semantic Web Rule Language (SWRL). In a prototype implementation, we created a diagnostic criteria upper ontology (DCUO) that integrates ICD-11 content model with the Quality Data Model (QDM). Using the DCUO, we developed a transformation tool that converts QDM-based diagnostic criteria into Semantic Web Rule Language (SWRL) representation. We evaluated the domain coverage of the upper ontology model using randomly selected diagnostic criteria from broad domains (n = 20). We also tested the transformation algorithms using 6 QDM templates for ontology population and 15 QDM-based criteria data for rule generation. As the results, the first draft of DCUO contains 14 root classes, 21 subclasses, 6 object properties and 1 data property. Investigation Findings, and Signs and Symptoms are the two most commonly used element types. All 6 HQMF templates are successfully parsed and populated into their corresponding domain specific ontologies and 14 rules (93.3 %) passed the rule validation. Conclusion: Our efforts in developing and prototyping a modular architecture provide useful insight into how to build a scalable solution to support diagnostic criteria representation and computerization.","Authors":"Hong, N (Hong, Na) ; Pathak, J (Pathak, Jyotishman) ; Chute, CG (Chute, Christopher G.) ; Jiang, GQ (Jiang, Guoqian)","Title":"Developing a modular architecture for creation of rule-based clinical diagnostic criteria"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000384398600034 ISSN: 1047-3203 eISSN: 1095-9076","Keywords":"Weakly supervised image parsing; Discriminative semantics KeyWords Plus:RECOGNITION; SEGMENTATION; CONTEXT","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION Volume: 40 Pages: 808-815 Part: B DOI: 10.1016/j.jvcir.2016.08.005 Published: OCT 2016","Abstract":"In this paper, we concentrate on a challenging problem, i.e., weakly supervised image parsing, whereby only weak image-level labels are available in the dataset. In tradition, an affinity graph of superpixels is constructed to strengthen weak information by leveraging the neighbors from the perspective of image level labels. Existing work constructs the affinity graph by purely utilizing the visual relevance, where the context homogenization is a common phenomenon and hinders the performance of label prediction. To overcome the context homogenization problem, we not only consider the visual and semantic relevance but also the semantic distinction between every target superpixel and its neighbor superpixels in the affinity graph construction. We propose a novel way in constructing the inter-image contextual graph, and design a label propagation framework jointly combining visual relevance, semantic relevance and discriminative ability. Extensive experiments on real-world datasets demonstrate that our approach obtains significant gains. (C) 2016 Elsevier Inc. All rights reserved.","Authors":"Xu, XC (Xu, Xiaocheng) ; Ma, J (Ma, Jun) ; Nie, LQ (Nie, Liqiang)","Title":"Weakly supervised image parsing via label propagation over discriminatively semantic graph"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000382678200021 ISSN: 1380-7501 eISSN: 1573-7721","Keywords":"Semantic video parsing; Transfer learning; Maximum a posterior (MAP) inference; Markov Random Felds (MRF); Prior contextual constraint KeyWords Plus:ENERGY MINIMIZATION; GRAPH CUTS; SEGMENTATION; ALGORITHMS","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"MULTIMEDIA TOOLS AND APPLICATIONS Volume: 75 Issue: 19 Pages: 11961-11976 DOI: 10.1007/s11042-015-2735-x Published: OCT 2016","Abstract":"Effective parsing of video through the spatial and temporal domains is vital to many computer vision problems because it is helpful to automatically label objects in video instead of manual fashion, which is tedious. Some literatures propose to parse the semantic information on individual 2D images or individual video frames, however, these approaches only take use of the spatial information, ignore the temporal continuity information and fail to consider the relevance of frames. On the other hand, some approaches which only consider the spatial information attempt to propagate labels in the temporal domain for parsing the semantic information of the whole video, yet the non-injective and non-surjective natures can cause the black hole effect. In this paper, inspirited by some annotated image datasets (e.g., Stanford Background Dataset, LabelMe, and SIFT-FLOW), we propose to transfer or propagate such labels from images to videos. The proposed approach consists of three main stages: I) the posterior category probability density function (PDF) is learned by an algorithm which combines frame relevance and label propagation from images. II) the prior contextual constraint PDF on the map of pixel categories through whole video is learned by the Markov Random Fields (MRF). III) finally, based on both learned PDFs, the final parsing results are yielded up to the maximum a posterior (MAP) process which is computed via a very efficient graph-cut based integer optimization algorithm. The experiments show that the black hole effect can be effectively handled by the proposed approach.","Authors":"Li, XL (Li, Xuelong) ; Mou, LC (Mou, Lichao) ; Lu, XQ (Lu, Xiaoqiang)","Title":"Video parsing via spatiotemporally analysis with images"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000382678200032 ISSN: 1380-7501 eISSN: 1573-7721","Keywords":"Video structured description; Surveillance videos; Public security KeyWords Plus:LINK NETWORK","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"MULTIMEDIA TOOLS AND APPLICATIONS Volume: 75 Issue: 19 Pages: 12155-12172 DOI: 10.1007/s11042-015-3112-5 Published: OCT 2016","Abstract":"Video surveillance is an integrated system with strong prevention capabilities and widely used in military, customs, police, fire fighting, airports, railways, urban transport and many other public places. It's an important part of security system because of its visualized, accurate, timely and rich information content. Video surveillance has become the main tool due to its rich, intuitive and accurate information. However, with the large-scale construction of video surveillance systems all over the world, problems such as \"useful information and clues cannot be found immediately with video big data\" decrease detecting efficiency during crime prediction and public security governance. The increasing need of video based applications issues the importance of parsing and organizing the content in videos. However, the accurate understanding and managing video contents at the semantic level is still insufficient. The semantic gap between low level features and high level semantics cannot be bridged by manual or semi-automatic methods. In this paper, a semantic based model named video structural description (VSD) for representing and organizing the content in videos is introduced firstly. Video structural description aims at parsing video content into the text information, which uses spatiotemporal segmentation, feature selection, object recognition, and semantic web technology. The applications of VSD technology on public security from surveillance videos are given. The intelligent analysis of person and vehicle from surveillance video based on VSD is presented. The cloud enhanced platform managing surveillance videos is also given. At last, applications using VSD are introduced.","Authors":"Xu, Z (Xu, Zheng) ; Hu, CP (Hu, Chuanping) ; Mei, L (Mei, Lin)","Title":"Video structured description technology based intelligence analysis of surveillance videos for public security applications"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000390887700008 ISSN: 0146-4116 eISSN: 1558-108X","Keywords":"Chinese complex sentences; hyponymy; entity identification; CRF; pattern matching; syntactic analysis","Categories":"Automation & Control Systems Web of Science Categories:Automation & Control Systems","Journal Information":"AUTOMATIC CONTROL AND COMPUTER SCIENCES Volume: 50 Issue: 5 Pages: 369-377 DOI: 10.3103/S0146411616050035 Published: SEP 2016","Abstract":"Extracting entity hyponymy in Chinese complex sentences can be a highly difficult process. This paper proposes a novel hybrid approach that combines parsing with supervised learning and semi-supervised learning. First, conditional random fields (CRF) model is employed to obtain the candidate domain named entity. Pattern matching is then used to acquire candidate hyponymy. Next, predicate and symbol features, syntactic analysis, and semantic roles are introduced into the CRF features template to identify the hyponymy entity pairs. Finally, analysis of both the parallel relationship of entities among sentences and entity pairs in simple sentences is conducted to obtain the hyponymy entity pairs in Chinese complex sentences. The experimental results show that the proposed method reduces the manual work required for CRF markers and has an improved overall performance in comparison with the baseline methods.","Authors":"Cheng, YR (Cheng, Yunru) ; Guo, JY (Guo, Jianyi) ; Xian, YT (Xian, Yantuan) ; Yu, ZT (Yu, Zhengtao) ; Chen, W (Chen, Wei) ; Yang, QY (Yang, Qiyue)","Title":"A Hybrid Method for Entity Hyponymy Acquisition in Chinese Complex Sentences"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000384920500018 ISSN: 1745-1361","Keywords":"incremental interpretation; normal form derivation; lambda-calculus; incremental parsing KeyWords Plus:DERIVATIONS","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS Volume: E99D Issue: 9 Pages: 2368-2376 DOI: 10.1587/transinf.2015EDP7355 Published: SEP 2016","Abstract":"This paper proposes a method of incrementally constructing semantic representations. Our method is based on Steedman's Combinatory Categorial Grammar ( CCG), which has a transparent correspondence between syntax and semantics. In our method, a derivation for a sentence is constructed in an incremental fashion and the corresponding semantic representation is derived synchronously. Our method uses normal form CCG derivation. This is the difference between our approach and previous ones. Previous approaches use most left-branching derivation called incremental derivation, but they cannot process coordinate structures incrementally. Our method overcomes this problem.","Authors":"Kato, Y (Kato, Yoshihide) ; Matsubara, S (Matsubara, Shigeki)","Title":"Incremental Semantic Construction Based on Combinatory Categorial Grammar"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000384451900001 ISSN: 0891-2017 eISSN: 1530-9312","Categories":"Computer Science; Linguistics Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics","Journal Information":"COMPUTATIONAL LINGUISTICS Volume: 42 Issue: 3 Pages: 353-389 DOI: 10.1162/COLI_a_00252 Published: SEP 2016","Abstract":"Derivations under different grammar formalisms allow extraction of various dependency structures. Particularly, bilexical deep dependency structures beyond surface tree representation can be derived from linguistic analysis grounded by CCG, LFG, and HPSG. Traditionally, these dependency structures are obtained as a by-product of grammar-guided parsers. In this article, we study the alternative data-driven, transition-based approach, which has achieved great success for tree parsing, to build general dependency graphs. We integrate existing tree parsing techniques and present two new transition systems that can generate arbitrary directed graphs in an incremental manner. Statistical parsers that are competitive in both accuracy and efficiency can be built upon these transition systems. Furthermore, the heterogeneous design of transition systems yields diversity of the corresponding parsing models and thus greatly benefits parser ensemble. Concerning the disambiguation problem, we introduce two new techniques, namely, transition combination and tree approximation, to improve parsing quality. Transition combination makes every action performed by a parser significantly change configurations. Therefore, more distinct features can be extracted for statistical disambiguation. With the same goal of extracting informative features, tree approximation induces tree backbones from dependency graphs and re-uses tree parsing techniques to produce tree-related features. We conduct experiments on CCG-grounded functor-argument analysis, LFG-grounded grammatical relation analysis, and HPSG-grounded semantic dependency analysis for English and Chinese. Experiments demonstrate that data-driven models with appropriate transition systems can produce high-quality deep dependency analysis, comparable to more complex grammar-driven models. Experiments also indicate the effectiveness of the heterogeneous design of transition systems for parser ensemble, transition combination, as well as tree approximation for statistical disambiguation.","Authors":"Zhang, X (Zhang, Xun) ; Du, YT (Du, Yantao) ; Sun, WW (Sun, Weiwei) ; Wan, XJ (Wan, Xiaojun)","Title":"Transition-Based Parsing for Deep Dependency Structures"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000379368800011 ISSN: 0925-2312 eISSN: 1872-8286","Keywords":"Social network; Semantic web; Semantic network; Ranking; FOAF; Linked data","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"NEUROCOMPUTING Volume: 202 Pages: 104-107 DOI: 10.1016/j.neucom.2015.10.021 Published: AUG 19 2016","Abstract":"Social Network Ranker (SoNeR) is software that retrieves, from the Semantic Web, documents describing people (users) and ranks them based on their popularity. It provides supportive tools for obtaining the related FOAF/RDF documents, parsing them, detecting identity synonyms and ranking people. The software is developed and implemented in the Java environment; and consists of the following modules: (1) semantic web crawler (collects FOAF/RDF documents), (2) document parser (extracts relevant information from FOAF/RDF documents), (3) synonym identity tagger (used to manually tag synonym pairs), (4) identity synonym merge and detection (5) ranking algorithms. While all these modules can be used separately, they are also unified in one Desktop GUI application. (C) 2015 Elsevier B.V. All rights reserved.","Authors":"Petrovic, G (Petrovic, Gajo) ; Fujita, H (Fujita, Hamido) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Fujita, Hamido  http://orcid.org/0000-0001-5256-210X","Title":"SoNeR: Social Network Ranker"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000383682900034 PubMed ID: 27153616 ISSN: 1367-4803 eISSN: 1460-2059","Categories":"Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics Web of Science Categories:Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability","Journal Information":"BIOINFORMATICS Volume: 32 Issue: 16 Pages: 2559-2561 DOI: 10.1093/bioinformatics/btw179 Published: AUG 15 2016","Abstract":"SBtab is a table-based data format for Systems Biology, designed to support automated data integration and model building. It uses the structure of spreadsheets and defines conventions for table structure, controlled vocabularies and semantic annotations. The format comes with pre-defined table types for experimental data and SBML-compliant model structures and can easily be customized to cover new types of data. Availability and Implementation: SBtab documents can be created and edited with any text editor or spreadsheet tool. The websitewww.sbtab.net provides online tools for syntax validation and conversion to SBML and HTML, as well as software for using SBtab in MS Excel, MATLAB and R. The stand-alone Python code contains functions for file parsing, validation, conversion to SBML and HTML and an interface to SQLite databases, to be integrated into Systems Biology workflows. A detailed specification of SBtab, including examples and descriptions of table types and available tools, can be found at www.sbtab.net. Contact: wolfram. liebermeister@gmail.com","Authors":"Lubitz, T (Lubitz, Timo) ; Hahn, J (Hahn, Jens) ; Bergmann, FT (Bergmann, Frank T.) ; Noor, E (Noor, Elad) ; Klipp, E (Klipp, Edda) ; Liebermeister, W (Liebermeister, Wolfram) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Hahn, Jens  http://orcid.org/0000-0003-2200-6553 Bergmann, Frank  http://orcid.org/0000-0001-5553-4702","Title":"SBtab: a flexible table format for data exchange in systems biology"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000377923600009 ISSN: 0925-2312 eISSN: 1872-8286","Keywords":"Non-parametric image parsing; Sparse-dense reconstruction; Hierarchical semantic voting; String with semantic spatial-contextual cue KeyWords Plus:SEGMENTATION; RECOGNITION; FEATURES; TEXTURE; MODEL","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"NEUROCOMPUTING Volume: 201 Pages: 92-103 DOI: 10.1016/j.neucom.2016.03.034 Published: AUG 12 2016","Abstract":"Image parsing is vital for many high-level image understanding tasks. Although both parametric and non-parametric approaches have achieved remarkable success, many technical challenges still prevail for images containing things/objects with broad-coverage and high-variability, because it still lacks versatile and effective strategies to seamlessly integrate local-global features selection, contextual cues exploitation, spatial layout encoding, data-driven coherency exploration, and flexible accommodation of newly annotated labels. To ameliorate, this paper develops a novel automatic non-parametric image parsing method with advantages of both parametric and non-parametric methodologies by resorting to new modeling and inferring strategies. The originality of our new approach is to employ sparse-dense reconstruction as a latent learning model to conduct candidate-label probability analysis over multi-level local regions, and synchronously leverage context-specific local-global label confidence propagation and global semantic spatial-contextual cues to guide holistic scene parsing. Towards this goal, we devise several novel technical components to comprise a lightweight parsing framework, including local region representation integrating complementary features, anisotropic consistency propagation based on bi-harmonic distance metric, bottom-up label voting, semantic string generation of image-level spatial contextual cues based on Hilbert space-filling curve, and co-occurrence priors analysis based on relaxed string matching algorithm, which collectively enable us to effectively combat the aforementioned obstinate problems. Moreover, we conduct comprehensive experiments on public benchmarks, and make extensive and quantitative evaluations with state-of-the-art methods, which demonstrate the advantages of our method in accuracy, versatility, flexibility, and efficiency. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"An, XY (An, Xinyi) ; Li, S (Li, Shuai) ; Qin, H (Qin, Hong) ; Hao, AM (Hao, Aimin)","Title":"Automatic non-parametric image parsing via hierarchical semantic voting based on sparse-dense reconstruction and spatial-contextual cues"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000384736400001 ISSN: 2192-1962","Keywords":"Web services; Change management framework; Semantic reasoner; Ontology; S-BPEL; BPEL KeyWords Plus:DISCOVERY","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"HUMAN-CENTRIC COMPUTING AND INFORMATION SCIENCES Volume: 6 Article Number: 13 DOI: 10.1186/s13673-016-0067-0 Published: AUG 10 2016","Abstract":"Enterprises enhance their business on the web with the help of web services. This enhancement is achieved by composing the pre-existing services, so that they will be able to provide solutions for the problems on the web. Due to rapid development in technology, the need for making changes in the composed services by the respective analysts becomes an essential task. Thus, the change management process becomes a challenging area in web service. Although, the existing solutions use ontology for change management, they have been designed majorly for IT developers rather than analyst. Therefore, we concentrate on providing a change management framework that will make use of an enriched ontology set and semantic reasoner for implementing the changes by the analyst itself. The semantic reasoner component parses the change request from the analysts and determines the possibility for making the change. The framework represents the implemented changes in the form of a S-BPEL notation (Semantic BPEL) which is then converted to their corresponding BPEL notations by a BPEL constructor so that they can be deployed in the run time environment for composing the services.","Authors":"Thirumaran, M (Thirumaran, M.) ; Brendha, GG (Brendha, G. Gayathry)","Title":"Incremental stages of a semantic framework for automating the changes on long term composed services"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000382793700008 ISSN: 1474-0346 eISSN: 1873-5320","Keywords":"Building Information Modeling (BIM); Interoperability; Ontology; Information Delivery Manual (IDM); Model View Definition (MVD); Industry Foundation Classes (IFC); Information technology; Rule checking","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Multidisciplinary","Journal Information":"ADVANCED ENGINEERING INFORMATICS Volume: 30 Issue: 3 Pages: 354-367 DOI: 10.1016/j.aei.2016.04.008 Published: AUG 2016","Abstract":"Each domain industry requires the detailed specifications for sharing and exchanging building information models throughout the design, construction, and operation phases. Industry Foundation Classes (IFC) Model View Definitions (MVDs) specify required information for exchanges of building model data among building project experts. The data involves the identification of model semantics shared by two or more applications. However, since no robust standard for defining building semantics and requirements for data exchange has been agreed upon, information embedded in domain-specific MVDs are generated separately and are vague in scope, which results in a lack of consistency. In addition, the Information Delivery Manual (IDM) that includes exchange specifications needed for each exchange process of a product model is manually defined in a paper-based document. Because there is no clear logical link between the units of information in the exchange requirements of an IDM, and those of MVDs, the mapping that translates requirements of an IDM into ones of an MVD is open to various interpretation, without semantic and logical consistency. Such challenges might result in redundant requirements and rules for data exchange that are not supposed to be handled in the process of MVDs. To ameliorate this situation, this research proposes the new approach of formalizing domain knowledge and defining accurate data modules for model views. To achieve this goal, the authors employed ontological principles for generating an IDM for the precast concrete domain and for linking its MVD with formal information models. The formalized structure of domain knowledge is expected to support defining explicit data modules and developing manageable relationships among entities using semantic reasoning so that domain professionals and software vendors can identify the intents of the requirements of mapped MVDs and keep track of mapping problems. Moreover, to integrate IDM and MVD development processes, the ontology-based IDM is parsed and translated from OWL/XML to mvdXML, which automatically generates MVD documentation in the IfcDoc tool. (C) 2016 Published by Elsevier Ltd.","Authors":"Lee, YC (Lee, Yong-Cheol) ; Eastman, CM (Eastman, Charles M.) ; Solihin, W (Solihin, Wawan) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Lee, Yongcheol  http://orcid.org/0000-0002-0040-0894","Title":"An ontology-based approach for developing data exchange requirements and model views of building information modeling"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000382721300008 PubMed ID: 27088643 ISSN: 0048-5772 eISSN: 1469-8986","Keywords":"Safety signals; Anxiety; Emotion regulation; Fear; Psychophysiology KeyWords Plus:FEAR-POTENTIATED STARTLE; CONDITIONED INHIBITION; SOCIAL-CONSEQUENCES; PREFRONTAL CORTEX; COGNITIVE CONTROL; ANXIETY DISORDER; UNCERTAIN THREAT; STRESS; AMYGDALA; ALCOHOL","Categories":"Psychology; Neurosciences & Neurology; Physiology Web of Science Categories:Psychology, Biological; Neurosciences; Physiology; Psychology; Psychology, Experimental","Journal Information":"PSYCHOPHYSIOLOGY Volume: 53 Issue: 8 Pages: 1193-1202 DOI: 10.1111/psyp.12660 Published: AUG 2016","Abstract":"Improved understanding of fear inhibition processes can inform the etiology and treatment of anxiety disorders. Safety signals can reduce fear to threat, but precise mechanisms remain unclear. Safety signals may acquire attentional salience and affective properties (e.g., relief) independent of the threat; alternatively, safety signals may only hold affective value in the presence of simultaneous threat. To clarify such mechanisms, an experimental paradigm assessed independent processing of threat and safety cues. Participants viewed a series of red and green words from two semantic categories. Shocks were administered following red words (cue+). No shocks followed green words (cue-). Words from one category were defined as safety signals (SS); no shocks were administered on cue+ trials. Words from the other (control) category did not provide information regarding shock administration. Threat (cue+ vs. cue-) and safety (SS+ vs. SS-) were fully crossed. Startle response and ERPs were recorded. Startle response was increased during cue+ versus cue-. Safety signals reduced startle response during cue+, but had no effect on startle response during cue-. ERP analyses (PD+30 and P3) suggested that participants parsed threat and safety signal information in parallel. Motivated attention was not associated with safety signals in the absence of threat. Overall, these results confirm that fear can be reduced by safety signals. Furthermore, safety signals do not appear to hold inherent hedonic salience independent of their effect during threat. Instead, safety signals appear to enable participants to engage in effective top-down emotion regulatory processes.","Authors":"Hefner, KR (Hefner, Kathryn R.) ; Verona, E (Verona, Edelyn) ; Curtin, JJ (Curtin, John. J.)","Title":"Emotion regulation during threat: Parsing the time course and consequences of safety signal processing"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000380125800003 ISSN: 0165-5515 eISSN: 1741-6485","Keywords":"Features; initial summary; latent semantic analysis; summarization; update summary","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF INFORMATION SCIENCE Volume: 42 Issue: 4 Pages: 465-476 DOI: 10.1177/0165551515594726 Published: AUG 2016","Abstract":"With the exponential growth of the internet, a lot of online news reports are produced on the web every day. The news stream flows so rapidly that no one has the time to look at each and every item of information. In this situation, a person would naturally prefer to read updated information at certain time intervals. Document updating technique is very helpful for individuals to acquire new information or knowledge by eliminating out-of-date or redundant information. Existing summarization systems involve identifying the most relevant sentences from the text and putting them together to create a concise initial summary. In the process of identifying the important sentences, features influencing the relevance of sentences are determined. Based on these features the salience of the sentence is calculated and an initial summary is generated from highly important sentences at different compression rates. These types of initial summaries work on a batch of documents and do not consider the documents that may arrive at later time, so that corresponding summaries need to get updated. The update summarization system addresses this issue by taking into account the documents read by the user in the past and seeks to present only fresh or different information. The first step is to create an initial summary based on basic and additional features. The next step is to create an update summary based on the basic, additional and update features. In this paper, two approaches are proposed for generating initial and update summary from multiple documents about given news. The first approach performs semantic analysis by modifying the vector space model with dependency parse relations and applying latent semantic analysis on it to create a summary. The second approach applies sentence annotation based on aspects, prepositions and named entities to generate summary. Experimental results show that the proposed approaches generate better initial and update summaries compared with the existing systems.","Authors":"Kogilavani, SV (Kogilavani, S. V.) ; Kanimozhiselvi, CS (Kanimozhiselvi, C. S.) ; Malliga, S (Malliga, S.)","Title":"Summary generation approaches based on semantic analysis for news documents"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000377835200003 ISSN: 0010-4485 eISSN: 1879-2685","Keywords":"Data driven; Color design; Lexicographic optimization; Color semantics KeyWords Plus:2-COLOR COMBINATIONS; VISUALIZATION; PREFERENCE; ATTENTION; EMOTIONS; MODEL","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"COMPUTER-AIDED DESIGN Volume: 77 Pages: 46-59 DOI: 10.1016/j.cad.2016.03.001 Published: AUG 2016","Abstract":"This paper presents a design framework for automatic webpage coloring regarding several fundamental design objectives: proper visual contrasts, multi-color compatibility and semantic associations. The objective functions are formulated with data-driven probabilistic models: the Color Contrast model concerning visual saliencies is trained on 52,000 basic components parsed from 500 popular webpages. Color Compatibility and Semantics are modeled from a dataset of manually tagged and rated color schemes from Adobe Kuler. To incorporate the multi-objectives in optimization, the framework adopts a lexicographic strategy, which determines the best choices by optimizing the objectives one by one in a user specified sequence. We demonstrate the effectiveness of the models and the flexibility of the framework in two typical web color design scenarios: fine tuning a colored page and recoloring a page with a specified palette. Independent perception experiments verify that the system-generated designs are preferable to those generated by nonprofessionals. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Gu, ZY (Gu, Zhenyu) ; Lou, J (Lou, Jian)","Title":"Data driven webpage color design"}, {"Document Information":"Document Type:Article; Proceedings Paper Language:English Accession Number: WOS:000380112400119 ISSN: 0730-0301 eISSN: 1557-7368","Keywords":"sky segmentation; sky replacement; compositing; appearance transfer; semantic search","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"ACM TRANSACTIONS ON GRAPHICS Volume: 35 Issue: 4 Article Number: 149 DOI: 10.1145/2897824.2925942 Published: JUL 2016","Abstract":"Skies are common backgrounds in photos but are often less interesting due to the time of photographing. Professional photographers correct this by using sophisticated tools with painstaking efforts that are beyond the command of ordinary users. In this work, we propose an automatic background replacement algorithm that can generate realistic, artifact-free images with a diverse styles of skies. The key idea of our algorithm is to utilize visual semantics to guide the entire process including sky segmentation, search and replacement. First we train a deep convolutional neural network for semantic scene parsing, which is used as visual prior to segment sky regions in a coarse-to-fine manner. Second, in order to find proper skies for replacement, we propose a data-driven sky search scheme based on semantic layout of the input image. Finally, to re-compose the stylized sky with the original foreground naturally, an appearance transfer method is developed to match statistics locally and semantically. We show that the proposed algorithm can automatically generate a set of visually pleasing results. In addition, we demonstrate the effectiveness of the proposed algorithm with extensive user studies.","Authors":"Tsai, YH (Tsai, Yi-Hsuan) ; Shen, XH (Shen, Xiaohui) ; Lin, Z (Lin, Zhe) ; Sunkavalli, K (Sunkavalli, Kalyan) ; Yang, MH (Yang, Ming-Hsuan)","Title":"Sky is Not the Limit: Semantic-Aware Sky Replacement"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000381506500007 ISSN: 1545-5963 eISSN: 1557-9964","Keywords":"Biomedical event extraction; dual decomposition; word embeddings; natural language processing","Categories":"Biochemistry & Molecular Biology; Computer Science; Mathematics Web of Science Categories:Biochemical Research Methods; Computer Science, Interdisciplinary Applications; Mathematics, Interdisciplinary Applications; Statistics & Probability","Journal Information":"IEEE-ACM TRANSACTIONS ON COMPUTATIONAL BIOLOGY AND BIOINFORMATICS Volume: 13 Issue: 4 Pages: 669-677 DOI: 10.1109/TCBB.2015.2476876 Published: JUL-AUG 2016","Abstract":"Extracting biomedical event from literatures has attracted much attention recently. By now, most of the state-of-the-art systems have been based on pipelines which suffer from cascading errors, and the words encoded by one-hot are unable to represent the semantic information. Joint inference with dual decomposition and novel word embeddings are adopted to address the two problems, respectively, in this work. Word embeddings are learnt from large scale unlabeled texts and integrated as an unsupervised feature into other rich features based on dependency parse graphs to detect triggers and arguments. The proposed system consists of four components: trigger detector, argument detector, jointly inference with dual decomposition, and rule-based semantic post-processing, and outperforms the state-of-the-art systems. On the development set of BioNLP'09, the F-score is 59.77 percent on the primary task, which is 0.96 percent higher than the best system. On the test set of BioNLP'11, the F-score is 56.09 and 0.89 percent higher than the best published result that do not adopt additional techniques. On the test set of BioNLP'13, the F-score reaches 53.19 percent which is 2.22 percent higher than the best result.","Authors":"Li, LS (Li, Lishuang) ; Liu, SS (Liu, Shanshan) ; Qin, MY (Qin, Meiyue) ; Wang, YW (Wang, Yiwen) ; Huang, DG (Huang, Degen)","Title":"Extracting Biomedical Event with Dual Decomposition Integrating Word Embeddings"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000380322200013 ISSN: 2157-6904 eISSN: 2157-6912","Keywords":"Design; Algorithms; Performance; Crowdsourcing; quality control; behavioral features; worker performance","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY Volume: 7 Issue: 4 Special Issue: SI Article Number: 56 DOI: 10.1145/2870649 Published: JUL 2016","Abstract":"Parsing the semantic structure of a web page is a key component of web information extraction. Successful extraction algorithms usually require large-scale training and evaluation datasets, which are difficult to acquire. Recently, crowdsourcing has proven to be an effective method of collecting large-scale training data in domains that do not require much domain knowledge. For more complex domains, researchers have proposed sophisticated quality control mechanisms to replicate tasks in parallel or sequential ways and then aggregate responses from multiple workers. Conventional annotation integration methods often put more trust in the workers with high historical performance; thus, they are called performance-based methods. Recently, Rzeszotarski and Kittur have demonstrated that behavioral features are also highly correlated with annotation quality in several crowdsourcing applications. In this article, we present a new crowdsourcing system, called Wernicke, to provide annotations for web information extraction. Wernicke collects a wide set of behavioral features and, based on these features, predicts annotation quality for a challenging task domain: annotating web page structure. We evaluate the effectiveness of quality control using behavioral features through a case study where 32 workers annotate 200 Q&A web pages from five popular websites. In doing so, we discover several things: (1) Many behavioral features are significant predictors for crowdsourcing quality. (2) The behavioral-feature-based method outperforms performance-based methods in recall prediction, while performing equally with precision prediction. In addition, using behavioral features is less vulnerable to the cold-start problem, and the corresponding prediction model is more generalizable for predicting recall than precision for cross-website quality analysis. (3) One can effectively combine workers' behavioral information and historical performance information to further reduce prediction errors.","Authors":"Han, SG (Han, Shuguang) ; Dai, P (Dai, Peng) ; Paritosh, P (Paritosh, Praveen) ; Huynh, D (Huynh, David)","Title":"Crowdsourcing Human Annotation on Web Page Structure: Infrastructure Design and Behavior-Based Quality Control"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000371900800006 ISSN: 0885-2308 eISSN: 1095-8363","Keywords":"Multilingual Language Understanding; Graph of words; Graph of concepts; Statistical semantic models KeyWords Plus:SEMANTIC INTERPRETATION; NETWORKS","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"COMPUTER SPEECH AND LANGUAGE Volume: 38 Pages: 86-103 DOI: 10.1016/j.csl.2016.01.002 Published: JUL 2016","Abstract":"In this paper, we present an approach to multilingual Spoken Language Understanding based on a process of generalization of multiple translations, followed by a specific methodology to perform a semantic parsing of these combined translations. A statistical semantic model, which is learned from a segmented and labeled corpus, is used to represent the semantics of the task in a language. Our goal is to allow the users to interact with the system using other languages different from the one used to train the semantic models, avoiding the cost of segmenting and labeling a training corpus for each language. In order to reduce the effect of translation errors and to increase the coverage, we propose an algorithm to generate graphs of words from different translations. We also propose an algorithm to parse graphs of words with the statistical semantic model. The experimental results confirm the good behavior of this approach using French and English as input languages in a spoken language understanding task that was developed for Spanish. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Calvo, M (Calvo, Marcos) ; Hurtado, LF (Hurtado, Lluis-Felip) ; Garcia, F (Garcia, Fernando) ; Sanchis, E (Sanchis, Emilio) ; Segarra, E (Segarra, Encarna)","Title":"Multilingual Spoken Language Understanding using graphs and multiple translations"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000372040400002 ISSN: 1751-7575 eISSN: 1751-7583","Keywords":"dependency parsing; frequency-inverse document frequency; affective computing; sentiment analysis; pointwise mutual information KeyWords Plus:INFORMATION-RETRIEVAL; SEMANTIC ORIENTATION; LANGUAGE","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"ENTERPRISE INFORMATION SYSTEMS Volume: 10 Issue: 5 Pages: 505-522 DOI: 10.1080/17517575.2014.985613 Published: JUN 12 2016","Abstract":"Feature-level sentiment analysis (SA) is able to provide more fine-grained SA on certain opinion targets and has a wider range of applications on E-business. This study proposes an approach based on comparative domain corpora for feature-level SA. The proposed approach makes use of word associations for domain-specific feature extraction. First, we assign a similarity score for each candidate feature to denote its similarity extent to a domain. Then we identify domain features based on their similarity scores on different comparative domain corpora. After that, dependency grammar and a general sentiment lexicon are applied to extract and expand feature-oriented opinion words. Lastly, the semantic orientation of a domain-specific feature is determined based on the feature-oriented opinion lexicons. In evaluation, we compare the proposed method with several state-of-the-art methods (including unsupervised and semi-supervised) using a standard product review test collection. The experimental results demonstrate the effectiveness of using comparative domain corpora.","Authors":"Quan, CQ (Quan, Changqin) ; Ren, FJ (Ren, Fuji)","Title":"Feature-level sentiment analysis by using comparative domain corpora"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000383043400002 ISSN: 2192-6611 eISSN: 2192-662X","Keywords":"Event detection; Event recounting; Ontology KeyWords Plus:VIDEO; RECOGNITION; CONTEXT","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL Volume: 5 Issue: 2 Pages: 73-88 DOI: 10.1007/s13735-015-0090-3 Published: JUN 2016","Abstract":"Textually narrating the observed evidences relevant to the reasons why a video clip is being retrieved for an event is still a highly challenging problem. This paper explores the use of a commonsense ontology, namely ConceptNet, in generating short descriptions for recounting the audio-visual evidences. The ontology is exploited as a knowledge engine to provide event-relevant common sense, which is expressed in terms of concepts and their relationships, for semantics understanding, context-based concept screening and sentence synthesis. A principal way of exploiting the ontology, from extracting the event-relevant semantic network to the formation of syntactic parse trees, is outlined and discussed. Experimental results on two benchmark datasets (TRECVID MED and MediaEval) show the effectiveness of our approach. The findings show insights on the usability of common sense for multimedia search, including the feasibility of inferring relevant concepts for event detection, as well as the quality of textual sentences in meeting human expectation.","Authors":"Tan, CC (Tan, Chun-Chet) ; Ngo, CW (Ngo, Chong-Wah)","Title":"On the use of commonsense ontology for multimedia event recounting"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000379979700004 ISSN: 1751-9659 eISSN: 1751-9667","Categories":"Computer Science; Engineering; Imaging Science & Photographic Technology Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology","Journal Information":"IET IMAGE PROCESSING Volume: 10 Issue: 6 Pages: 456-463 DOI: 10.1049/iet-ipr.2015.0507 Published: JUN 2016","Abstract":"In this study, the authors address the problem of parsing fashion images into mid-level semantic parts including upper-clothing, lower-clothing, skin, hair and background. These mid-level parts provide the regional information of fashion items and have potential value in high-level parsing process. The key idea of the method is to parse the mid-level parts by region expanding. Owing to the co-occurrence of pose skeleton and the proposed parts, the region expanding process starts from the super-pixels crossed by specific segments of pose skeleton. The super-pixels are then merged with their neighbours by conditional inference based on their position and perceptual similarity. To avoid the difficulties of training on arbitrary graph structures, conditional random fields (CRFs) are constructed on super-pixel chains, which are extracted from the generated expanding trees. This is followed by a voting stage to mix up the probabilities estimated by the chain-CRFs to obtain the final result. Experiments on two datasets show that the new method outperforms related approaches in regional accuracy and has good generalisation capability. Furthermore, the method can be easily employed to improve the performance of high-level parsing. Its effectiveness has been verified by another group of experiments on two state-of-the-art high-level parsing approaches.","Authors":"Wang, F (Wang Fan) ; Zhao, QY (Zhao Qiyang) ; Yin, BL (Yin Baolin) ; Xu, T (Xu Tao)","Title":"Parsing fashion image into mid-level semantic parts based on chain-conditional random fields"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000378301200009 PubMed ID: 27208858 ISSN: 0093-934X eISSN: 1090-2155","Keywords":"Syntax; Parsing; Prediction; fMRI; ATL; IFG; PTL; Narrative KeyWords Plus:LANGUAGE COMPREHENSION; SENTENCE COMPREHENSION; SYNTACTIC STRUCTURE; SEMANTIC MEMORY; WORKING-MEMORY; HUMAN BRAIN; BROCAS AREA; CORTEX; FMRI; LOBE","Categories":"Audiology & Speech-Language Pathology; Linguistics; Neurosciences & Neurology; Psychology Web of Science Categories:Audiology & Speech-Language Pathology; Linguistics; Neurosciences; Psychology, Experimental","Journal Information":"BRAIN AND LANGUAGE Volume: 157 Pages: 81-94 DOI: 10.1016/j.bandl.2016.04.008 Published: JUN-JUL 2016","Abstract":"Neurolinguistic accounts of sentence comprehension identify a network of relevant brain regions, but do not detail the information flowing through them. We investigate syntactic information. Does brain activity implicate a computation over hierarchical grammars or does it simply reflect linear order, as in a Markov chain? To address this question, we quantify the cognitive states implied by alternative parsing models. We compare processing-complexity predictions from these states against fMRI timecourses from regions that have been implicated in sentence comprehension. We find that hierarchical grammars independently predict timecourses from left anterior and posterior temporal lobe. Markov models are predictive in these regions and across a broader network that includes the inferior frontal gyrus. These results suggest that while linear effects are wide-spread across the language network, certain areas in the left temporal lobe deal with abstract, hierarchical syntactic representations. (C) 2016 Elsevier Inc. All rights reserved.","Authors":"Brennan, JR (Brennan, Jonathan R.) ; Stabler, EP (Stabler, Edward P.) ; Van Wagenen, SE (Van Wagenen, Sarah E.) ; Luh, WM (Luh, Wen-Ming) ; Hale, JT (Hale, John T.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Brennan, Jonathan R  http://orcid.org/0000-0002-3639-350X","Title":"Abstract linguistic structure correlates with temporal activity during naturalistic comprehension"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000376107100019 ISSN: 1520-9210 eISSN: 1941-0077","Keywords":"Clothes recognition; fashion understanding; human-centric computing; image parsing KeyWords Plus:REPRESENTATION; RECOGNITION; CONTEXT; COLOR","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications","Journal Information":"IEEE TRANSACTIONS ON MULTIMEDIA Volume: 18 Issue: 6 Pages: 1175-1186 DOI: 10.1109/TMM.2016.2542983 Published: JUN 2016","Abstract":"This paper aims at developing an integrated system for clothing co-parsing (CCP), in order to jointly parse a set of clothing images (unsegmented but annotated with tags) into semantic configurations. A novel data-driven system consisting of two phases of inference is proposed. The first phase, referred as \"image cosegmentation,\" iterates to extract consistent regions on images and jointly refines the regions over all images by employing the exemplar-SVM technique [1]. In the second phase (i.e., \"region colabeling\"), we construct a multiimage graphical model by taking the segmented regions as vertices, and incorporating several contexts of clothing configuration (e.g., item locations and mutual interactions). The joint label assignment can be solved using the efficient Graph Cuts algorithm. In addition to evaluate our framework on the Fashionista dataset [2], we construct a dataset called the SYSU-Clothes dataset consisting of 2098 high-resolution street fashion photos to demonstrate the performance of our system. We achieve 90.29%/88.23% segmentation accuracy and 65.52%/63.89% recognition rate on the Fashionista and the SYSU-Clothes datasets, respectively, which are superior compared with the previous methods. Furthermore, we apply our method on a challenging task, i.e., cross-domain clothing retrieval: given user photo depicting a clothing image, retrieving the same clothing items from online shopping stores based on the fine-grained parsing results.","Authors":"Liang, XD (Liang, Xiaodan) ; Lin, L (Lin, Liang) ; Yang, W (Yang, Wei) ; Luo, P (Luo, Ping) ; Huang, JS (Huang, Junshi) ; Yan, SC (Yan, Shuicheng)","Title":"Clothes Co-Parsing Via Joint Image Segmentation and Labeling With Application to Clothing Retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000375801900001 ISSN: 2329-9290","Keywords":"Class-based features; conditional random fields; exponential models; natural language understanding; regularization; shrinkage features","Categories":"Acoustics; Engineering Web of Science Categories:Acoustics; Engineering, Electrical & Electronic","Journal Information":"IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING Volume: 24 Issue: 6 Pages: 994-1005 DOI: 10.1109/TASLP.2015.2511925 Published: JUN 2016","Abstract":"There are many studies that show using class-based features improves the performance of natural language processing (NLP) tasks such as syntactic part-of-speech tagging, dependency parsing, sentiment analysis, and slot filling in natural language understanding (NLU), but not much has been reported on the underlying reasons for the performance improvements. In this paper, we investigate the effects of the word class-based features for the exponential family of models specifically focusing on NLU tasks, and demonstrate that the performance improvements could be attributed to the regularization effect of the class-based features on the underlying model. Our hypothesis is based on empirical observation that shrinking the sum of parameter magnitudes in an exponential model tends to improve performance. We show on several semantic tagging tasks that there is a positive correlation between the model size reduction by the addition of the class-based features and the model performance on a held-out dataset. We also demonstrate that class-based features extracted from different data sources using alternate word clustering methods can individually contribute to the performance gain. Since the proposed features are generated in an unsupervised manner without significant computational overhead, the improvements in performance largely come for free and we show that such features provide gains for a wide range of tasks from semantic classification and slot tagging in NLU to named entity recognition (NER).","Authors":"Celikyilmaz, A (Celikyilmaz, Asli) ; Sarikaya, R (Sarikaya, Ruhi) ; Jeong, M (Jeong, Minwoo) ; Deoras, A (Deoras, Anoop)","Title":"An Empirical Investigation of Word Class-Based Features for Natural Language Understanding"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000374897900002 PubMed ID: 25794495 ISSN: 0090-6905 eISSN: 1573-6555","Keywords":"Maze task; Scrambling; Control; Preverbal processing; Japanese KeyWords Plus:REFLEXIVE RESOLUTION; WORD-ORDER; EYE-MOVEMENTS; FILLING GAPS; INFORMATION; COMPREHENSION; LANGUAGE; DEPENDENCIES; ANTECEDENT; ACTIVATION","Categories":"Linguistics; Psychology Web of Science Categories:Linguistics; Psychology, Experimental","Journal Information":"JOURNAL OF PSYCHOLINGUISTIC RESEARCH Volume: 45 Issue: 3 Pages: 475-505 DOI: 10.1007/s10936-015-9356-4 Published: JUN 2016","Abstract":"This study investigates preverbal structural and semantic processing in Japanese, a head-final language, using the maze task. Two sentence types were tested-simple scrambled sentences (Experiment 1) and control sentences (Experiment 2). Experiment 1 showed that even for simple, mono-clausal Japanese sentences, (1) there are online processing costs associated with parsing noncanonical word orders and (2) these costs are incurred during the incremental integration of constituents into developing sentence representations. Experiment 2 indicated (1) that antecedents are provisionally assigned to empty subjects in Japanese control sentences before verb information becomes available and (2) that this process is guided by an object control bias. Taken together, these findings are interpreted to suggest an important role for preverbal analysis in the processing of displaced constituents and of referential properties for empty elements in head-final languages.","Authors":"Witzel, J (Witzel, Jeffrey) ; Witzel, N (Witzel, Naoko)","Title":"Incremental Sentence Processing in Japanese: A Maze Investigation into Scrambled and Control Sentences"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000372262500004 ISSN: 0928-8910 eISSN: 1573-7535","Keywords":"Concern mining; User assistance; Tool support; Semantic analysis; Natural language processing; Use case specifications KeyWords Plus:SPECIFICATIONS; AGREEMENT","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"AUTOMATED SOFTWARE ENGINEERING Volume: 23 Issue: 2 Pages: 219-252 DOI: 10.1007/s10515-014-0156-0 Published: JUN 2016","Abstract":"Textual requirements are very common in software projects. However, this format of requirements often keeps relevant concerns (e.g., performance, synchronization, data access, etc.) from the analyst's view because their semantics are implicit in the text. Thus, analysts must carefully review requirements documents in order to identify key concerns and their effects. Concern mining tools based on NLP techniques can help in this activity. Nonetheless, existing tools cannot always detect all the crosscutting effects of a given concern on different requirements sections, as this detection requires a semantic analysis of the text. In this work, we describe an automated tool called REAssistant that supports the extraction of semantic information from textual use cases in order to reveal latent crosscutting concerns. To enable the analysis of use cases, we apply a tandem of advanced NLP techniques (e.g, dependency parsing, semantic role labeling, and domain actions) built on the UIMA framework, which generates different annotations for the use cases. Then, REAssistant allows analysts to query these annotations via concern-specific rules in order to identify all the effects of a given concern. The REAssistant tool has been evaluated with several case-studies, showing good results when compared to a manual identification of concerns and a third-party tool. In particular, the tool achieved a remarkable recall regarding the detection of crosscutting concern effects.","Authors":"Rago, A (Rago, Alejandro) ; Marcos, C (Marcos, Claudia) ; Diaz-Pace, JA (Diaz-Pace, J. Andres) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Rago, Alejandro  http://orcid.org/0000-0002-8617-4225","Title":"Assisting requirements analysts to find latent concerns with REAssistant"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000375688700003 PubMed ID: 27028353 ISSN: 0959-4965 eISSN: 1473-558X","Keywords":"Chinese middle sentences; event-related potential; syntactic and semantic processing KeyWords Plus:AMBIGUITY RESOLUTION; TEMPORAL STRUCTURE; ERP EVIDENCE; COMPREHENSION; LANGUAGE; INFORMATION","Categories":"Neurosciences & Neurology Web of Science Categories:Neurosciences","Journal Information":"NEUROREPORT Volume: 27 Issue: 8 Pages: 568-573 DOI: 10.1097/WNR.0000000000000569 Published: MAY 25 2016","Abstract":"Scalp-recorded event-related potentials are known to be sensitive to particular aspects of sentence processing. The N400 component is widely recognized as an effect closely related to lexical-semantic processing. The absence of an N400 effect in participants performing tasks in Indo-European languages has been considered evidence that failed syntactic category processing appears to block lexical-semantic integration and that syntactic structure building is a prerequisite of semantic analysis. An event-related potential experiment was designed to investigate whether such syntactic primacy can be considered to apply equally to Chinese sentence processing. Besides correct middles, sentences with either single semantic or single syntactic violation as well as double syntactic and semantic anomaly were used in the present research. Results showed that both purely semantic and combined violation induced a broad negativity in the time window 300-500 ms, indicating the independence of lexical-semantic integration. These findings provided solid evidence that lexical-semantic parsing plays a crucial role in Chinese sentence comprehension. Copyright (C) 2016 Wolters Kluwer Health, Inc. All rights reserved.","Authors":"Zeng, T (Zeng, Tao) ; Mao, W (Mao, Wen) ; Lu, Q (Lu, Qing)","Title":"Syntactic and semantic processing of Chinese middle sentences: evidence from event-related potentials"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000372102000004 PubMed ID: 25920901 ISSN: 1747-0218 eISSN: 1747-0226","Keywords":"Language processing in ageing; Language comprehension; Good-enough language processing; Syntactic parsing KeyWords Plus:LANGUAGE COMPREHENSION; WORKING-MEMORY; SENTENCES; AGE; PLAUSIBILITY; RECOVERY; SPEECH","Categories":"Psychology; Physiology Web of Science Categories:Psychology, Biological; Physiology; Psychology; Psychology, Experimental","Journal Information":"QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY Volume: 69 Issue: 5 Pages: 880-906 Special Issue: SI DOI: 10.1080/17470218.2015.1045530 Published: MAY 3 2016","Abstract":"Previous research has shown that comprehenders do not always conduct a full (re)analysis of temporarily ambiguous \"garden-path\" sentences. The present study used a sentence-picture matching task to investigate what kind of representations are formed when full reanalysis is not performed: Do comprehenders \"blend\" two incompatible representations as a result of shallow syntactic processing or do they erroneously maintain the initial incorrect parsing without incorporating new information, and does this vary with age? Twenty-five younger and 15 older adults performed a multiple-choice sentence-picture matching task with stimuli including early-closure garden-path sentences. The results suggest that the type of erroneous representation is affected by linguistic variables, such as sentence structure, verb type, and semantic plausibility, as well as by age. Older adults' response patterns indicate an increased reliance on inferencing based on lexical and semantic cues, with a lower bar for accepting an initial parse and with a weaker drive to reanalyse a syntactic representation. Among younger adults, there was a tendency to blend two representations into a single interpretation, even if this was not licensed by the syntax.","Authors":"Malyutina, S (Malyutina, Svetlana) ; den Ouden, DB (den Ouden, Dirk-Bart)","Title":"What is it that lingers? Garden-path (mis)interpretations in younger and older adults"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000372102000005 PubMed ID: 25397360 ISSN: 1747-0218 eISSN: 1747-0226","Keywords":"Semantic persistence; Reanalysis; Non-native language processing; Garden-path recovery KeyWords Plus:SUBJECT-OBJECT AMBIGUITIES; REDUCED RELATIVE CLAUSE; LANGUAGE COMPREHENSION; SENTENCE COMPREHENSION; THEMATIC ROLES; EYE-MOVEMENTS; MAIN VERB; 2ND-LANGUAGE; RESOLUTION; LEARNERS","Categories":"Psychology; Physiology Web of Science Categories:Psychology, Biological; Physiology; Psychology; Psychology, Experimental","Journal Information":"QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY Volume: 69 Issue: 5 Pages: 907-925 Special Issue: SI DOI: 10.1080/17470218.2014.984231 Published: MAY 3 2016","Abstract":"We report the results from an eye-movement monitoring study investigating how native and non-native speakers of English process temporarily ambiguous sentences such as While the gentleman was eating the burgers were still being reheated in the microwave, in which an initially plausible direct-object analysis is first ruled out by a syntactic disambiguation (were) and also later on by semantic information (being reheated). Both participant groups showed garden-path effects at the syntactic disambiguation, with native speakers showing significantly stronger effects of ambiguity than non-native speakers in later eye-movement measures but equally strong effects in first-pass reading times. Ambiguity effects at the semantic disambiguation and in participants' end-of-trial responses revealed that for both participant groups, the incorrect direct-object analysis was frequently maintained beyond the syntactic disambiguation. The non-native group showed weaker reanalysis effects at the syntactic disambiguation and was more likely to misinterpret the experimental sentences than the native group. Our results suggest that native language (L1) and non-native language (L2) parsing are similar with regard to sensitivity to syntactic and semantic error signals, but different with regard to processes of reanalysis.","Authors":"Jacob, G (Jacob, Gunnar) ; Felser, C (Felser, Claudia)","Title":"Reanalysis and semantic persistence in native and non-native garden-path recovery"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000375789300002 ISSN: 0920-5691 eISSN: 1573-1405","Keywords":"Semantic segmentation; Facade parsing; Procedural modeling KeyWords Plus:SEGMENTATION; OPTIMIZATION; ARCHITECTURE; RECOGNITION","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"INTERNATIONAL JOURNAL OF COMPUTER VISION Volume: 118 Issue: 1 Pages: 22-48 DOI: 10.1007/s11263-015-0868-z Published: MAY 2016","Abstract":"We propose a novel approach for semantic segmentation of building facades. Our system consists of three distinct layers, representing different levels of abstraction in facade images: segments, objects and architectural elements. In the first layer, the facade is segmented into regions, each of which is assigned a probability distribution over semantic classes. We evaluate different state-of-the-art segmentation and classification strategies to obtain the initial probabilistic semantic labeling. In the second layer, we investigate the performance of different object detectors and show the benefit of using such detectors to improve our initial labeling. The generic approaches of the first two layers are then specialized for the task of facade labeling in the third layer. There, we incorporate additional meta-knowledge in the form of weak architectural principles, which enforces architectural plausibility and consistency on the final reconstruction. Rigorous tests performed on two existing datasets of building facades demonstrate that we outperform the current state of the art, even when using outputs from lower layers of the pipeline. Finally, we demonstrate how the output of the highest layer can be used to create a procedural building reconstruction.","Authors":"Mathias, M (Mathias, Markus) ; Martinovic, A (Martinovic, Andelo) ; Van Gool, L (Van Gool, Luc)","Title":"ATLAS: A Three-Layered Approach to Facade Parsing"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000374474300008 ISSN: 2330-1635 eISSN: 2330-1643","Keywords":"natural language processing; text mining; semantic analysis KeyWords Plus:ORGANIZATION SYSTEMS; CLASSIFICATION; ANNOTATION","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY Volume: 67 Issue: 5 Pages: 1138-1152 DOI: 10.1002/asi.23485 Published: MAY 2016","Abstract":"The article presents a method for automatic semantic indexing of archaeological grey-literature reports using empirical (rule-based) Information Extraction techniques in combination with domain-specific knowledge organization systems. The semantic annotation system (OPTIMA) performs the tasks of Named Entity Recognition, Relation Extraction, Negation Detection, and Word-Sense Disambiguation using hand-crafted rules and terminological resources for associating contextual abstractions with classes of the standard ontology CIDOC Conceptual Reference Model (CRM) for cultural heritage and its archaeological extension, CRM-EH. Relation Extraction (RE) performance benefits from a syntactic-based definition of RE patterns derived from domain oriented corpus analysis. The evaluation also shows clear benefit in the use of assistive natural language processing (NLP) modules relating to Word-Sense Disambiguation, Negation Detection, and Noun Phrase Validation, together with controlled thesaurus expansion. The semantic indexing results demonstrate the capacity of rule-based Information Extraction techniques to deliver interoperable semantic abstractions (semantic annotations) with respect to the CIDOC CRM and archaeological thesauri. Major contributions include recognition of relevant entities using shallow parsing NLP techniques driven by a complimentary use of ontological and terminological domain resources and empirical derivation of context-driven RE rules for the recognition of semantic relationships from phrases of unstructured text.","Authors":"Vlachidis, A (Vlachidis, Andreas) ; Tudhope, D (Tudhope, Douglas)","Title":"A knowledge-based approach to Information Extraction for semantic interoperability in the archaeology domain"}, {"Categories":"Gastroenterology & Hepatology Web of Science Categories:Gastroenterology & Hepatology","Journal Information":"GASTROENTEROLOGY Volume: 150 Issue: 4 Pages: S433-S433 Supplement: 1 Meeting Abstract: Sa2026 Published: APR 2016","Abstract":"Document Information Document Type:Meeting Language:English Accession Number: WOS:000391764900451 ISSN: 0016-5085 eISSN: 1528-0012","Authors":"Metwally, ON (Metwally, Omar N.); Sinha, SR (Sinha, Sidhartha R.)","Title":"A Novel Voice-Activated Web Application for Rapid Knowledge Generation and Information Retrieval Through Semantic Parsing of Verbal Communication"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000371615600001 ISSN: 2095-2228 eISSN: 2095-2236","Keywords":"dialogue management; domain extension; evolvable dialogue state tracking; parser; tracker KeyWords Plus:SYSTEMS","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods","Journal Information":"FRONTIERS OF COMPUTER SCIENCE Volume: 10 Issue: 2 Pages: 201-215 DOI: 10.1007/s11704-015-5209-4 Published: APR 2016","Abstract":"Statistical dialogue management is the core of cognitive spoken dialogue systems (SDS) and has attracted great research interest. In recent years, SDS with the ability of evolution is of particular interest and becomes the cuttingedge of SDS research. Dialogue state tracking (DST) is a process to estimate the distribution of the dialogue states at each dialogue turn, given the previous interaction history. It plays an important role in statistical dialogue management. To provide a common testbed for advancing the research of DST, international DST challenges (DSTC) have been organised and well-attended by major SDS groups in the world. This paper reviews recent progresses on rule-based and statistical approaches during the challenges. In particular, this paper is focused on evolvable DST approaches for dialogue domain extension. The two primary aspects for evolution, semantic parsing and tracker, are discussed. Semantic enhancement and a DST framework which bridges rule-based and statistical models are introduced in detail. By effectively incorporating prior knowledge of dialogue state transition and the ability of being data-driven, the new framework supports reliable domain extension with little data and can continuously improve with more data available. Thismakes it excellent candidate for DST evolution. Experiments show that the evolvable DST approaches can achieve the state-of-the-art performance and outperform all previously submitted trackers in the third DSTC.","Authors":"Yu, K (Yu, Kai) ; Chen, L (Chen, Lu) ; Sun, K (Sun, Kai) ; Xie, QZ (Xie, Qizhe) ; Zhu, S (Zhu, Su)","Title":"Evolvable dialogue state tracking for statistical dialogue management"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000371758500001 PubMed ID: 27014107 ISSN: 1664-1078","Keywords":"focus; semantics; marked stress; prosody; incremental language processing; eye tracking; visual world paradigm; anticipatory eye movements and predictions KeyWords Plus:RELATIVE CLAUSE SENTENCES; COMPREHENSION; AMBIGUITIES","Categories":"Psychology Web of Science Categories:Psychology, Multidisciplinary","Journal Information":"FRONTIERS IN PSYCHOLOGY Volume: 7 Article Number: 150 DOI: 10.3389/fpsyg.2016.00150 Published: MAR 11 2016","Abstract":"In three visual-world eye tracking studies, we investigated the processing of sentences containing the focus-sensitive operator alleen 'only' and different pitch accents, such as the Dutch Ik heb alleen SELDERIJ aan de brandweerman gegeven 'I only gave CELERY to the fireman' versus Ik heb alleen selderij aan de BRANDWEERMAN gegeven 'I only gave celery to the FIREMAN'. Dutch, like English, allows accent shift to express different focus possibilities. Participants judged whether these utterances match different pictures: in Experiment 1 the Early Stress utterance matched the picture, in Experiment 2 both the Early and Late Stress utterance did, and in Experiment 3 neither did. We found that eye-gaze patterns start to diverge across the conditions already as the indirect object is being heard. Our data also indicate that participants perform anticipatory eye-movements based on the presence of prosodic focus during auditory sentence processing. Our investigation is the first to report the effect of varied prosodic accent placement on different arguments in sentences with a semantic operator, alleen 'only', on the time course of looks in the visual world paradigm. Using an operator in the visual world paradigm allowed us to confirm that prosodic focus information immediately gets integrated into the semantic parse of the proposition. Our study thus provides further evidence for fast, incremental prosodic focus processing in natural language.","Authors":"Mulders, I (Mulders, Iris) ; Szendroj, K (Szendroj, Kriszta)","Title":"Early Association of Prosodic Focus with alleen 'only': Evidence from Eye Movements in the Visual-World Paradigm"}, {"Document Information":"Document Type:Article; Proceedings Paper Language:English Accession Number: WOS:000372579300006 ISSN: 0167-8655 eISSN: 1872-7344","Keywords":"Pattern theory; Graphical methods; Compositional approach; Video interpretation; Activity recognition KeyWords Plus:RECOGNITION","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"PATTERN RECOGNITION LETTERS Volume: 72 Pages: 41-51 Special Issue: SI DOI: 10.1016/j.patrec.2016.01.028 Published: MAR 1 2016","Abstract":"We develop a combinatorial approach to represent and infer semantic interpretations of video contents using tools from Grenander's pattern theory. Semantic structures for video interpretation are formed using generators and bonds, the fundamental units of representation in pattern theory. Generators represent features and ontological items, such as actions and objects, whereas bonds are threads used to connect generators while respecting appropriate constraints. The resulting configurations of partially-connected generators are termed scene interpretations. Our goal is to parse a given video data set into high-probability configurations. The probabilistic models are imposed using energies that have contributions from both data (classification scores) and prior information (ontological constraints, co-occurrence frequencies, etc). The search for optimal configurations is based on an MCMC, simulated-annealing algorithm that uses simple moves to propose configuration changes and to accept/reject them according to the posterior energy. In contrast to current graphical methods, this framework does not preselect a neighborhood structure but tries to infer it from the data. The proposed framework is able to obtain 20% higher classification rates, compared to a purely machine learning-based baseline, despite artificial insertion of low-level processing errors. In an uncontrolled scenario, video interpretation performance rates are found to be double that of the baseline. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"de Souza, FDM (de Souza, Fillipe D. M.) ; Sarkar, S (Sarkar, Sudeep) ; Srivastava, A (Srivastava, Anuj) ; Su, JY (Su, Jingyong)","Title":"Pattern theory for representation and inference of semantic structures in videos"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000371156500001 ISSN: 0920-5691 eISSN: 1573-1405","Keywords":"Scene parsing; Graphical models; Geometric reasoning; Structured learning KeyWords Plus:GRAPH CUTS; OBJECT RECOGNITION; SEGMENTATION; FEATURES; SCALE; TEXTURE","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"INTERNATIONAL JOURNAL OF COMPUTER VISION Volume: 117 Issue: 1 Pages: 1-20 DOI: 10.1007/s11263-015-0843-8 Published: MAR 2016","Abstract":"Inexpensive structured light sensors can capture rich information from indoor scenes, and scene labeling problems provide a compelling opportunity to make use of this information. In this paper we present a novel conditional random field (CRF) model to effectively utilize depth information for semantic labeling of indoor scenes. At the core of the model, we propose a novel and efficient plane detection algorithm which is robust to erroneous depthmaps. Our CRF formulation defines local, pairwise and higher order interactions between image pixels. At the local level, we propose a novel scheme to combine energies derived from appearance, depth and geometry-based cues. The proposed local energy also encodes the location of each object class by considering the approximate geometry of a scene. For the pairwise interactions, we learn a boundary measure which defines the spatial discontinuity of object classes across an image. To model higher-order interactions, the proposed energy treats smooth surfaces as cliques and encourages all the pixels on a surface to take the same label. We show that the proposed higher-order energies can be decomposed into pairwise submodular energies and efficient inference can be made using the graph-cuts algorithm. We follow a systematic approach which uses structured learning to fine-tune the model parameters. We rigorously test our approach on SUN3D and both versions of the NYU-Depth database. Experimental results show that our work achieves superior performance to state-of-the-art scene labeling techniques.","Authors":"Khan, SH (Khan, Salman H.) ; Bennamoun, M (Bennamoun, Mohammed) ; Sohel, F (Sohel, Ferdous) ; Togneri, R (Togneri, Roberto) ; Naseem, I (Naseem, Imran) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Sohel, Ferdous  C-2428-2013 http://orcid.org/0000-0003-1557-4907","Title":"Integrating Geometrical Context for Semantic Labeling of Indoor Scenes using RGBD Images"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000369776200016 ISSN: 1077-3142 eISSN: 1090-235X","Keywords":"Image parsing; Semantic segmentation; Scene understanding; Objectness KeyWords Plus:ENERGY MINIMIZATION; GRAPH CUTS; VISION","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic","Journal Information":"COMPUTER VISION AND IMAGE UNDERSTANDING Volume: 143 Pages: 191-200 DOI: 10.1016/j.cviu.2015.08.009 Published: FEB 2016","Abstract":"Scene parsing is the task of labeling every pixel in an image with its semantic category. We present CollageParsing, a nonparametric scene parsing algorithm that performs label transfer by matching content adaptive windows. Content-adaptive windows provide a higher level of perceptual organization than superpixels, and unlike superpixels are designed to preserve entire objects instead of fragmenting them. Performing label transfer using content-adaptive windows enables the construction of a more effective Markov random field unary potential than previous approaches. On a standard benchmark consisting of outdoor scenes from the LabelMe database, CollageParsing obtains state-of-the-art performance with 15-19% higher average per-class accuracy than recent nonparametric scene parsing algorithms. (C) 2015 Elsevier Inc. All rights reserved.","Authors":"Tung, F (Tung, Frederick) ; Little, JJ (Little, James J.)","Title":"Scene parsing by nonparametric label transfer of content-adaptive windows"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000368582400015 PubMed ID: 25801451 ISSN: 1747-0218 eISSN: 1747-0226","Keywords":"Suffix priming; Masked priming; Morphological processing; Suffixed words; Pseudosuffixed words; Semantics KeyWords Plus:VISUAL WORD RECOGNITION; MORPHOLOGICAL DECOMPOSITION; BRAIN POTENTIALS; PREFIXES; NOUNS; ERP","Categories":"Psychology; Physiology Web of Science Categories:Psychology, Biological; Physiology; Psychology; Psychology, Experimental","Journal Information":"QUARTERLY JOURNAL OF EXPERIMENTAL PSYCHOLOGY Volume: 69 Issue: 1 Pages: 197-208 DOI: 10.1080/17470218.2015.1031146 Published: JAN 2 2016","Abstract":"This work presents the results of a masked lexical decision experiment in which we explore the morphological parsing of Spanish suffixed or pseudosuffixed words through the suffix priming effect. Priming the bases or pseudobases with their suffixed or pseudosuffixed forms is the standard process in experiments aimed at understanding the processes underlying morphological parsing in visual word recognition with masked priming lexical decision (e.g., darkness-DARK; corner-CORN). We, however, compare the effect of suffix priming on the lexical decision of suffixed (ero-JORNALERO) and pseudosuffixed words (ero-CORDERO), as well as the effect of orthographic priming on nonsuffixed words (eba-PRUEBA). The results show that in the case of suffixed and pseudosuffixed words, related primes (ero-JORNALERO; ero-CORDERO) significantly accelerated response latencies in comparison to unrelated primes (ista-JORNALERO; ura-CORDERO), while for simple words there was no facilitation from the orthographically related prime in comparison to the unrelated prime (eba-PRUEBA; afo-PRUEBA). These results are consistent with the so-called morpho-orthographic segmentation process in the course of visual word recognition, which might also be independent of orthographic and purely semantic factors. Our results also support the view that morphological parsing takes place regardless of whether a stem is present in a word. These results complement findings from studies dealing with CORNER- and BROTHEL-like stimuli.","Authors":"Lazaro, M (Lazaro, Miguel) ; Illera, V (Illera, Victor) ; Sainz, J (Sainz, Javier) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Lazaro Lopez-Villasenor, Miguel  http://orcid.org/0000-0001-8073-3957","Title":"The suffix priming effect: Further evidence for an early morpho-orthographic segmentation process independent of its semantic content"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390179300004 ISBN:978-3-319-47955-2; 978-3-319-47954-5 ISSN: 0302-9743","Keywords":"Semantic web services; Automatic discovery; Ontology axioms","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"ADVANCES IN ARTIFICIAL INTELLIGENCE - IBERAMIA 2016 Book Series: Lecture Notes in Artificial Intelligence Volume: 10022 Pages: 37-48 DOI: 10.1007/978-3-319-47955-2_4 Published: 2016","Abstract":"In this paper we describe the process by which semantic relatedness assertions are discovered and defined between Web service operations. The general approach relies on a global ontology model that describes Web services. Obtaining semantic similarities between operations is performed by calculating eight semantic relatedness measures between all operations pairs. The entire process consists of: Web service parsing, Web service data extraction, automatic Web service ontology population, similarity measures calculation, similarity discovery; and finally, object property assertion between web service operations.","Authors":"Bravo, M (Bravo, Maricela) ; Reyes-Ortiz, JA (Reyes-Ortiz, Jose A.) ; Alcantara-Ramirez, R (Alcantara-Ramirez, Roberto) ; Sanchez, L (Sanchez, Leonardo) Edited by:MontesYGomez, M; Escalante, HJ; Segura, A; Murillo, JD","Title":"Semantic Enrichment of Web Service Operations"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389797400035 ISBN:978-3-319-49130-1; 978-3-319-49129-5 ISSN: 0302-9743","Keywords":"Spoken language understanding; Automatic interpretation of robotic commands; Grounded language learning; Human robot interaction KeyWords Plus:SYMBOL GROUNDING PROBLEM","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"AI*IA 2016: ADVANCES IN ARTIFICIAL INTELLIGENCE Book Series: Lecture Notes in Computer Science Volume: 10037 Pages: 477-489 DOI: 10.1007/978-3-319-49130-1_35 Published: 2016","Abstract":"Robots operate in specific environments and the correct interpretation of linguistic interactions depends on physical, cognitive and language-dependent aspects triggered by the environment. In this work, we describe a Spoken Language Understanding chain for the semantic parsing of robotic commands, designed according to a Client/Server architecture. This work also reports a first evaluation of the proposed architecture in the automatic interpretation of commands expressed in Italian for a robot in a Service Robotics domain. The experimental results show that the proposed solution can be easily extended to other languages for a robust Spoken Language Understanding in Human-Robot Interaction.","Authors":"Vanzo, A (Vanzo, Andrea) ; Croce, D (Croce, Danilo) ; Castellucci, G (Castellucci, Giuseppe) ; Basili, R (Basili, Roberto) ; Nardi, D (Nardi, Daniele) Edited by:Adorni, G; Cagnoni, S; Gori, M; Maratea, M","Title":"Spoken Language Understanding for Service Robotics in Italian"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000393168500130 ISBN:978-1-5090-1666-2","Keywords":"Information Retrieval; Natural Language Processing; Ontology; Query Parsing; Stop Words","Categories":"Automation & Control Systems; Computer Science; Telecommunications Web of Science Categories:Automation & Control Systems; Computer Science, Theory & Methods; Telecommunications","Journal Information":"2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA) Pages: 704-710 Published: 2016","Abstract":"Being such a vast resource of information, World Wide Web has become irreplaceable but the outburst of information available over the internet has made web search a time consuming and a very complex process. Now days if someone need to retrieve any information using internet they come across huge number of web pages because of large amount of data on web. It becomes difficult task to find information so in order to retrieve meaningful and intelligent information we have many information retrieval (IR) techniques. To gather the significant information from such a vast available resource Information Retrieval (IR); a method of retrieving such information resources which are relevant to an information need is applied. This paper would review few of these methods for intelligent information retrieval systems on web based on the Ontology information retrieval techniques.","Authors":"Sahu, SK (Sahu, Sanjib Kumar) ; Mahapatra, P (Mahapatra, P.) ; Balabantaray, RC (Balabantaray, R. C.) Edited by:Astya, PN; Swaroop, A; Sharma, V; Singh, M","Title":"Analytical Study on Intelligent Information Retrieval System Using Semantic Network"}, {"Categories":"Computer Science; Medical Informatics Web of Science Categories:Computer Science, Interdisciplinary Applications; Medical Informatics","Journal Information":"2016 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE (BIBM) Book Series: IEEE International Conference on Bioinformatics and Biomedicine-BIBM Pages: 946-952 Published: 2016","Abstract":"This work focuses on the extraction of allergic drug reactions in electronic health records. The goal is to annotate a sub-class of cause-effect events, those in which drugs are causing allergies. Little work has carried out in this field, seldom for Spanish clinical text mining, which is, indeed, the aim of this work. We present two approaches: a rule-based method and another one based on machine learning. Both approaches incorporate semantic knowledge derived from FreeLing-Med, a software explicitly developed to parse texts in the medical domain. Having recognised the medical entities for a given record, the challenge stands on triggering the underlying allergies. To this end, the knowledge is expressed as a set of semantic, syntactic and structural features. Our best system, based on machine learning, obtained a precision of 0.90 with a recall of 0.87, outperforming a rule-based approach.","Authors":"Casillas, A (Casillas, Arantza) ; Gojenola, K (Gojenola, Koldo) ; Perez, A (Perez, Alicia) ; Oronoz, M (Oronoz, Maite) Edited by:Tian, T; Jiang, Q; Liu, Y; Burrage, K; Song, J; Wang, Y; Hu, X; Morishita, S; Zhu, Q; Wang, G","Title":"Clinical text mining for efficient extraction of drug-allergy reactions"}, {"Keywords":"CRP; Semantic Dependency Parsing; Dependency Parsing; Part-of-speech Tagging; Word Segmentation; Evaluation Object","Categories":"Automation & Control Systems; Engineering; Robotics Web of Science Categories:Automation & Control Systems; Engineering, Electrical & Electronic; Robotics","Journal Information":"PROCEEDINGS OF 2016 8TH INTERNATIONAL CONFERENCE ON MODELLING, IDENTIFICATION & CONTROL (ICMIC 2016) Pages: 434-438 Published: 2016","Abstract":"As a newly shopping tool, electronic commerce has been drawing more and more attention of researchers. According to the characteristics of comments diversity, it is necessary to extract evaluation object which is an important component of sentiment information. This paper explores Conditional Random Field (CRF) to do evaluation objects extraction. After observing generally used features in sentiment extraction, this paper conclude all the features into four categories, i.e. word Segmentation, Part-of-speech Tagging (POS), Dependency Parsing, Semantic Dependency Parsing. What's more, focusing on the introduction of new feature semantic dependency is a very vital item in our research. In the experiment, we examine the various features and combinations in the extraction task performance, and make a detailed comparative study. The experimental results confirm that adding the feature of semantic dependency has better performance in terms of the evaluation object extraction.","Authors":"Gao, K (Gao, Kai) ; Zhang, SS (Zhang, Shan-shan) ; Su, S (Su, Shu) ; Li, M (Li, Mei) Book Group Author(s):IEEE","Title":"Modeling on Evaluation Object Extraction in E-commerce Corpus based on Semantic Feature"}, {"Keywords":"hyponymy relation; \"is a\" pattern; lexical analysis; dependency parsing","Categories":"Automation & Control Systems; Engineering; Robotics Web of Science Categories:Automation & Control Systems; Engineering, Electrical & Electronic; Robotics","Journal Information":"PROCEEDINGS OF 2016 8TH INTERNATIONAL CONFERENCE ON MODELLING, IDENTIFICATION & CONTROL (ICMIC 2016) Pages: 439-443 Published: 2016","Abstract":"More and more electric power data are generated with the development of the electric power field. Hyponymy relationships extraction is an important task in building semantic knowledge base, information retrieval and other semantic applications etc. This paper uses sentences to match \"is a\" pattern as research subjects and proposes a novel hyponymy relation extraction approach, which combines lexical analysis and dependency parsing. In order to better complete experiment of the proposed method, the electric power field corpus is processed in this paper and more normative corpus are obtained. Some hyponymy relationships are obtained from the electric power concepts with proposed method. The experiment results confirm that the proposed approach of this paper has better performance in the process of relationship extraction.","Authors":"Ruan, DR (Ruan, Dong-ru) ; He, XY (He, Xiao-yi) ; Li, DY (Li, Dan-yang) ; Gao, K (Gao, Kai) Book Group Author(s):IEEE","Title":"Modeling and Extracting Hyponymy Relationships on Chinese Electric Power Field Content"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000392625500114 ISBN:978-1-5090-4069-8 ISSN: 2473-8565","Keywords":"Machine interpreter system; syntax construction; semantic analyses; sign language; Russian language","Categories":"Engineering; Instruments & Instrumentation Web of Science Categories:Engineering, Electrical & Electronic; Instruments & Instrumentation","Journal Information":"2016 13TH INTERNATIONAL SCIENTIFIC-TECHNICAL CONFERENCE ON ACTUAL PROBLEMS OF ELECTRONIC INSTRUMENT ENGINEERING (APEIE), VOL 2 Book Series: International Conference on Actual Problems of Electronic Instrument Engineering Pages: 498-501 Published: 2016","Abstract":"In this paper the existing systems of translation into sign language are analyzed. There are ViSiCAST project, Zardoz system, ASL Workbench, TEAM system. Their strengths and weaknesses are identified. A new translation way based on a comparison of syntactic constructions is described. Sentences in sounding language often describe complex situations, including some simple situations (for example, a few actions). The unit, which is processed about, is a proposal for a full participle. As a result of comparison of syntactic constructions is obtained a set of simple sentences in which all participles replace verb. A corresponding library to determine the syntax construction is developed. A new method for constructing a semantic unit of the computer system of sign language is proposed. The result of semantic analysis system is a list of correspondence \"word-gesture\". Among the many alternatives of words based on semantic analysis algorithm, every word is assigned a unique lexical meaning. For simple sentences algorithms of semantic analysis are designed and implemented. The most priority directions of modification module semantic analysis may include the following: broadening the base of gesture, the implementation of parsing complex sentences, taking into account specifics of the Russian-language.","Authors":"Grif, MG (Grif, Mikhail G.) ; Manueva, JS (Manueva, Julia S.) Book Group Author(s):IEEE","Title":"Russian Sign Language Machine Interpreter System Based on the Analyses of Syntax and Semantic Construction"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000392503100082 ISBN:978-1-5090-2028-7","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Telecommunications","Journal Information":"2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI) Pages: 519-523 Published: 2016","Abstract":"Evaluating an essay automatically has been an area of active research even though there has been a shift to multiple choice answers in many competitive exams. In this paper, we propose an unsupervised technique to rank essays based on the structural and semantic content of the essays. The approach is unsupervised because it makes use of a the complete set of essays to determine the rank of the an individual essay. We purposely avoid deep parsing and the approach is based on use of both structural features of the essay and also the semantic content of the essay. We evaluate the proposed approach on a set of essays submitted to a competition generated from a single prompt. We compare the ranks of the essays with the ranks given by two different human evaluators. The results show a good correlation between the proposed unsupervised algorithm and the human evaluators. The proposed approach, as designed, is independent. of any external knowledge base.","Authors":"Kopparapu, SK (Kopparapu, Sunil Kumar) ; De, A (De, Arijit) Edited by:Wu, J; Perez, GM; Thampi, SM; Atiquzzaman, M; Berretti, S; Rodrigues, JJPC; Tomar, R; Gorthi, RP; Siarry, P; Pathan, AK; Li, J; Bedi, P; Mehta, S; Kammoun, MH; Jain, V","Title":"Automatic Ranking of Essays using Structural and Semantic Features"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000391925900032 ISBN:978-1-5090-4134-3","Categories":"Computer Science; Mathematical & Computational Biology Web of Science Categories:Computer Science, Artificial Intelligence; Mathematical & Computational Biology","Journal Information":"2016 IEEE RIVF INTERNATIONAL CONFERENCE ON COMPUTING & COMMUNICATION TECHNOLOGIES, RESEARCH, INNOVATION, AND VISION FOR THE FUTURE (RIVF) Pages: 187-192 Published: 2016","Abstract":"Lexicon is an important resource in natural language processing (NLP), as it provides NLP systems with lexical information at different levels, from morphology to semantics. For Vietnamese, lexical resources are available for several basic tools such as word segmentation, part-of-speech tagging and syntactic parsing. In this paper, we discuss the construction of a lexicon enriched with syntactic and semantic information, based on an existing computational lexicon for Vietnamese. This lexicon is desigued to serve for a syntactic and semantic parser using the tree adjoining grammar (TAG) formalism.","Authors":"Nguyen, TH (Thi Huyen Nguyen) ; Nguyen, TMH (Thi Minh Huyen Nguyen) ; Ngo, TQ (The Quyen Ngo) ; Nguyen, MH (Minh Hai Nguyen) Edited by:Cao, T; Ho, YS","Title":"Towards a syntactically and semantically enriched lexicon for Vietnamese processing"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000391273400234 ISBN:978-0-9964-5274-8","Keywords":"3D lidar; vision; scene parsing; road boundary estimation","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2016 19TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION) Pages: 1760-1767 Published: 2016","Abstract":"This paper describes a perception system which fuses the output from a 3D lidar pointcloud classifier and an image scene parser to create a semantic 2D map of a rural, unstructured environment. This map is subsequently used to generate the dirt road boundary measurements, which are then fed into a particle filter to robustly track the dirt road boundaries in real time. A local road following reference path can be computed from the estimated road boundaries, which when combined with the semantic 2D map, can enable the robot to navigate in GPS challenged environments. The performance of the system is evaluated and verified through extensive experiments conducted out-field.","Authors":"Yeo, YC (Yeo, Yechuan) ; Xiao, XH (Xiao, Xuhong) ; Zhang, XH (Zhang, Xinghu) Book Group Author(s):IEEE","Title":"Rural scene parsing and road boundary estimation by fusion of Lidar pointcloud and EO images"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000391002500145 ISBN:978-1-5090-4065-0","Keywords":"electronic documents; screen-based reading; information extraction; semantic analysis KeyWords Plus:INFORMATION EXTRACTION","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"2016 IEEE 14TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 14TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 2ND INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/DATACOM/CYBERSC Pages: 927-932 DOI: 10.1109/DASC-PICom-DataCom-CyberSciTec.2016.167 Published: 2016","Abstract":"With an increasing amount of electronic documents, screen-based reading becomes popular, how to improve the ability of reading deeply and sustaining a prolonged engagement in reading is one of challenges in a digital environment. In this paper, we describe a semantic analysis framework for proactively decreasing fragmented time while screen-based reading. The central idea is to utilize semantic analysis programs to extract an extensive set of information that describes keyword spotting. And the auxiliary knowledge can be used for deeply reading. We discuss the strengths of our semantic analysis programs, namely, text extraction, name recognition, feature matching and knowledge map analysis. We report our results of applying these programs to parse scientific literature, such as citation recognition, the author name recognition, reference extraction and etc. The experimental results show that proposed approach can greatly decrease the fragmented time while reading in the digital environment.","Authors":"Zhong, HZ (Zhong, Huizhong) ; Li, SF (Li, Shaofeng) ; Zhao, F (Zhao, Feng) ; Jin, H (Jin, Hai) ; Zhang, Q (Zhang, Qin) Edited by:Wang, KIK; Jin, Q; Zhang, Q; Bhuiyan, MZA; Hsu, CH","Title":"A Semantic-based Approach to Building Auxiliary System for Screen-based Reading"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000391111000022 ISBN:978-989-758-203-5","Keywords":"Audio; Speech; Summarization; Tokenization; Speech Recognition; Latent Semantic Indexing KeyWords Plus:SEGMENTATION","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"KDIR: PROCEEDINGS OF THE 8TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT - VOL. 1 Pages: 221-227 DOI: 10.5220/0006044802210227 Published: 2016","Abstract":"This paper addresses speech summarization of highly spontaneous speech. The audio signal is transcribed using an Automatic Speech Recognizer, which operates at relatively high word error rates due to the complexity of the recognition task and high spontaneity of speech. An analysis is carried out to assess the propagation of speech recognition errors into syntactic parsing. We also propose an automatic, speech prosody based audio tokenization approach and compare it to human performance. The so obtained sentence-like tokens are analysed by the syntactic parser to help ranking based on thematic terms and sentence position. The thematic term is expressed in two ways: TF-IDF and Latent Semantic Indexing. The sentence scores are calculated as a linear combination of the thematic term score and a positional score. The summary is generated from the top 10 candidates. Results show that prosody based tokenization reaches human average performance and that speech recognition errors propagate moderately into syntactic parsing (POS tagging and dependency parsing). Nouns prove to be quite error resistant. Audio summarization shows 0.62 recall and 0.79 precision by an F-measure of 0.68, compared to human reference. A subjective test is also carried out on a Likert-scale. All results apply to spontaneous Hungarian.","Authors":"Szaszak, G (Szaszak, Gyorgy) ; Tundik, MA (Tundik, Mate Akos) ; Beke, A (Beke, Andras) Edited by:Fred, A; Dietz, J; Aveiro, D; Liu, K; Bernardino, J; Filipe, J","Title":"Summarization of Spontaneous Speech using Automatic Speech Recognition and a Speech Prosody based Tokenizer"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000391112200006 ISBN:978-989-758-203-5","Keywords":"Semantic Analysis; Semantic Network; Semantic Web; Natural Language Processing; Wiktionary; Russian Language","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"KEOD: PROCEEDINGS OF THE 8TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE DISCOVERY, KNOWLEDGE ENGINEERING AND KNOWLEDGE MANAGEMENT - VOL. 2 Pages: 74-80 DOI: 10.5220/0006038900740080 Published: 2016","Abstract":"There were several attempts to retrieve semantic relations from free, online Wiktionary for Russian language. Previous works combine automatic parsing of wiki snapshot with experts' assistance. Our main goal is to create machine readable lexical ontology from Russian Wiktionary, maximally close to its online state. This article provides approach to automatic creation of explicit and implicit semantic relations between words (lexemes) and meanings (senses) to provide exact relations from sense to sense. Explicit semantic relations are constructed comparatively easy. For example, if the lexeme contains single sense, then all relations that point to the lexeme will point to this single sense. Reconstruction of implicit relations relies on logical conclusions from already created explicit ones. Several algorithms for implicit semantic links were developed and tested on Russian Wiktionary. There were parsed more than 550000 online pages, containing about 250000 Russian lexemes with about 500000 senses in them, but only about 20% of these senses were linked with at least one external lexeme. About 47% of explicitly existing links were resolved as \"sense-to-sense\" relations and about 28% of new implicit \"sense-to-sense\" links were reconstructed. 53% of lexemes' references could not be resolved to exact sense.","Authors":"Klimenkov, S (Klimenkov, Serge) ; Tsopa, E (Tsopa, Evgenij) ; Pismak, A (Pismak, Alexey) ; Yarkeev, A (Yarkeev, Alexander) Edited by:Fred, A; Dietz, J; Aveiro, D; Liu, K; Bernardino, J; Filipe, J","Title":"Reconstruction of Implied Semantic Relations in Russian Wiktionary"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000391012700040 ISSN: 2194-9034","Keywords":"Weighted Attribute Grammar; Parse Tree; Incremental Parser; Kernel Density Estimation; 3D Building Models; UAV KeyWords Plus:RECONSTRUCTION; RULES","Categories":"Computer Science; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology Web of Science Categories:Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology","Journal Information":"XXIII ISPRS CONGRESS, COMMISSION III Book Series: International Archives of the Photogrammetry Remote Sensing and Spatial Information Sciences Volume: 3 Issue: 3 Pages: 311-316 DOI: 10.5194/isprsannals-III-3-311-2016 Published: 2016","Abstract":"Data acquisition using unmanned aerial vehicles (UAVs) has gotten more and more attention over the last years. Especially in the field of building reconstruction the incremental interpretation of such data is a demanding task. In this context formal grammars play an important role for the top-down identification and reconstruction of building objects. Up to now, the available approaches expect offline data in order to parse an a-priori known grammar. For mapping on demand an on the fly reconstruction based on UAV data is required. An incremental interpretation of the data stream is inevitable. This paper presents an incremental parser of grammar rules for an automatic 3D building reconstruction. The parser enables a model refinement based on new observations with respect to a weighted attribute context-free grammar (WACFG). The falsification or rejection of hypotheses is supported as well. The parser can deal with and adapt available parse trees acquired from previous interpretations or predictions. Parse trees derived so far are updated in an iterative way using transformation rules. A diagnostic step searches for mismatches between current and new nodes. Prior knowledge on fac, ades is incorporated. It is given by probability densities as well as architectural patterns. Since we cannot always assume normal distributions, the derivation of location and shape parameters of building objects is based on a kernel density estimation (KDE). While the level of detail is continuously improved, the geometrical, semantic and topological consistency is ensured.","Authors":"Dehbi, Y (Dehbi, Y.) ; Staat, C (Staat, C.) ; Mandtler, L (Mandtler, L.) ; Plumer, L (Pluemer, L.) Edited by:Halounova, L; Schindler, K; Limpouch, A; Pajdla, T; Safar, V; Mayer, H; Elberink, SO; Mallet, C; Rottensteiner, F; Bredif, M; Skaloud, J; Stilla, U","Title":"INCREMENTAL REFINEMENT OF FACADE MODELS WITH ATTRIBUTE GRAMMAR FROM 3D POINT CLOUDS"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390782001072 ISBN:978-1-4673-9961-6 ISSN: 1522-4880","Keywords":"Superpixel embedding; Image semantic parsing; Unary potential; Context feature KeyWords Plus:IMAGE; FEATURES","Categories":"Engineering; Imaging Science & Photographic Technology Web of Science Categories:Engineering, Electrical & Electronic; Imaging Science & Photographic Technology","Journal Information":"2016 IEEE INTERNATIONAL CONFERENCE ON IMAGE PROCESSING (ICIP) Book Series: IEEE International Conference on Image Processing ICIP Pages: 1269-1273 Published: 2016","Abstract":"In this paper, we propose to use contexts of superpixels as a prior to improve semantic segmentation by the CRF framework. A graphical model is constructed on over-segmented images. Our main contribution is to take the concept of \"superpixel embedding\" into consideration, which is formalized as a potential item for optimizing the energy of the whole graph. We also introduce two ways of calculating this embedding potential. Experiments on several popular datasets, e.g., MRSC-21 and PASCAL VOC, illustrate that our approach enhances the performance of a previously proposed segmentation model without embedding. The accuracy results are comparable to some fully supervised methods.","Authors":"Xing, FZ (Xing, Frank Z.) ; Cambria, E (Cambria, Erik) ; Huang, WB (Huang, Win-Bin) ; Xu, Y (Xu, Yang) Book Group Author(s):IEEE","Title":"WEAKLY SUPERVISED SEMANTIC SEGMENTATION WITH SUPERPIXEL EMBEDDING"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390843000020 ISBN:978-1-60595-348-9","Categories":"Engineering Web of Science Categories:Engineering, Multidisciplinary","Journal Information":"2016 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING, INFORMATION SCIENCE AND INTERNET TECHNOLOGY (CII 2016) Pages: 119-124 Published: 2016","Abstract":"Aiming at the biomedical domain, we construct a biomedical proposition corpus based on dependency parsing on the basis of the GENIA corpus. The corpus divided into training set and testing set, we use the maximum entropy classifier in the semantic role labeling system. All experiments are conducted using four-fold cross validation on the proposition corpus. This system achieves the best F1 score of 84.95% and shows that it has the same performance as other similar experiments.","Authors":"Han, L (Han, Lei) ; Ji, DH (Ji, Donghong) ; Ren, H (Ren, Han) Book Group Author(s):DEStech Publicat, Inc","Title":"Semantic Role Labeling for Biomedical Corpus Based on Dependency Parsing"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390840000002 ISBN:978-3-11-044353-0; 978-3-11-044311-0 ISSN: 1434-3452","Categories":"Linguistics Web of Science Categories:Linguistics; Language & Linguistics","Journal Information":"RE-ASSESSING THE PRESENT PERFECT Book Series: Topics in English Linguistics Volume: 91 Pages: 23-41 Published: 2016","Abstract":"The development of the have-perfect is often given as a prime example of a grammaticalization path. The generally accepted account of the development of the English [have + past participle] construction is that it changed from a possessive-resultative construction into a temporal-aspectual construction with perfect-anterior meaning at some time in the Old English period. This study seeks to test the hypothesis that a semantic shift from resultative to perfect-anterior meaning can be observed in early English data. It is based on corpus data from the York-Toronto-Helsinki Parsed Corpus of Old English Prose. All instances of [haebb-+ past participle] are categorized according to their meaning, and implications for possible source structures of the have-perfect are discussed. Finally, a look on Present-Day English helps to sound a note of caution on drawing conclusions from singular examples.","Authors":"Johannsen, B (Johannsen, Berit) Edited by:Werner, V; Seoane, E; SuarezGomez, C","Title":"From possessive-resultative to perfect? Re-assessing the meaning of [haebb- plus past participle] constructions in Old English prose"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389805000003 ISBN:978-3-319-39582-1; 978-3-319-39583-8 ISSN: 0302-9743","Categories":"Computer Science; Education & Educational Research Web of Science Categories:Computer Science, Interdisciplinary Applications; Education & Educational Research","Journal Information":"INTELLIGENT TUTORING SYSTEMS, ITS 2016 Book Series: Lecture Notes in Computer Science Volume: 9684 Pages: 23-33 DOI: 10.1007/978-3-319-39583-8_3 Published: 2016","Abstract":"Questioning has been shown to improve learning outcomes, and automatic question generation can greatly facilitate the inclusion of questions in learning technologies such as intelligent tutoring systems. The majority of prior QG systems use parsing software and transformation algorithms to create questions. In contrast, the approach described here infuses natural language understanding (NLU) into the natural language generation (NLG) process by first analyzing the central semantic content of each independent clause in each sentence. Then question templates are matched to what the sentence is communicating in order to generate higher quality questions. This approach generated a higher percentage of acceptable questions than prior state-of-the-art systems.","Authors":"Mazidi, K (Mazidi, Karen) ; Tarau, P (Tarau, Paul) Edited by:Micarelli, A; Stamper, J; Panourgia, K","Title":"Automatic Question Generation: From NLU to NLG"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389516204048 ISBN:978-1-4673-8026-3 ISSN: 1050-4729","Categories":"Automation & Control Systems; Robotics Web of Science Categories:Automation & Control Systems; Robotics","Journal Information":"2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA) Book Series: IEEE International Conference on Robotics and Automation ICRA Pages: 5068-5075 Published: 2016","Abstract":"Densely cluttered scenes are composed of multiple objects which are in close contact and heavily occlude each other. Few existing 3D object recognition systems are capable of accurately predicting object poses in such scenarios. This is mainly due to the presence of objects with textureless surfaces, similar appearances and the difficulty of object instance segmentation. In this paper, we present a hierarchical semantic segmentation algorithm which partitions a densely cluttered scene into different object regions. A RANSAC-based registration method is subsequently applied to estimate 6-DoF object poses within each object class. Part of this algorithm includes a generalized pooling scheme used to construct robust and discriminative object representations from a convolutional architecture with multiple pooling domains. We also provide a new RGB-D dataset which serves as a benchmark for object pose estimation in densely cluttered scenes. This dataset contains five thousand scene frames and over twenty thousand labeled poses of ten common hand tools. We show that our method demonstrates improved performance of pose estimation on this new dataset compared with other state-of-the-art methods.","Authors":"Li, C (Li, Chi) ; Bohren, J (Bohren, Jonathan) ; Carlson, E (Carlson, Eric) ; Hager, GD (Hager, Gregory D.) Edited by:Okamura, A; Menciassi, A; Ude, A; Burschka, D; Lee, D; Arrichiello, F; Liu, H; Moon, H; Neira, J; Sycara, K; Yokoi, K; Martinet, P; Oh, P; Valdastri, P; Krovi, V","Title":"Hierarchical Semantic Parsing for Object Pose Estimation in Densely Cluttered Scenes"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390305800041 ISBN:978-1-61499-696-5; 978-1-61499-695-8 ISSN: 0922-6389","Keywords":"Natural Language Generation; Multilingual; Summarization","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"ARTIFICIAL INTELLIGENCE RESEARCH AND DEVELOPMENT Book Series: Frontiers in Artificial Intelligence and Applications Volume: 288 Pages: 309-314 DOI: 10.3233/978-1-61499-696-5-309 Published: 2016","Abstract":"We present work in progress that tackles the problem of multilingual text summarization using semantic representations. As opposed to extractive summarization, in which text fragments are selected and a summary is assembled from them, our abstractive summarizer is based on abstract linguistic structures obtained from an analysis pipeline of disambiguation, syntactic and semantic parsing tools. The resulting structures are stored in a semantic repository, from which a text planning component produces content plans that go through a multilingual generation pipeline that eventually returns text in English, Spanish, French and/or German. We focuse on the multilingual generation part of the problem.","Authors":"Mille, S (Mille, Simon) ; Ballesteros, M (Ballesteros, Miguel) ; Burga, A (Burga, Alicia) ; Casamayor, G (Casamayor, Gerard) ; Wanner, L (Wanner, Leo) Edited by:Nebot, A; Binefa, X; DeMantaras, RL","Title":"Towards Multilingual Natural Language Generation Within Abstractive Summarization"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390307700022 ISBN:978-1-61499-701-6; 978-1-61499-700-9 ISSN: 0922-6389","Keywords":"Information extraction; word embeddings; word2vec","Categories":"Computer Science; Linguistics Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics","Journal Information":"HUMAN LANGUAGE TECHNOLOGIES - THE BALTIC PERSPECTIVE Book Series: Frontiers in Artificial Intelligence and Applications Volume: 289 Pages: 167-173 DOI: 10.3233/978-1-61499-701-6-167 Published: 2016","Abstract":"Word embeddings or distributed representations of words in a low dimensional vector space have been shown to capture both syntactic and semantic word relationships. Recently, multiple methods have been proposed to learn good word vector representations from very large text corpora effectively. Such word representations have been used to improve performance in a variety of natural language processing tasks. This work compares multiple methods to learn word embeddings for Latvian language and applies them to part of speech tagging, named entity recognition and dependency parsing tasks achieving state-of-the-art results for Latvian without resorting to any hand crafted and language specific features or resources such as gazetteers.","Authors":"Znotins, A (Znotins, Arturs) Edited by:Skadina, I; Rozis, R","Title":"Word Embeddings for Latvian Natural Language Processing Tools"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390179400005 ISBN:978-3-319-47650-6; 978-3-319-47649-0 ISSN: 0302-9743","Keywords":"Cyber attack records; Knowledge extraction; Noun phrase identification; Semantic grammar","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"KNOWLEDGE SCIENCE, ENGINEERING AND MANAGEMENT, KSEM 2016 Book Series: Lecture Notes in Artificial Intelligence Volume: 9983 Pages: 55-68 DOI: 10.1007/978-3-319-47650-6_5 Published: 2016","Abstract":"Knowledge acquisition from text is an important research of artificial intelligence. In this paper, we present a method of acquiring knowledge from Chinese records of events of cyber attacks based on a semantic grammar. In order to parse the sentences in the records, the method first identifies Chinese noun phrases in the records, and then use the semantic grammar of the cyber-attack domain to parse the records. Finally, knowledge is extracted from the parsing trees. Experimental results show that our method for noun phase identification has a good performance, and the precision of knowledge acquisition reaches a high level of 90 %.","Authors":"Fang, F (Fang, Fang) ; Wang, Y (Wang, Ya) ; Zhang, LC (Zhang, Luchen) ; Cao, CG (Cao, Cungen) Edited by:Lehner, F; Fteimi, N","Title":"Knowledge Extraction from Chinese Records of Cyber Attacks Based on a Semantic Grammar"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390239100039 ISBN:978-1-5090-3736-0","Keywords":"video stream; spatio temporal segmentation","Categories":"Computer Science Web of Science Categories:Computer Science, Theory & Methods","Journal Information":"PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP) Pages: 239-242 Published: 2016","Abstract":"Rapid development of up-to-date information technologies and the advent of the Web have accelerated the growth of digital media and, in particular, video collections. Due to semantic gap between the low-level video features and high-level interpretations lots of difficulties remain in the construction of video stream semantic structure. Relational model of video parsing has been proposed. Each frame segmentation lies on the basis of on line search for boundaries of homogeneous consecutive frames presenting an unit for semantic analysis.","Authors":"Mashtalir, S (Mashtalir, Sergii) ; Mashtalir, V (Mashtalir, Volodymyr) Edited by:Vynokurova, O; Peleshko, D","Title":"Sequential Temporal Video Segmentation via Spatial Image Partitions"}, {"Document Information":"Document Type:Article Language:Russian Accession Number: WOS:000390041100007 ISSN: 1607-3274 eISSN: 2313-688X","Keywords":"text; a Ukrainian; algorithm; content monitoring; keywords; linguistic analysis; parsing; generative grammar; structured scheme sentences; information linguistic system","Categories":"Computer Science Web of Science Categories:Computer Science, Hardware & Architecture","Journal Information":"RADIO ELECTRONICS COMPUTER SCIENCE CONTROL Issue: 3 Pages: 54-65 DOI: 10.15588/1607-3274-2016-3-7 Published: 2016","Abstract":"This paper presents the generative grammar application in linguistic modelling. Description of syntax sentence modelling is applied to automate the processes of analysis and synthesis of texts in natural language. The article shows the features of the sentences synthesis indifferent languages of using generative grammars. The paper considers norms and rules influence in the language on the grammars constructing course. The use of generative grammars has great potential in the development and creation of automated systems for textual content processing, for linguistic providing linguistic computer systems, etc. The methods and tools development for automatic processing of text of commercial content in modern information technology are important and topical (for example, systems of information retrieval, machine translation, semantic, statistical, optical and acoustic analysis and synthesis of speech, automated editing, knowledge extracting from the text content, text content abstracting and annotation, textual content indexing, training and didactic, linguistic buildings management, instrumental means of dictionaries conclusion of various types, etc.). Specialists actively seeking new models of description and methods for automatic processing of text content. One of these methods is the development of general principles of lexicographic systems of syntactic type. It is important by these principles these systems construction of text content processing for specific languages. Any tools of syntactic analysis consists of two parts: a knowledge base about a particular natural language and algorithm of syntactic analysis (a set of standard operators of text content processing on this knowledge). The source of grammatical knowledge is data from morphological analysis and various filled tables of concepts and linguistic units. They are the result of the empirical processing of textual content in natural language of experts in order to highlight the basic laws for syntactic analysis.","Authors":"Bisikalo, OV (Bisikalo, O., V) ; Vysotska, VA (Vysotska, V. A.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Bisikalo, Oleg  J-9715-2015 http://orcid.org/0000-0002-7607-1943","Title":"SENTENCE SYNTACTIC ANALYSIS APPLICATION TO KEYWORDS IDENTIFICATION UKRAINIAN TEXTS"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389539100186 ISBN:978-1-5090-0805-6","Keywords":"subject elements; event extraction; manual rules; CRF","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"2016 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS) Pages: 1103-1107 Published: 2016","Abstract":"Nowadays, with the rapid economic development, the amount of social information is also going up. Facing the daily explosive growth of the news quantity, the audience can difficultly get important information. To this end, the paper puts forward a method of Chinese news event extraction based on subject elements, which mixes the study of news topic sentence extraction and the research of event extraction together. According to the characteristics of news sentence, use dependency parsing to analyze the syntax. With the result of syntactic parsing to be a feature, distinguishably use Conditional Random Field algorithm (CRF) and Manual rules to identify the triggers in complex and simple sentences. Finally, Semantic Role Labeling algorithm (SRL) is used to identify the key elements of news events. What's more, the method will help readers quickly get the key elements from the long news, improving the efficiency of getting message.","Authors":"Zhang, C (Zhang, Chi) ; Hong, SH (Hong, Songhong) ; Zhang, PZ (Zhang, Pengzhou) Edited by:Uehara, K; Nakamura, M","Title":"The Research on Event Extraction of Chinese News Based on Subject Elements"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389502300023 ISBN:978-1-4503-4229-2","Keywords":"Scalable figure extraction; academic search engine; section title extraction; figure usage analysis","Categories":"Computer Science Web of Science Categories:Computer Science, Interdisciplinary Applications","Journal Information":"2016 IEEE/ACM JOINT CONFERENCE ON DIGITAL LIBRARIES (JCDL) Pages: 143-152 DOI: 10.1145/2910896.2910904 Published: 2016","Abstract":"Figures and tables are key sources of information in many scholarly documents. However, current academic search engines do not make use of figures and tables when semantically parsing documents or presenting document summaries to users. To facilitate these applications we develop an algorithm that extracts figures, tables, and captions from documents called \"PDFFigures 2.0.\" Our proposed approach analyzes the structure of individual pages by detecting captions, graphical elements, and chunks of body text, and then locates figures and tables by reasoning about the empty regions within that text. To evaluate our work, we introduce a new dataset of computer science papers, along with ground truth labels for the locations of the figures, tables, and captions within them. Our algorithm achieves impressive results (94% precision at 90% recall) on this dataset surpassing previous state of the art. Further, we show how our framework was used to extract figures from a corpus of over one million papers, and how the resulting extractions were integrated into the user interface of a smart academic search engine, Semantic Scholar (www.semanticscholar.org). Finally, we present results of exploratory data analysis completed on the extracted figures as well as an extension of our method for the task of section title extraction.","Authors":"Clark, C (Clark, Christopher) ; Divvala, S (Divvala, Santosh) Book Group Author(s):IEEE","Title":"PDFFigures 2.0: Mining Figures from Research Papers"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000388373406050 ISBN:978-1-4799-9988-0 ISSN: 1520-6149","Keywords":"Discourse Analysis; Speech Processing; Machine Learning","Categories":"Acoustics; Engineering Web of Science Categories:Acoustics; Engineering, Electrical & Electronic","Journal Information":"2016 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING PROCEEDINGS Book Series: International Conference on Acoustics Speech and Signal Processing ICASSP Pages: 6095-6099 Published: 2016","Abstract":"Discourse parsing is an important task in Language Understanding with applications to human-human and human-machine communication modeling. However, most of the research has focused on written text, and parsers heavily rely on syntactic parsers that themselves have low performance on dialog data. In our work, we address the problem of analyzing the semantic relations between discourse units in human-human spoken conversations. In particular, in this paper we focus on the detection of discourse connectives which are the predicate of such relations. The discourse relations are drawn from the Penn Discourse Treebank annotation model and adapted to a domain-specific Italian human-human spoken conversations. We study the relevance of lexical and acoustic context in predicting discourse connectives. We observe that both lexical and acoustic context have mixed effect on the prediction of specific connectives. While the oracle of using lexical and acoustic contextual feature combinations is F-1 = 68.53, the lexical context alone significantly outperforms the baseline by more than 10 points with F-1 = 64.93.","Authors":"Riccardi, G (Riccardi, Giuseppe) ; Stepanov, EA (Stepanov, Evgeny A.) ; Chowdhury, SA (Chowdhury, Shammur Absar) Book Group Author(s):IEEE","Title":"DISCOURSE CONNECTIVE DETECTION IN SPOKEN CONVERSATIONS"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389574300009 ISBN:978-1-4673-7258-9 ISSN: 1945-7871","Keywords":"Weakly supervised; image parsing; label co-occurrence; discriminatively semantic graph propagation","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2016 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA & EXPO (ICME) Book Series: IEEE International Conference on Multimedia and Expo Published: 2016","Abstract":"In this paper, we concentrate on a challenging proble-mimage parsing trained on images with weakly supervised information, i.e.,image-level labels. Image-level labels are ambiguous and difficult for training. Typically, an affinity graph of superpixels is constructed to provide additional information about labels of the target superpixel. However, existing work constructs affinity graph in a naive manner, L1 reconstruction and k-NN are most used where label co-occurrence is a common phenomenon and degenerates the assignment performance. To overcome above problem, we proposed the use of discriminatively semantic ability between neighbor superpixels and the target superpixel in affinity graph construction. With simpler experiment setup and lower time complexity, our method achieves average per-class accuracy comparable to state-of-the-art performances in weakly-supervised image parsing task on datasets MSRC-21 and PASCAL VOC 2007.","Authors":"Xu, XC (Xu, Xiaocheng) ; Ma, J (Ma, Jun) Book Group Author(s):IEEE","Title":"WEAKLY SUPERVISED IMAGE PARSING BY DISCRIMINATIVELY SEMANTIC GRAPH PROPAGATION"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389639600008 ISBN:978-3-319-42471-2; 978-3-319-42470-5 ISSN: 1865-0929","Keywords":"Lexicon-Grammar; NooJ; NooJ local grammars; NooJ finite-state automata/transducers; Formal semantics; Support verbs; Simple sentences; Passive diatheses","Categories":"Computer Science; Linguistics Web of Science Categories:Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics","Journal Information":"AUTOMATIC PROCESSING OF NATURAL-LANGUAGE ELECTRONIC TEXTS WITH NOOJ Book Series: Communications in Computer and Information Science Volume: 607 Pages: 83-95 DOI: 10.1007/978-3-319-42471-2_8 Published: 2016","Abstract":"As for past participles (PPs) and adjectives (As), and especially from the point of view of lexicographic descriptions, in Italian we may find a high level of categorial ambiguity. Very often, the words belonging to these two parts of speech (PsOS) are homographs and semantically contiguous. Therefore, when necessary, and in most of their occurrences, it may be useful to automatically parse their correct linguistic functions. Essentially, this is possible only by means of precise syntactic analyses, which must be focused on and applied to both the left and right contexts co-occurring with the propositions to be examined. Such analyses must also infer about all the possible verb antecedents to past participles and adjectives, be they operators, support verbs or simple auxiliary verbs. Therefore, in our article, we intend to use NooJ with the following purposes: Regarding Italian simple words, and at the level of lexicographical description, we will study and define the levels of categorical ambiguity existing between past participles and adjectives; Subsequently, we will define the syntactic pattern in which this ambiguity can be solved; Then, we will describe the construction of a set of local grammars to apply for the disambiguation and correct tagging of these parts of speech; Finally, we will determine the levels of recall and precision of these grammars. At the end of this four-step process, we aim at creating a set of formal semantic analysis tools, to exploit in NooJ to distinguish sentences with conventional operators (verb predicates) from sentences with support verbs and predicative adjectives, that is to say, to make work our grammars as Formal Semantics processing tools.","Authors":"Monteleone, M (Monteleone, Mario) Edited by:Okrut, T; Hetsevich, Y; Silberztein, M; Stanislavenka, H","Title":"NooJ Local Grammars and Formal Semantics: Past Participles vs. Adjectives in Italian"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389639600013 ISBN:978-3-319-42471-2; 978-3-319-42470-5 ISSN: 1865-0929","Keywords":"Semantic indexing; Archaeological Italian electronic dictionaries; CIDOC CRM; NooJ linguistic resources KeyWords Plus:SEMANTICS","Categories":"Computer Science; Linguistics Web of Science Categories:Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics","Journal Information":"AUTOMATIC PROCESSING OF NATURAL-LANGUAGE ELECTRONIC TEXTS WITH NOOJ Book Series: Communications in Computer and Information Science Volume: 607 Pages: 151-161 DOI: 10.1007/978-3-319-42471-2_13 Published: 2016","Abstract":"Due to the large amount of data available on the Web, indexing information represents a crucial step to guarantee fast and accurate Information Retrieval (IR). Indexing content allows to find relevant documents on the basis of a user's query. Numerous researches discuss the use of automated indexing, considered faster and cheaper than manual systems. However, in order to produce the index, using algorithms, entails low precision, low recall, and generic results [1]. This is the reason why in this paper we propose a NooJ- based system, by means of which we will develop a search engine able to process online documents, starting from a natural language query, and to return information to users. To do this, and in order to analyze user's request, we will employ software automations to apply NooJ and its Linguistic Resources (LRs).","Authors":"di Buono, MP (di Buono, Maria Pia) Edited by:Okrut, T; Hetsevich, Y; Silberztein, M; Stanislavenka, H","Title":"Semi-automatic Indexing and Parsing Information on the Web with NooJ"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389501700031 ISBN:978-3-319-48881-3; 978-3-319-48880-6 ISSN: 0302-9743","Keywords":"Indoor assistive navigation; Context-aware; Semantic map; Obstacle avoidance; Tango device KeyWords Plus:SYSTEM","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"COMPUTER VISION - ECCV 2016 WORKSHOPS, PT II Book Series: Lecture Notes in Computer Science Volume: 9914 Pages: 448-462 DOI: 10.1007/978-3-319-48881-3_31 Published: 2016","Abstract":"This paper presents a novel mobile wearable context-aware indoor maps and navigation system with obstacle avoidance for the blind. The system includes an indoor map editor and an App on Tango devices with multiple modules. The indoor map editor parses spatial semantic information from a building architectural model, and represents it as a high-level semantic map to support context awareness. An obstacle avoidance module detects objects in front using a depth sensor. Based on the ego-motion tracking within the Tango, localization alignment on the semantic map, and obstacle detection, the system automatically generates a safe path to a desired destination. A speech-audio interface delivers user input, guidance and alert cues in real-time using a priority-based mechanism to reduce the user's cognitive load. Field tests involving blindfolded and blind subjects demonstrate that the proposed prototype performs context-aware and safety indoor assistive navigation effectively.","Authors":"Li, B (Li, Bing) ; Munoz, JP (Munoz, J. Pablo) ; Rong, XJ (Rong, Xuejian) ; Xiao, JZ (Xiao, Jizhong) ; Tian, YL (Tian, Yingli) ; Arditi, A (Arditi, Aries) Edited by:Hua, G; Jegou, H","Title":"ISANA: Wearable Context-Aware Indoor Assistive Navigation with Obstacle Avoidance for the Blind"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389723300009 ISBN:978-3-319-41498-0; 978-3-319-41497-3 ISSN: 0302-9743","Keywords":"Natural language simplification; Semantic annotation; Legal rules; Controlled languages; Semantic web","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications","Journal Information":"CONTROLLED NATURAL LANGUAGE, CNL 2016 Book Series: Lecture Notes in Computer Science Volume: 9767 Pages: 92-101 DOI: 10.1007/978-3-319-41498-0_9 Published: 2016","Abstract":"Legislation and regulations are required to be structured and augmented in order to make them serviceable on the Internet. However, it is known that it is complex to accurately parse and semantically represent such texts. Controlled languages have been one approach to adjusting to the complexities, where the source text is rewritten in some systematic form. Such an approach is not only costly, but potentially introduces alternative translations which may be undesirable. To navigate between the requirements and complexities, we propose and exemplify a high-level controlled language that serves as an XML representation for key components of legal content. The language tightly correlates to the source text and also facilitates analysis.","Authors":"Wyner, A (Wyner, Adam) ; Nazarenko, A (Nazarenko, Adeline) ; Levy, F (Levy, Francois) Edited by:Davis, B; Pace, GJ; Wyner, A","Title":"Towards a High-Level Controlled Language for Legal Sources on the Semantic Web"}]