[{"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395475200006 ISSN: 1046-8188 eISSN: 1558-2868","Keywords":"Compact data structure; top-k document retrieval KeyWords Plus:SEARCH-TREES; DOCUMENT-RETRIEVAL; QUERIES; INDEXES; CODES","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"ACM TRANSACTIONS ON INFORMATION SYSTEMS Volume: 35 Issue: 3 Article Number: 22 DOI: 10.1145/3007186 Published: JAN 2017","Abstract":"We introduce a new representation of the inverted index that performs faster ranked unions and intersections while using similar space. Our index is based on the treap data structure, which allows us to intersect/merge the document identifiers while simultaneously thresholding by frequency, instead of the costlier two-step classical processing methods. To achieve compression, we represent the treap topology using different alternative compact data structures. Further, the treap invariants allow us to elegantly encode differentially both document identifiers and frequencies. We also show how to extend this representation to support incremental updates over the index. Results show that, under the tf-idf scoring scheme, our index uses about the same space as state-of-the-art compact representations, while performing up to 2-20 times faster on ranked single-word, union, or intersection queries. Under the BM25 scoring scheme, our index may use up to 40% more space than the others and outperforms them less frequently but still reaches improvement factors of 2-20 in the best cases. The index supporting incremental updates poses an overhead of 50%-100% over the static variants in terms of space, construction, and query time.","Authors":"Konow, R (Konow, Roberto) ; Navarro, G (Navarro, Gonzalo) ; Clarke, CLA (Clarke, Charles L. A.); Lopez-Ortiz, A (Lopez-Ortiz, Alejandro)","Title":"Inverted Treaps"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000392193600025 ISBN:978-3-319-46562-3; 978-3-319-46561-6 ISSN: 2194-5357","Categories":"Computer Science; Robotics Web of Science Categories:Computer Science, Artificial Intelligence; Robotics","Journal Information":"ADVANCES IN COMPUTATIONAL INTELLIGENCE SYSTEMS Book Series: Advances in Intelligent Systems and Computing Volume: 513 Pages: 387-405 DOI: 10.1007/978-3-319-46562-3_25 Published: 2017","Abstract":"In many contexts of Information Retrieval (IR), term weights play an important role in retrieving the relevant documents responding to users' queries. The term weight measures the importance or the information content of a keyword existing in the documents in the IR system. The term weight can be divided into two parts, the Global Term Weight (GTW) and the Local Term Weight (LTW). The GTW is a value assigned to each index term to indicate the topic of the documents. It has the discrimination value of the term to discriminate between documents in the same collection. The LTW is a value that measures the contribution of the index term in the document. This paper proposes an approach, based on an evolutionary gradient strategy, for evolving the Global Term Weights (GTWs) of the collection and using Term Frequency-Average Term Occurrence (TF-ATO) as the Local Term Weights (LTWs). This approach reduces the problem size for the term weights evolution which reduces the computational time helping to achieve an improved IR effectiveness compared to other Evolutionary Computation (EC) approaches in the literature. The paper also investigates the limitation that the relevance judgment can have in this approach by conducting two sets of experiments, for partially and fully evolved GTWs. The proposed approach outperformed the Okapi BM25 and TF-ATO with DA weighting schemes methods in terms of Mean Average Precision (MAP), Average Precision (AP) and Normalized Discounted Cumulative Gain (NDCG).","Authors":"Ibrahim, OAS (Ibrahim, Osman Ali Sadek) ; Landa-Silva, D (Landa-Silva, Dario) Edited by:Angelov, P; Gegov, A; Jayne, C; Shen, Q Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Ibrahim, Osman Ali Sadek  http://orcid.org/0000-0001-9254-3093 Landa-Silva, Dario  http://orcid.org/0000-0002-9499-6827","Title":"(1+1)-Evolutionary Gradient Strategy to Evolve Global Term Weights in Information Retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000390504300011 ISSN: 0306-4573 eISSN: 1873-5371","Keywords":"Information retrieval; Formal concept analysis; Network analysis; Portal retrieval KeyWords Plus:INFORMATION-RETRIEVAL; CONCEPT LATTICES; TEXT RETRIEVAL; WEB; ALGORITHMS","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"INFORMATION PROCESSING & MANAGEMENT Volume: 53 Issue: 1 Pages: 203-222 DOI: 10.1016/j.ipm.2016.08.002 Published: JAN 2017","Abstract":"The web is a network of linked sites whereby each site either forms a physical portal or a standalone page. In the former case, the portal presents an access point to its embedded web pages that coherently present a specific topic. In the latter case, there are millions of standalone web pages, that are scattered throughout the web, having the same topic and could be conceptually linked together to form virtual portals. Search engines have been developed to help users in reaching the adequate pages in an efficient and effective manner. All the known current search engine techniques rely on the web page as the basic atomic search unit. They ignore the conceptual links, that reveal the implicit web related meanings, among the retrieved pages. However, building a semantic model for the whole portal may contain more semantic information than a model of scattered individual pages. In addition, user queries can be poor and contain imprecise terms that do not reflect the real user intention. Consequently, retrieving the standalone individual pages that are directly related to the query may not satisfy the user's need. In this paper, we propose PREFCA, a Portal Retrieval Engine based on Formal Concept Analysis that relies on the portal as the main search unit. PREFCA consists of three phases: First, the information extraction phase that is concerned with extracting portal's semantic data. Second, the formal concept analysis phase that utilizes formal concept analysis to discover the conceptual links among portal and attributes. Finally, the information retrieval phase where we propose a portal ranking method to retrieve ranked pairs of portals and embedded pages. Additionally, we apply the network analysis rules to output some portal characteristics. We evaluated PREFCA using two data sets, namely the Forum for Information Retrieval Evaluation 2010 and ClueWeb09 (category B) test data, for physical and virtual portals respectively. PREFCA proves higher F-measure accuracy, better Mean Average Precision ranking and comparable network analysis and efficiency results than other search engine approaches, namely Term Frequency Inverse Document Frequency (TF-IDF), Latent Semantic Analysis (LSA), and BM25 techniques. As well, it gains high Mean Average Precision in comparison with learning to rank techniques. Moreover, PREFCA also gains better reach time than Carrot as a well-known topic-based search engine. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Negm, E (Negm, Eman) ; AbdelRahman, S (AbdelRahman, Samir) ; Bahgat, R (Bahgat, Reem)","Title":"PREFCA: A portal retrieval engine based on formal concept analysis"}, {"Categories":"Information Science & Library Science Web of Science Categories:Information Science & Library Science","Journal Information":"INFORMATION RESEARCH-AN INTERNATIONAL ELECTRONIC JOURNAL Volume: 21 Issue: 4 Article Number: 724 Published: DEC 2016","Abstract":"Introduction. Studies have indicated that users' text highlighting behaviour can be further manipulated to improve the relevance of retrieved results. This article reports on a study that examined users' text highlight frequency, length and users' copy-paste actions. Method. A binary voting mechanism was employed to determine the weights for the feedback, which were then used to re-rank the original search results. A search engine prototype was built using the Communications of the ACM test collection, with the well-known BM25 acting as the baseline model. Analysis. The proposed enhanced model's performance was evaluated using the mean average precisions and F-score metrics, and results were compared at the top 5, 10 and 15. Additionally, comparisons were also made based on the number of terms used in a query, that is single, double and triple terms. Results. The findings show that the enhanced model significantly outperformed BM25, and the rest of the models at all document levels. To be specific, the enhanced model showed significant improvements over the frequency model. Additionally, retrieval relevance was found to be the best when the query length is two. Conclusions. Users' post-click behaviour may serve as a significant indicator of their interests, and thus can be used to improve the relevance of the retrieved results. Future studies could look into further extending this model by including other post-click behaviour such as printing or saving.","Authors":"Balakrishnan, V (Balakrishnan, Vimala) ; Mehmood, Y (Mehmood, Yasir) ; Nagappan, Y (Nagappan, Yoganathan) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Balakrishnan, Vimala  F-4037-2011 http://orcid.org/0000-0002-6859-4488","Title":"Moving beyond text highlights: inferring users' interests to improve the relevance of retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000384920500013 ISSN: 1745-1361","Keywords":"video retrieval; instance search; region-of-interest; TRECVID; probabilistic information retrieval; BM25; exponential IDF; Bayesian exponential IDF KeyWords Plus:VISUAL OBJECT RETRIEVAL; DIVERGENCE; FEATURES; SCALE","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS Volume: E99D Issue: 9 Pages: 2320-2331 DOI: 10.1587/transinf.2016EDP7066 Published: SEP 2016","Abstract":"In this paper, we first analyze the discriminative power in the Best Match ( BM) 25 formula and provide its calculation method from the Bayesian point of view. The resulting, derived discriminative power is quite similar to the exponential inverse document frequency ( EIDF) that we have previously proposed [ 1] but retains more preferable theoretical advantages. In our previous paper [ 1], we proposed the EIDF in the framework of the probabilistic information retrieval ( IR) method BM25 to address the instance search task, which is a specific object search for videos using an image query. Although the effectiveness of our EIDF was experimentally demonstrated, we did not consider its theoretical justification and interpretation. We also did not describe the use of region-of-interest ( ROI) information, which is supposed to be input to the instance search system together with the original image query showing the instance. Therefore, here, we justify the EIDF by calculating the discriminative power in the BM25 from the Bayesian viewpoint. We also investigate the effect of the ROI information for improving the instance search accuracy and propose two search methods incorporating the ROI effect into the BM25 video ranking function. We validated the proposed methods through a series of experiments using the TREC Video Retrieval Evaluation instance search task dataset.","Authors":"Murata, M (Murata, Masaya) ; Nagano, H (Nagano, Hidehisa) ; Hiramatsu, K (Hiramatsu, Kaoru) ; Kashino, K (Kashino, Kunio) ; Satoh, S (Satoh, Shin'ichi)","Title":"Bayesian Exponential Inverse Document Frequency and Region-of-Interest Effect for Enhancing Instance Search Accuracy"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000372679700001 PubMed ID: 26969433 ISSN: 0048-3575 eISSN: 1095-9939","Keywords":"Benzimidazoles; Resistance mutations; beta(2)-tubulin; Cold-sensitivity; Fitness parameters; Zearalenone KeyWords Plus:BETA-TUBULIN GENE; CARBENDAZIM-RESISTANCE; GIBBERELLA-ZEAE; THIABENDAZOLE RESISTANCE; BENOMYL RESISTANCE; BOTRYTIS-CINEREA; BINDING-SITE; IDENTIFICATION; MODEL; MUTATION","Categories":"Biochemistry & Molecular Biology; Entomology; Physiology Web of Science Categories:Biochemistry & Molecular Biology; Entomology; Physiology","Journal Information":"PESTICIDE BIOCHEMISTRY AND PHYSIOLOGY Volume: 128 Pages: 1-9 DOI: 10.1016/j.pestbp.2015.10.004 Published: MAR 2016","Abstract":"Six benzimidazole (BMZ)-resistant Fusarium graminearum strains were obtained after UV mutagenesis and selection on carbendazim (MBC) -amended medium. In vitro bioassays resulted in the identification of two resistant phenotypes that were highly HR (Rf: 40-170, based on EC50) and moderately MR (Rf: 10-20) resistant to carbendazim. Cross resistance studies with other fungicides showed that all mutant strains tested were also resistant to other BM25, such as benomyl and thiabendazole, but retained their parental sensitivity to fungicides belonging to other chemical groups. A point mutation at codon 6 (His6Asn) was found in the)32-tubulin gene of MR isolates while another mutation at codon 200 (Phe200Tyr) was present in one MR and one HR isolates. Interestingly, low temperatures suppressed MBC-resistance in all isolates bearing the H6N mutation. The three-dimensional homology model of the wild-type and mutants of p-tubulins were constructed, and the possible carbendazim binding site was analyzed. Studies on fitness parameters showed that the mutation(s) for resistance to BMZs did not affect the mycelial growth rate whereas adverse effects were found in sporulation and conidial germination in most of the resistant mutants. Pathogenicity tests on corn cobs revealed that mutants were less or equally aggressive to the wild-type strain but expressed their BMZ-resistance after inoculation on maize cobs treated with MBC. Analysis of mycotoxin production by high performance liquid chromatography revealed that only two HR strains produced zearalenone (ZEA) at concentrations similar to that of the wild-type strain, while no ZEA levels were detected in the rest of the mutants. (C) 2015 Elsevier Inc. All rights reserved.","Authors":"Sevastos, A (Sevastos, A.) ; Markoglou, A (Markoglou, A.) ; Labrou, NE (Labrou, N. E.) ; Flouri, F (Flouri, F.) ; Malandrakis, A (Malandrakis, A.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Labrou, Nikolaos  B-1089-2011 http://orcid.org/0000-0003-1925-9867","Title":"Molecular characterization, fitness and mycotoxin production of Fusarium graminearum laboratory strains resistant to benzimidazoles"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000370255700008 ISSN: 2330-1635 eISSN: 2330-1643","Keywords":"information retrieval KeyWords Plus:INFORMATION-RETRIEVAL; LANGUAGE MODELS; FEEDBACK; FREQUENCY","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY Volume: 67 Issue: 3 Pages: 582-593 DOI: 10.1002/asi.23419 Published: MAR 2016","Abstract":"Numerous past studies have demonstrated the effectiveness of the relevance model (RM) for information retrieval (IR). This approach enables relevance or pseudo-relevance feedback to be incorporated within the language modeling framework of IR. In the traditional RM, the feedback information is used to improve the estimate of the query language model. In this article, we introduce an extension of RM in the setting of relevance feedback. Our method provides an additional way to incorporate feedback via the improvement of the document language models. Specifically, we make use of the context information of known relevant and nonrelevant documents to obtain weighted counts of query terms for estimating the document language models. The context information is based on the words (unigrams or bigrams) appearing within a text window centered on query terms. Experiments on several Text REtrieval Conference (TREC) collections show that our context-dependent relevance model can improve retrieval performance over the baseline RM. Together with previous studies within the BM25 framework, our current study demonstrates that the effectiveness of our method for using context information in IR is quite general and not limited to any specific retrieval model.","Authors":"Dang, EKF (Dang, Edward Kai Fung) ; Luk, RWP (Luk, Robert W. P.) ; Allan, J (Allan, James)","Title":"A context-dependent relevance model"}, {"Keywords":"opinion clustering; opinion summarization; vector space model (VSM); syntactic parsing","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Hardware & Architecture; Engineering, Industrial","Journal Information":"2016 IEEE 14TH INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN) Book Series: IEEE International Conference on Industrial Informatics INDIN Pages: 1177-1180 Published: 2016","Abstract":"Online short texts of hot topics submitted to social media by users can provide valuable personal opinions, which are useful for service providers and individuals. However, it is difficult for readers to grasp the main opinions of massive short texts. In this paper, to cope with the summarization challenge of short texts, we proposed a novel approach, which makes full use of BM25 to weight each short text and syntactic parsing to generate important information of each opinion cluster. The approach also utilizes the feature pruning to reduce the dimensions of the vectors. We conduct our experiments on real datasets and evaluate the results by standard metrics and manual evaluation. The experimental results show that our proposed approach improves the accuracy when compared to the state-of-the-art method.","Authors":"Niu, JW (Niu, Jianwei) ; Zhao, QJ (Zhao, Qingjuan) ; Wang, L (Wang, Lei) ; Chen, H (Chen, Huan) ; Zheng, SC (Zheng, Shichao) Book Group Author(s):IEEE","Title":"Opinion Summarization for Short Texts based on BM25 and Syntactic Parsing"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000393191700276 ISBN:978-1-5090-1610-5 ISSN: 2156-1125","Categories":"Computer Science; Medical Informatics Web of Science Categories:Computer Science, Interdisciplinary Applications; Medical Informatics","Journal Information":"2016 IEEE INTERNATIONAL CONFERENCE ON BIOINFORMATICS AND BIOMEDICINE (BIBM) Book Series: IEEE International Conference on Bioinformatics and Biomedicine-BIBM Pages: 1616-1623 Published: 2016","Abstract":"The goal of Clinical Decision Support (CDS) is to link relevant medical information to meet physicians' needs for taking better care of their patients. An effective CDS system takes medical records as input and returns the most relevant full-text biomedical articles to provide clinical decision supports for the physicians. Existing CDS systems mainly consist of three processing stages i.e. Query Reformulation, Retrieval and Re-ranking. Most of the existing CDS systems are only implemented based on classical keyword-indexing retrieval models such as BM25, PL2 and BB2, without taking semantics into account. To this end, this paper develops a novel CDS approach based on the semantic vector representations of both documents and queries. Experimental results on the standard Text REtrieval Conference (TREC) CDS track dataset show that the performance of a CDS system can be improved by integrating the semantic information.","Authors":"Yang, CH (Yang, Chenhao) ; He, B (He, Ben) Edited by:Tian, T; Jiang, Q; Liu, Y; Burrage, K; Song, J; Wang, Y; Hu, X; Morishita, S; Zhu, Q; Wang, G","Title":"A Novel Semantics-based Approach to Medical Literature Search"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390890800031 ISBN:978-1-4503-4073-1","Keywords":"Question Answering; Deep Learning; Value-shared Weights; Term Importance Learning","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT Pages: 287-296 DOI: 10.1145/2983323.2983818 Published: 2016","Abstract":"As an alternative to question answering methods based on feature engineering, deep learning approaches such as convolutional neural networks (CNNs) and Long Short-Term Memory Models (LSTMs) have recently been proposed for semantic matching of questions and answers. To achieve good results, however, these models have been combined with additional features such as word overlap or BM25 scores. Without this combination, these models perform significantly worse than methods based on linguistic feature engineering. In this paper, we propose an attention based neural matching model for ranking short answer text. We adopt value-shared weighting scheme instead of position-shared weighting scheme for combining different matching signals and incorporate question term importance learning using question attention network. Using the popular benchmark TREC QA data, we show that the relatively simple aNMM model can significantly outperform other neural network models that have been used for the question answering task, and is competitive with models that are combined with additional features. When aNMM is combined with additional features, it outperforms all baselines.","Authors":"Yang, L (Yang, Liu) ; Ai, QY (Ai, Qingyao) ; Guo, JF (Guo, Jiafeng) ; Croft, WB (Croft, W. Bruce) Book Group Author(s):ACM","Title":"aNMM: Ranking Short Answer Texts with Attention-Based Neural Matching Model"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390890800075 ISBN:978-1-4503-4073-1","Keywords":"IR Models; translation model; word embeddings; related terms","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT Pages: 711-720 DOI: 10.1145/2983323.2983833 Published: 2016","Abstract":"A recurring question in information retrieval is whether term associations can be properly integrated in traditional information retrieval models while preserving their robustness and effectiveness. In this paper, we revisit a wide spectrum of existing models (Pivoted Document Normalization, BM25, BM25 Verboseness Aware, Multi-Aspect TF, and Language Modelling) by introducing a generalisation of the idea of the translation model. This generalisation is a de facto transformation of the translation models from Language Modelling to the probabilistic models. In doing so, we observe a potential limitation of these generalised translation models: they only affect the term frequency based components of all the models, ignoring changes in document and collection statistics. We correct this limitation by extending the translation models with the statistics of term associations and provide extensive experimental results to demonstrate the benefit of the newly proposed methods. Additionally, we compare the translation models with query expansion methods based on the same term association resources, as well as based on Pseudo-Relevance Feedback (PRF). We observe that translation models always outperform the first, but provide complementary information with the second, such that by using PRF and our translation models together we observe results better than the current state of the art.","Authors":"Rekabsaz, N (Rekabsaz, Navid) ; Lupu, M (Lupu, Mihai) ; Hanbury, A (Hanbury, Allan) ; Zuccon, G (Zuccon, Guido) Book Group Author(s):ACM","Title":"Generalizing Translation Models in the Probabilistic Relevance Framework"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390299100009 ISBN:978-1-4673-9591-5","Keywords":"text mining; author profiling; machine learning","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA ANALYSIS (ICBDA) Pages: 42-47 Published: 2016","Abstract":"Native language identification (NLI) is a process by which an author's native language can be identified from essays written in the second language of the author. In this work, a supervised model is built to accomplish this based on a Chinese learner corpus. In the NLI field, this is the first work to (1) eliminate noisy data automatically before the training phase and (2) employ a BM25 term weighting technique to score each feature. We also adopt a hierarchical structure of linear support vector machine classifiers to achieve high accuracy and a state-of-the-art accuracy of 77.1%, which is greater than those of other Chinese NLI methods by over 10%.","Authors":"Wang, L (Wang, Lan) ; Tanaka, M (Tanaka, Masahiro) ; Yamana, H (Yamana, Hayato) Book Group Author(s):IEEE","Title":"What is your Mother Tongue?: Improving Chinese Native Language Identification by Cleaning Noisy Data and Adopting BM25"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389539100180 ISBN:978-1-5090-0805-6","Keywords":"Page Sorting; Nutch; TF/IDF; BM25; Music","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"2016 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE (ICIS) Pages: 1071-1074 Published: 2016","Abstract":"The default page sorting algorithm in Nutch which is open source search engine is TF/IDF algorithm, but it's difficult to meet the demand of music page sorting. The paper presents a new page sorting algorithm bases on BM25 model for music users. According word count and keyword frequency in music web pages, the pages whose keyword frequency is high and text size is long such as music home page, can be sorted at or near the top, and other music pages are low in sorting. The experiment proved that the new algorithm bases on BM25 model is better to meet demand of music page sorting than TF/IDF algorithm for music users.","Authors":"Li, Y (Li, Ying) ; Sha, F (Sha, Fei) ; Wang, S (Wang, Shujuan) ; Hu, T (Hu, Tao) Edited by:Uehara, K; Nakamura, M","Title":"The Improvement of Page Sorting Algorithm for Music Users in Nutch"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389610000057 ISBN:978-1-5090-2179-6","Keywords":"instance search; bichromatic reverse nearest neighbor search; BM25","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM) Pages: 326-333 DOI: 10.1109/BigMM.2016.76 Published: 2016","Abstract":"Recently more and more videos have been shared through the websites such as youtube.com. In order to utilize them efficiently, instance search (INS) techniques which find a specific person, object and place from a video database without metadata has been desired. It is known that the BM25 scoring method is a powerful tool for the INS task. It is, however, also known that it requires a time consuming process. It has been pointed out that the time consuming process is equivalent to the bichromatic reverse nearest neighbor (BRNN) search problem and a method to approximate it has been proposed. However, the algorithm needs a huge reference table which causes large memory usage and computational complexity. In this paper, we propose a more efficient way to search BRNNs using a reverse lookup structure. An experimental result using the database of TRECVID 2012 INS task showed that the proposed method was 2.8 times faster with 10% less memory usage than the conventional method.","Authors":"Sato, T (Sato, Tomokazu) ; Iwamura, M (Iwamura, Masakazu) ; Kaneda, K (Kaneda, Kitahiro) ; Kise, K (Kise, Koichi) Book Group Author(s):IEEE","Title":"Fast and Memory Saving Instance Search with Approximate Reverse Nearest Neighbor Search Using Reverse Lookup"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389727300049 ISBN:978-3-319-40548-3; 978-3-319-40547-6 ISSN: 1865-0929","Keywords":"Twitter; BM25; Brand image; Text-mining","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Ergonomics","Journal Information":"HCI INTERNATIONAL 2016 - POSTERS' EXTENDED ABSTRACTS, PT I Book Series: Communications in Computer and Information Science Volume: 617 Pages: 291-295 DOI: 10.1007/978-3-319-40548-3_49 Published: 2016","Abstract":"The purpose of this study is to extract characteristic words as the information of expression pertaining to a brand's image, from the language resources that have accumulated by users on Twitter. In this study, we analyzed Twitter data related to brands extracted the characteristic representations by using Okapi BM25, which is a ranking function that has been recently introduced in information retrieval. To confirm the validity of our approach, we conduct comparative experiments on the Twitter data of several Japanese automobile brands using BM25 and TF-IDF. By using the BM25, the extraction of keywords that are meaningful and buried in high frequency terms can be expected.","Authors":"Saitoh, F (Saitoh, Fumiaki) ; Shiozawa, F (Shiozawa, Fumiya) ; Ishizu, S (Ishizu, Syohei) Edited by:Stephanidis, C","Title":"Knowledge Extraction About Brand Image Using Information Retrieval Method"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389801100016 ISBN:978-3-319-46759-7; 978-3-319-46758-0 ISSN: 0302-9743","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"SIMILARITY SEARCH AND APPLICATIONS, SISAP 2016 Book Series: Lecture Notes in Computer Science Volume: 9939 Pages: 210-217 DOI: 10.1007/978-3-319-46759-7_16 Published: 2016","Abstract":"There are many contexts where the definition of similarity in multivariate space requires to be based on the correlation, rather than absolute value, of the variables. Examples include classic IR measurements such as TDF/IF and BM25, client similarity measures based on collaborative filtering, feature analysis of chemical molecules, and biodiversity contexts. In such cases, it is almost standard for Cosine similarity to be used. More recently, Jensen-Shannon divergence has appeared in a proper metric form, and a related metric Structural Entropic Distance (SED) has been investigated. A fourth metric, based on a little-known divergence function named as Triangular Divergence, is also assessed here. For these metrics, we study their properties in the context of similarity and metric search. We compare and contrast their semantics and performance. Our conclusion is that, despite Cosine Distance being an almost automatic choice in this context, Triangular Distance is most likely to be the best choice in terms of a compromise between semantics and performance.","Authors":"Connor, R (Connor, Richard) Edited by:Amsaleg, L; Houle, ME; Schubert, E","Title":"A Tale of Four Metrics"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000387957400026 ISBN:978-3-319-41754-7; 978-3-319-41753-0 ISSN: 0302-9743","Keywords":"BM25; Linear support vector; Sentiment analysis; Term frequency KeyWords Plus:WEB","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods","Journal Information":"NATURAL LANGUAGE PROCESSING AND INFORMATION SYSTEMS, NLDB 2016 Book Series: Lecture Notes in Computer Science Volume: 9612 Pages: 285-291 DOI: 10.1007/978-3-319-41754-7_26 Published: 2016","Abstract":"The enormous growth of user-generated information of social networks has caused the need for new algorithms and methods for their classification. The Sentiment Analysis (SA) methods attempt to identify the polarity of a text, using among other resources, the ranking algorithms. One of the most popular ranking algorithms is the Okapi BM25 ranking, designed to rank documents according to their relevance on a topic. In this paper, we present an approach of sentiment analysis for Spanish Tweets based combining the BM25 ranking function with a Linear Support Vector supervised model. We describe the implemented procedure to adapt BM25 to the peculiarities of SA in Twitter. The results confirm the potential of the BM25 algorithm to improve the sentiment analysis tasks.","Authors":"Sixto, J (Sixto, Juan) ; Almeida, A (Almeida, Aitor) ; Lopez-de-Ipina, D (Lopez-de-Ipina, Diego) Edited by:Metais, E; Meziane, F; Saraee, M; Sugumaran, V; Vadera, S","Title":"Improving the Sentiment Analysis Process of Spanish Tweets with BM25"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000386658300270 ISBN:978-1-5090-4093-3","Keywords":"single-option question; BM25; CNN: SDA","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD) Pages: 1572-1576 Published: 2016","Abstract":"In this paper, we develop a question answering system for solving single-option geography questions. The system is built in two directions. One computes semantic similarity between two questions. The other converts the task into question sentence binary-classification by generating the distributed representation of sentence semantic. When computing semantic similarity, we first implement a basic framework based on bag-of-words (BOW), and then extend the framework to Edit Distance variant and BM25 variant. On the other hand, we use convolutional neural network and stacked denoising auto-encoder to generate the distributed representation of sentence semantic respectively. Given the semantic representation of sentence, a logistic regression classifier is employed to classify the sentence. The dataset we use is a large scale Chinese college entrance examination question set of geography, which is clawed from the internet. Experiment results show that the performance of CNN can answer the single-option geography questions with high accuracy, which can achieve 0.7310.","Authors":"Zhao, SS (Zhao, Shanshan) ; Zheng, YQ (Zheng, Yuqing) ; Zhu, CH (Zhu, Conghui) ; Zhao, TJ (Zhao, Tiejun) ; Li, S (Li, Sheng) Edited by:Li, MZ; Xiong, N; Tong, Z; Du, J; Liu, C; Li, KL; Wang, L","Title":"Semantic Computation in Geography Question Answering"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000387579700051 ISSN: 1877-0509","Keywords":"Cross-Language Information Retrieval; Inter-Wiki Link; Wikipedia API","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Telecommunications","Journal Information":"TWELFTH INTERNATIONAL CONFERENCE ON COMMUNICATION NETWORKS, ICCN 2016 / TWELFTH INTERNATIONAL CONFERENCE ON DATA MINING AND WAREHOUSING, ICDMW 2016 / TWELFTH INTERNATIONAL CONFERENCE ON IMAGE AND SIGNAL PROCESSING, ICISP 2016 Book Series: Procedia Computer Science Volume: 89 Pages: 434-440 DOI: 10.1016/j.procs.2016.06.094 Published: 2016","Abstract":"The rapidly increasing demographics of the internet population and the abundance of multilingual content on the web increased the communication in multiple languages. Most of the people use their regional languages to express their needs and the language diversity becomes a great barrier. Cross-Language Information Retrieval (CLIR) provides a solution for that language barrier which allows a user to ask a query in the native language and get the relevant documents in the different language. In this paper, we proposed a Wikipedia API based query translation approach. Queries are tokenized and multi-words query terms are created using N-gram technique. Wikipedia title and inter-wiki link features are exploited for query translation. Target language documents are retrieved using vector space retrieval model and BM25 retrieval algorithm. Experiment results shows that the proposed approach achieves better results without exploiting any language resources. (C) 2016 The Authors. Published by Elsevier B.V.","Authors":"Sharma, VK (Sharma, Vijay Kumar) ; Mittal, N (Mittal, Namita) Edited by:Venugopal, KR; Buyya, R; Patnaik, LM; Shenoy, PD; Iyengar, SS; Raja, KB","Title":"Exploiting Wikipedia API for Hindi-English Cross-Language Information Retrieval"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000382920900033 ISBN:978-1-4673-9044-6 ISSN: 2155-5044","Categories":"Computer Science; Engineering; Telecommunications Web of Science Categories:Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications","Journal Information":"2016 IEEE INTERNATIONAL SYMPOSIUM ON BROADBAND MULTIMEDIA SYSTEMS AND BROADCASTING (BMSB) Book Series: IEEE International Symposium on Broadband Multimedia Systems and Broadcasting Published: 2016","Abstract":"Broadcasting companies have started offering video-on-demand services to provide their viewers with various kinds of TV programs. Most of these services have a program retrieval system that helps users find the TV programs they would like to watch. The conventional systems retrieve TV programs by keyword matching of the query and the TV program summary. However, it is difficult for these systems to retrieve TV programs from small databases (e.g. databases where the broadcasting companies select the programs) because there are only a few programs featuring summaries that include the query. As a result, retrieval systems often output very few programs. To tackle this problem, we propose a new retrieval method using a semantic relations dictionary (SRD). We first generate a graph structure from the SRD and TV programs and then calculate the similarity scores between an input query and all TV programs. We use four metrics - the distance in the graph structure, the number of paths from query to TV program, word similarity and word ambiguity - to calculate similarity scores effectively and efficiently. The system then retrieves TV programs that have a high similarity score with the query. Evaluation results showed that our method can output more programs than the baseline method using okapi BM25, while maintaining a competitive accuracy rate.","Authors":"Miyazaki, T (Miyazaki, Taro) ; Yamada, I (Yamada, Ichiro) ; Miura, K (Miura, Kikuka) ; Miyazaki, M (Miyazaki, Masaru) ; Matsui, A (Matsui, Atsushi) ; Goto, J (Goto, Jun) ; Sumiyoshi, H (Sumiyoshi, Hideki) Book Group Author(s):IEEE","Title":"A New TV Program Retrieval Method Using a Semantic Relations Dictionary"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000379765500004 ISSN: 2050-3806 eISSN: 1758-3748","Keywords":"Query expansion; Personalization; Automatic evaluation; Cross-language information retrieval; Topic models; User profile representation KeyWords Plus:QUERY EXPANSION; MODELS","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"ASLIB JOURNAL OF INFORMATION MANAGEMENT Volume: 68 Issue: 4 Pages: 448-477 DOI: 10.1108/AJIM-06-2015-0091 Published: 2016","Abstract":"Purpose - With an increase in the amount of multilingual content on the World Wide Web, users are often striving to access information provided in a language of which they are non-native speakers. The purpose of this paper is to present a comprehensive study of user profile representation techniques and investigate their use in personalized cross-language information retrieval (CLIR) systems through the means of personalized query expansion. Design/methodology/approach - The user profiles consist of weighted terms computed by using frequency-based methods such as tf-idf and BM25, as well as various latent semantic models trained on monolingual documents and cross-lingual comparable documents. This paper also proposes an automatic evaluation method for comparing various user profile generation techniques and query expansion methods. Findings - Experimental results suggest that latent semantic-weighted user profile representation techniques are superior to frequency-based methods, and are particularly suitable for users with a sufficient amount of historical data. The study also confirmed that user profiles represented by latent semantic models trained on a cross-lingual level gained better performance than the models trained on a monolingual level. Originality/value - Previous studies on personalized information retrieval systems have primarily investigated user profiles and personalization strategies on a monolingual level. The effect of utilizing such monolingual profiles for personalized CLIR remains unclear. The current study fills the gap by a comprehensive study of user profile representation for personalized CLIR and a novel personalized CLIR evaluation methodology to ensure repeatable and controlled experiments can be conducted.","Authors":"Zhou, D (Zhou, Dong) ; Lawless, S (Lawless, Seamus) ; Wu, X (Wu, Xuan) ; Zhao, WY (Zhao, Wenyu) ; Liu, JX (Liu, Jianxun)","Title":"A study of user profile representation for personalized cross-language information retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000369239500001 ISSN: 1574-017X eISSN: 1875-905X","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Information Systems; Telecommunications","Journal Information":"MOBILE INFORMATION SYSTEMS Article Number: 7908328 DOI: 10.1155/2016/7908328 Published: 2016","Abstract":"The smartphones are widely available in recent years. Wireless networks and personalized mobile devices are deeply integrated and embedded in our lives. The behavior based forwarding has become a new transmission paradigm for supporting many novel applications. However, the commodities, services, and individuals usually have multiple properties of their interests and behaviors. In this paper, we profile these multiple properties and propose an Opportunistic Dissemination Protocol based on Multiple Behavior Profile, ODMBP, in mobile social networks. We first map the interest space to the behavior space and extract the multiple behavior profiles from the behavior space. Then, we propose the correlation computing model based on the principle of BM25 to calculate the correlation metric of multiple behavior profiles. The correlation metric is used to forward the message to the users who are more similar to the target in our protocol. ODMBP consists of three stages: user initialization, gradient ascent, and group spread. Through extensive simulations, we demonstrate that the proposed multiple behavior profile and correlation computing model are correct and efficient. Compared to other classical routing protocols, ODMBP can significantly improve the performance in the aspect of delivery ratio, delay, and overhead ratio.","Authors":"Xu, J (Xu, Jia) ; Xiang, JX (Xiang, Jin Xin) ; Chen, X (Chen, Xiang) ; Liu, FB (Liu, Fang Bin) ; Yu, JJ (Yu, Jing Jie)","Title":"ODMBP: Behavior Forwarding for Multiple Property Destinations in Mobile Social Networks"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000372082600001 ISSN: 0924-8463 eISSN: 1572-8382","Keywords":"Legal index extraction; Japanese legal document; Unsupervised approach; Japanese chunk; Japanese clause","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"ARTIFICIAL INTELLIGENCE AND LAW Volume: 23 Issue: 4 Pages: 315-344 DOI: 10.1007/s10506-015-9168-8 Published: DEC 2015","Abstract":"This article addresses the problem of automatically extracting legal indices which express the important contents of legal documents. Legal indices are not limited to single-word keywords and compound-word (or phrase) keywords, they are also clause keywords. We approach index extraction using structural information of Japanese sentences, i.e. chunks and clauses. Based on the assumption that legal indices are composed of important tokens from the documents, extracting legal indices is treated as a problem of collecting chunks and clauses that contain as many important tokens as possible. Each token is assigned a weight which is a statistical score, e.g. TF-IDF and Okapi BM25, to indicate its importance. The importance of a chunk or clause is determined based on the average weight of tokens included in that chunk or clause. Then, highly weighted chunks and clauses are recognized as the indices for legal documents. The experimental results on Japanese National Pension Act data show that our proposed method achieves better performance (8.6 % higher on F1-score) than TextRank, the most popular unsupervised method in extracting single-word and compound-word keywords. In addition, this approach is also applicable to extract clause keywords with high performance.","Authors":"Le, TTN (Tho Thi Ngoc Le) ; Shirai, K (Shirai, Kiyoaki) ; Le Nguyen, M (Minh Le Nguyen) ; Shimazu, A (Shimazu, Akira)","Title":"Extracting indices from Japanese legal documents"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000363437500019 ISSN: 1532-0464 eISSN: 1532-0480","Keywords":"Semantic similarity; Scientific publications; Similarity metrics; Semantic annotations; Related articles KeyWords Plus:TEXT CLASSIFICATION; ONTOLOGY; SEARCH; DOMAIN; MODEL","Categories":"Computer Science; Medical Informatics Web of Science Categories:Computer Science, Interdisciplinary Applications; Medical Informatics","Journal Information":"JOURNAL OF BIOMEDICAL INFORMATICS Volume: 57 Pages: 204-218 DOI: 10.1016/j.jbi.2015.07.015 Published: OCT 2015","Abstract":"Motivation: Although full-text articles are provided by the publishers in electronic formats, it remains a challenge to find related work beyond the title and abstract context. Identifying related articles based on their abstract is indeed a good starting point; this process is straightforward and does not consume as many resources as full-text based similarity would require. However, further analyses may require in-depth understanding of the full content. Two articles with highly related abstracts can be substantially different regarding the full content. How similarity differs when considering title-and-abstract versus full-text and which semantic similarity metric provides better results when dealing with full-text articles are the main issues addressed in this manuscript. Methods: We have benchmarked three similarity metrics - BM25, PMRA, and Cosine, in order to determine which one performs best when using concept-based annotations on full-text documents. We also evaluated variations in similarity values based on title-and-abstract against those relying on full-text. Our test dataset comprises the Genomics track article collection from the 2005 Text Retrieval Conference. Initially, we used an entity recognition software to semantically annotate titles and abstracts as well as full-text with concepts defined in the Unified Medical Language System (UMLS). For each article, we created a document profile, i.e., a set of identified concepts, term frequency, and inverse document frequency; we then applied various similarity metrics to those document profiles. We considered correlation, precision, recall, and F1 in order to determine which similarity metric performs best with concept-based annotations. For those full-text articles available in PubMed Central Open Access (PMC-OA), we also performed dispersion analyses in order to understand how similarity varies when considering full-text articles. Results: We have found that the PubMed Related Articles similarity metric is the most suitable for full-text articles annotated with UMLS concepts. For similarity values above 0.8, all metrics exhibited an F1 around 0.2 and a recall around 0.1; BM25 showed the highest precision close to 1; in all cases the concept-based metrics performed better than the word-stem-based one. Our experiments show that similarity values vary when considering only title-and-abstract versus full-text similarity. Therefore, analyses based on full-text become useful when a given research requires going beyond title and abstract, particularly regarding connectivity across articles. Availability: Visualization available at ljgarcia.github.io/semsim.benchmark/, data available at http://dx.doi.org/10.5281/zenodo.13323. (C) 2015 Elsevier Inc. All rights reserved.","Authors":"Castro, LJG (Garcia Castro, Leyla Jael) ; Berlanga, R (Berlanga, Rafael) ; Garcia, A (Garcia, Alexander)","Title":"In the pursuit of a semantic similarity metric based on UMLS annotations for articles in PubMed Central Open Access"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000360007500014 ISSN: 2157-6904 eISSN: 2157-6912","Keywords":"Algorithms; Design; Experimentation; Human Factors; Phenotype; Genotype; Bipartite; BM25; NDCG KeyWords Plus:DECISION-SUPPORT-SYSTEMS; INTERACTION NETWORKS; COMPLEX TRAITS; SEARCH ENGINE; RARE DISEASES; INFORMATION; PREDICTION; DISORDERS; ONTOLOGY; CARE","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY Volume: 6 Issue: 4 Article Number: 56 DOI: 10.1145/2700487 Published: AUG 2015","Abstract":"With vast amounts of medical knowledge available on the Internet, it is becoming increasingly practical to help doctors in clinical diagnostics by suggesting plausible diseases predicted by applying data and text mining technologies. Recently, Genome-Wide Association Studies (GWAS) have proved useful as a method for exploring phenotypic associations with diseases. However, since genetic diseases are difficult to diagnose because of their low prevalence, large number, and broad diversity of symptoms, genetic disease patients are often misdiagnosed or experience long diagnostic delays. In this article, we propose a method for ranking genetic diseases for a set of clinical phenotypes. In this regard, we associate a phenotype-gene bipartite graph (PGBG) with a gene-disease bipartite graph (GDBG) by producing a phenotype-disease bipartite graph (PDBG), and we estimate the candidate weights of diseases. In our approach, all paths from a phenotype to a disease are explored by considering causative genes to assign a weight based on path frequency, and the phenotype is linked to the disease in a new PDBG. We introduce the Bidirectionally induced Importance Weight (BIW) prediction method to PDBG for approximating the weights of the edges of diseases with phenotypes by considering link information from both sides of the bipartite graph. The performance of our system is compared to that of other known related systems by estimating Normalized Discounted Cumulative Gain (NDCG), Mean Average Precision (MAP), and Kendall's tau metrics. Further experiments are conducted with well-known TF.IDF, BM25, and Jenson-Shannon divergence as baselines. The result shows that our proposed method outperforms the known related tool Phenomizer in terms of NDCG@10, NDCG@20, MAP@10, andMAP@20; however, it performs worse than Phenomizer in terms of Kendall's tau-b metric at the top-10 ranks. It also turns out that our proposed method has overall better performance than the baseline methods.","Authors":"Ullah, MZ (Ullah, Md Zia) ; Aono, M (Aono, Masaki) ; Seddiqui, MH (Seddiqui, Md Hanif)","Title":"Estimating a Ranked List of Human Genetic Diseases by Associating Phenotype-Gene with Gene-Disease Bipartite Graphs"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000356297500003 ISSN: 0219-1377 eISSN: 0219-3116","Keywords":"Focused information retrieval; Structured information retrieval; Proximity; XML; Tags KeyWords Plus:TERM PROXIMITY; XML RETRIEVAL","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"KNOWLEDGE AND INFORMATION SYSTEMS Volume: 44 Issue: 1 Pages: 51-76 DOI: 10.1007/s10115-014-0767-6 Published: JUL 2015","Abstract":"Focused information retrieval is concerned with the retrieval of small units of information. In this context, the structure of the documents as well as the proximity among query terms have been found useful for improving retrieval effectiveness. In this article, we propose an approach combining the proximity of the terms and the tags which mark these terms. Our approach is based on a Fetch and Browse method where the fetch step is performed with BM25 and the browse step with a structure enhanced proximity model. In this way, the ranking of a document depends not only upon the existence of the query terms within the document but also upon the tags which mark these terms. Thus, the document tends to be highly relevant when query terms are close together and are emphasized by tags. The evaluation of this model on a large XML structured collection provided by the INEX 2010 XML IR evaluation campaign shows that the use of term proximity and structure improves the retrieval effectiveness of BM25 in the context of focused information retrieval.","Authors":"Beigbeder, M (Beigbeder, Michel) ; Gery, M (Gery, Mathias) ; Largeron, C (Largeron, Christine)","Title":"Using proximity and tag weights for focused retrieval in structured documents"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000363895500005 ISSN: 2192-6611 eISSN: 2192-662X","Keywords":"Clickthrough data; Concept-based image retrieval; SVM; Fuzzy SVM; Power SVM; Bilateral-weighted Fuzzy SVM KeyWords Plus:SUPPORT VECTOR MACHINES; FUZZY-SVM; CLASSIFICATION","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL Volume: 4 Issue: 2 Pages: 129-142 Special Issue: SI DOI: 10.1007/s13735-015-0080-5 Published: JUN 2015","Abstract":"Clickthrough data is a source of information that can be used for automatically building concept detectors for image retrieval. Previous studies, however, have shown that in many cases the resulting training sets suffer from severe label noise that has a significant impact in the SVM concept detector performance. This paper evaluates and proposes a set of strategies for automatically building effective concept detectors from clickthrough data. These strategies focus on: (1) automatic training set generation; (2) assignment of label confidence weights to the training samples and (3) using these weights at the classifier level to improve concept detector effectiveness. For training set selection and in order to assign weights to individual training samples three Information Retrieval (IR) models are examined: vector space models, BM25 and language models. Three SVM variants that take into account importance at the classifier level are evaluated and compared to the standard SVM: the Fuzzy SVM, the Power SVM, and the Bilateral-weighted Fuzzy SVM. Experiments conducted on the MM Grand Challenge dataset (consisting of 1M images and 82.3M unique clicks) for 40 concepts demonstrate that (1) on average, all weighted SVM variants are more effective than the standard SVM; (2) the vector space model produces the best training sets and best weights; (3) the Bilateral-weighted Fuzzy SVM produces the best results but is very sensitive to weight assignment and (4) the Fuzzy SVM is the most robust training approach for varying levels of label noise.","Authors":"Sarafis, I (Sarafis, Ioannis) ; Diou, C (Diou, Christos) ; Delopoulos, A (Delopoulos, Anastasios)","Title":"Building effective SVM concept detectors from clickthrough data for large-scale image retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000345734700021 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Information Retrieval; Fuzzy Logic Controller; Precision; Recall; Ranking function KeyWords Plus:SIMILARITY MEASURES; TEXT RETRIEVAL; CONTROLLER; FRAMEWORK; RELEVANCE; NUMBERS; TOOLS; SETS","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 42 Issue: 3 Pages: 1223-1234 DOI: 10.1016/j.eswa.2014.09.009 Published: FEB 15 2015","Abstract":"The relevant documents from large data sets are retrieved with the help of ranking function in Information Retrieval system. In this paper, a new fuzzy logic based ranking function is proposed and implemented to enhance the performance of Information Retrieval system. The proposed ranking function is based on the computation of different terms of term-weighting schema such as term frequency, inverse document frequency and normalization. Fuzzy logic is used at two levels to compute relevance score of a document with respect to the query in present work. All the experiments are performed on CACM and CISI benchmark data sets. The experimental results reveal that the performance of our proposed ranking function is much better than the fuzzy based ranking function developed by Rubens along with other widely used ranking function Okapi-BM25 in terms of precision, recall and F-measure. (C) 2014 Elsevier Ltd. All rights reserved.","Authors":"Gupta, Y (Gupta, Yogesh) ; Saini, A (Saini, Ashish) ; Saxena, AK (Saxena, A. K.)","Title":"A new fuzzy logic based ranking function for efficient Information Retrieval system"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000349356300012 ISSN: 1380-7501 eISSN: 1573-7721","Keywords":"Lexical speaker identification; Broadcast conversations; TFIDF; BM25; Speaker roles; Classifier fusion; Crossmedia learning; Wikipedia KeyWords Plus:VERIFICATION","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"MULTIMEDIA TOOLS AND APPLICATIONS Volume: 74 Issue: 4 Pages: 1377-1396 DOI: 10.1007/s11042-014-1940-3 Published: FEB 2015","Abstract":"It is possible to use lexical information extracted from speech transcripts for speaker identification (SID), either on its own or to improve the performance of standard cepstral-based SID systems upon fusion. This was established before typically using isolated speech from single speakers (NIST SRE corpora, parliamentary speeches). On the contrary, this work applies lexical approaches for SID on a different type of data. It uses the REPERE corpus consisting of unsegmented multiparty conversations, mostly debates, discussions and Q&A sessions from TV shows. It is hypothesized that people give out clues to their identity when speaking in such settings which this work aims to exploit. The impact on SID performance of the diarization front-end required to pre-process the unsegmented data is also measured. Four lexical SID approaches are studied in this work, including TFIDF, BM25 and LDA-based topic modeling. Results are analysed in terms of TV shows and speaker roles. Lexical approaches achieve low error rates for certain speaker roles such as anchors and journalists, sometimes lower than a standard cepstral-based Gaussian Supervector - Support Vector Machine (GSV-SVM) system. Also, in certain cases, the lexical system shows modest improvement over the cepstral-based system performance using score-level sum fusion. To highlight the potential of using lexical information not just to improve upon cepstral-based SID systems but as an independent approach in its own right, initial studies on crossmedia SID is briefly reported. Instead of using speech data as all cepstral systems require, this approach uses Wikipedia texts to train lexical speaker models which are then tested on speech transcripts to identify speakers.","Authors":"Roy, A (Roy, Anindya) ; Bredin, H (Bredin, Herve) ; Hartmann, W (Hartmann, William) ; Le, VB (Viet Bac Le) ; Barras, C (Barras, Claude) ; Gauvain, JL (Gauvain, Jean-Luc)","Title":"Lexical speaker identification in TV shows"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000348350600002 ISSN: 1386-4564 eISSN: 1573-7659","Keywords":"Web search; Query segmentation; Relevance ranking; Query processing; Re-ranking; BM25; Term dependency model; Key n-gram extraction","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL Volume: 18 Issue: 1 Pages: 26-50 DOI: 10.1007/s10791-014-9246-7 Published: FEB 2015","Abstract":"In this paper, we try to determine how best to improve state-of-the-art methods for relevance ranking in web searching by query segmentation. Query segmentation is meant to separate the input query into segments, typically natural language phrases. We propose employing the re-ranking approach in query segmentation, which first employs a generative model to create the top k candidates and then employs a discriminative model to re-rank the candidates to obtain the final segmentation result. The method has been widely utilized for structure prediction in natural language processing, but has not been applied to query segmentation, as far as we know. Furthermore, we propose a new method for using the results of query segmentation in relevance ranking, which takes both the original query words and the segmented query phrases as units of query representation. We investigate whether our method can improve three relevance models, namely n-gram BM25, key n-gram model and term dependency model, within the framework of learning to rank. Our experimental results on large scale web search datasets show that our method can indeed significantly improve relevance ranking in all three cases.","Authors":"Wu, HC (Wu, Haocheng) ; Hu, YH (Hu, Yunhua) ; Li, H (Li, Hang) ; Chen, EH (Chen, Enhong)","Title":"A new approach to query segmentation for relevance ranking in web search"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000348051800003 ISSN: 0925-9902 eISSN: 1573-7675","Keywords":"Information retrieval; Query processing; Retrieval models; Ranking; Web search engines; Query log analysis KeyWords Plus:SEARCH; WEB; USERS","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"JOURNAL OF INTELLIGENT INFORMATION SYSTEMS Volume: 44 Issue: 1 Pages: 67-106 DOI: 10.1007/s10844-014-0330-7 Published: FEB 2015","Abstract":"Caching is one of the techniques that Information Retrieval Systems (IRS) and Web Search Engines (WSEs) use to reduce processing costs and attain faster response times. In this paper we introduce Top-K SCRC (Set Cover Results Cache), a novel technique for results caching which aims at maximizing the utilization of cache. Identical queries are treated as in plain results caching (i.e. their evaluation does not require accessing the index), while combinations of cached sub-queries are exploited as in posting lists caching, however the exploited subqueries are not necessarily single-word queries. The problem of finding the right set of cached subqueries to answer an incoming query, is actually the Exact Set Cover problem. This technique can be applied in any best match retrieval model that is based on a decomposable scoring function, and we show that several best-match retrieval models (i.e VSM, Okapi BM25 and hybrid retrieval models) rely on such scoring functions. To increase the capacity (in queries) of the cache only the top-K results of each cached query are stored and we introduce metrics for measuring the accuracy of the composed top-K answer. By analyzing queries submitted to real-world WSEs, we verified that there is a significant proportion of queries whose terms is the result of a union of the terms of other queries. The comparative evaluation over traces of real query sets showed that the Top-K SCRC is on the average two times faster than a plain Top-K RC for the same cache size.","Authors":"Papadakis, M (Papadakis, Myron) ; Tzitzikas, Y (Tzitzikas, Yannis)","Title":"Answering keyword queries through cached subqueries in best match retrieval models"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000387849100072 ISBN:978-1-4503-3274-3","Keywords":"Bag of Visual Words model; Information gain; Vocabulary construction; Image Retrieval KeyWords Plus:RETRIEVAL","Categories":"Computer Science; Imaging Science & Photographic Technology Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Imaging Science & Photographic Technology","Journal Information":"ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL Pages: 503-506 DOI: 10.1145/2671188.2749319 Published: 2015","Abstract":"Content Based Image Retrieval (CBIR) systems retrieve the most similar images to a query image in a collection. One of the most popular models and widely applied in this task is the Bag of Visual Words model (BoVW). In this paper, we introduce an evaluation study of different information gain models used for the construction of a visual word vocabulary. In the proposed framework, the information gain is used as discriminative information to index image features and select the ones that have the highest values of information gain. The empirical experiments made for this study evaluate the effect of four different information gain models: tf-idf, entropy, bm25, tfc with respect to different descriptors and image databases. The results show that selecting the image features based on at least one of the studied information gain model allows the retrieval process to be more accurate than the classical Bag of Visual Words model.","Authors":"Le, HT (Le, Huu Ton) ; Gbehounou, S (Gbehounou, Syntyche) ; Urruty, T (Urruty, Thierry) ; Lecellier, F (Lecellier, Francois) ; Fernandez, C (Fernandez, Christine) Book Group Author(s):ACM","Title":"Information Gain Study for Visual Vocabulary Construction"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380581600289 ISBN:978-1-5108-1790-6","Categories":"Acoustics; Computer Science Web of Science Categories:Acoustics; Computer Science, Interdisciplinary Applications","Journal Information":"16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5 Pages: 1378-1382 Published: 2015","Abstract":"We present an extended technique for spoken content retrieval (SCR) that exploits the prosodic characteristics of spoken terms in order to improve retrieval effectiveness. Our method promotes the rank of speech segments containing a high number of prosodically prominent terms. Given a set of queries and examples of relevant speech segments, we train a classifier to learn differences in the prosodic realisation of spoken terms mentioned in relevant and non-relevant segments. The classifier is trained with a set of lexical and prosodic features that capture local variations of prosodic prominence. For an unseen query, we perform SCR by using an extension of the Okapi BM25 function of probabilistic retrieval that incorporates the prosodic classifier's predictions into the computation of term weights. Experiments with the speech data from the SDPWS corpus of Japanese oral presentations, and the queries and relevance assessment data from the NTCIR SpokenDoc task show that our approach provides improvements over purely text-based SCR approaches.","Authors":"Racca, DN (Racca, David N.) ; Jones, GJF (Jones, Gareth J. F.) Book Group Author(s):ISCA-INT SPEECH COMMUN ASSOC","Title":"Incorporating Prosodic Prominence Evidence into Term Weights for Spoken Content Retrieval"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000382307300096 ISBN:978-1-4503-3621-5","Keywords":"Patent Search; Query Reformulation","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL Pages: 803-806 DOI: 10.1145/2766462.2767801 Published: 2015","Abstract":"In this paper, we investigate the influence of term selection on retrieval performance on the CLEF-IP prior art test collection, using the Description section of the patent query with Language Model (LM) and BM25 scoring functions. We find that an oracular relevance feedback system that extracts terms from the judged relevant documents far outperforms the baseline and performs twice as well on MAP as the best competitor in CLEF-IP 2010. We find a very clear term selection value threshold for use when choosing terms. We also noticed that most of the useful feedback terms are actually present in the original query and hypothesized that the baseline system could be substantially improved by removing negative query terms. We tried four simple automated approaches to identify negative terms for query reduction but we were unable to notably improve on the baseline performance with any of them. However, we show that a simple, minimal interactive relevance feedback approach where terms are selected from only the first retrieved relevant document outperforms the best result from CLEF-IP 2010 suggesting the promise of interactive methods for term selection in patent prior art search.","Authors":"Far, MG (Far, Mona Golestan) ; Sanner, S (Sanner, Scott) ; Bouadjenek, MR (Bouadjenek, Mohamed Reda) ; Ferraro, G (Ferraro, Gabriela) ; Hawking, D (Hawking, David) Book Group Author(s):ACM Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Bouadjenek, Mohamed Reda  http://orcid.org/0000-0003-1807-430X Hawking, David  http://orcid.org/0000-0002-3704-5398","Title":"On Term Selection Techniques for Patent Prior Art Search"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000382307300116 ISBN:978-1-4503-3621-5","Keywords":"Term location; probabilistic information retrieval; noun KeyWords Plus:NOUN PHRASES","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL Pages: 883-886 DOI: 10.1145/2766462.2767827 Published: 2015","Abstract":"Nouns are more important than other parts of speech in information retrieval and are more often found near the beginning or the end of sentences. In this paper, we investigate the effects of rewarding terms based on their location in sentences on information retrieval. Particularly, we propose a novel Term Location (TEL) retrieval model based on BM25 to enhance probabilistic information retrieval, where a kernel-based method is used to capture term placement patterns. Experiments on f ve TREC datasets of varied size and content indicate the proposed model signifcantly outperforms the optimized BM25 and DirichletLM in MAP over all datasets with all kernel functions, and excels the optimized BM25 and DirichletLM over most of the datasets in P@5 and P@20 with different kernel functions.","Authors":"Liu, BY (Liu, Baiyan) ; An, XD (An, Xiangdong) ; Huang, JX (Huang, Jimmy Xiangji) Book Group Author(s):ACM","Title":"Using Term Location Information to Enhance Probabilistic Information Retrieval"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000382307300154 ISBN:978-1-4503-3621-5","Keywords":"Probabilistic Models; Bayesian Inference; Text Retrieval","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL Pages: 1031-1032 DOI: 10.1145/2766462.2767867 Published: 2015","Abstract":"In this demo, we present a web application which allows users to interact with two retrieval models, namely the Binary Independence Model (BIM) and the BM25 model, on a standard TREC collection. The goal of this demo is to give students deeper insight into the consequences of modeling assumptions (BIM vs. BM25) and the consequences of tuning parameter values by means of a two-dimensional representation of probabilities. The application was developed in R, and it is accessible at the following link: http: //gmdn. shinyapps. io/shinyRF04.","Authors":"Di Nunzio, GM (Di Nunzio, Giorgio Maria) Book Group Author(s):ACM","Title":"Shiny on Your Crazy Diagonal"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380773500040 ISBN:978-3-319-25207-0; 978-3-319-25206-3 ISSN: 0302-9743","Keywords":"Microblogging analysis; Online social network; Information retrieval; Microblog search; Experimental study KeyWords Plus:INFORMATION-RETRIEVAL","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Theory & Methods","Journal Information":"NATURAL LANGUAGE PROCESSING AND CHINESE COMPUTING, NLPCC 2015 Book Series: Lecture Notes in Artificial Intelligence Volume: 9362 Pages: 436-443 DOI: 10.1007/978-3-319-25207-0_40 Published: 2015","Abstract":"Microblogging websites have emerged to the center of information production and diffusion, on which people can get useful information from other users' microblog posts. In the era of Big Data, we are overwhelmed by the large amount of microblog posts. To make good use of these informative data, an effective search tool is required specialized for microblog posts. However, it is not trivial to do microblog search due to the following reasons: 1) microblog posts are noisy and time-sensitive rendering general information retrieval models ineffective. 2) Conventional IR models are not designed to consider microblog-specific features. In this paper, we propose to utilize learning to rank model for microblog search. We combine content-based, microblog-specific and temporal features into learning to rank models, which are found to model microblog posts effectively. To study the performance of learning to rank models, we evaluate our models using tweet data set provided by TERC 2011 and TREC 2012 microblogs track with the comparison of three state-of-the-art information retrieval baselines, vector space model, language model, BM25 model. Extensive experimental studies demonstrate the effectiveness of learning to rank models and the usefulness to integrate microblog-specific and temporal information for microblog search task.","Authors":"Li, J (Li, Jing) ; Wei, ZY (Wei, Zhongyu) ; Wei, H (Wei, Hao) ; Zhao, KF (Zhao, Kangfei) ; Chen, JW (Chen, Junwen) ; Wong, KF (Wong, Kam-Fai) Edited by:Li, J; Ji, H; Zhao, D; Feng, Y","Title":"Learning to Rank Microblog Posts for Real-Time Ad-Hoc Search"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000371516200058 ISBN:978-94-6252-124-7 ISSN: 2352-5401","Keywords":"medical record text; semantic analysis; Latent Dirichlet Allocation; BM25 KeyWords Plus:GENE ONTOLOGY","Categories":"Automation & Control Systems; Computer Science; Engineering Web of Science Categories:Automation & Control Systems; Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary","Journal Information":"PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON ELECTROMECHANICAL CONTROL TECHNOLOGY AND TRANSPORTATION Book Series: AER-Advances in Engineering Research Volume: 41 Pages: 305-308 Published: 2015","Abstract":"With the rapid development of medical information, medical data, especially medical record text, are difficult to intelligent analyses, because these data have loose grammar structure. Latent semantic analysis technology in the field of text mining in recent years made extensive research and application, and Latent Dirichlet Allocation(LDA), put forward by Blei, is a method to solve those difficulties. This paper proposed an improved LDA based on BM25 mixture weights method to analyze Chinese medical record text and had a good performance.","Authors":"Jin, XY (Jin, Xinyu) ; Jin, QL (Jin, Qiliang) ; Li, YZ (Li, Yuze) Edited by:Shyu, YH; Zhang, Y","Title":"A Method of Automatic Annotation for Medical Record Text Based on Latent Dirichlet Allocation"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000366623200003 ISSN: 1744-0084 eISSN: 1744-0092","Keywords":"Web search and information extraction; Web structure/linkage mining; Indexing and retrieval of XML data KeyWords Plus:STRUCTURED RETRIEVAL; KEYWORD SEARCH","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INTERNATIONAL JOURNAL OF WEB INFORMATION SYSTEMS Volume: 11 Issue: 4 Pages: 468-490 DOI: 10.1108/IJWIS-04-2015-0017 Published: 2015","Abstract":"Purpose - This paper aims to focus on automatic selection of two important structural concepts required in an XML query, namely, target and constraint concepts, when given a keywords query. Due to the diversities of concepts used in XML resources, it is not easy to select a correct concept when constructing an XML query. Design/methodology/approach - In this paper, a Context-based Term Weighting model that performs term weighting based on part of documents. Each part represents a specific context, thus offering better capturing of concept and term relationship. For query time analysis, a Query Context Graph and two algorithms, namely, Select Target and Constraint (QC) and Select Target and Constraint (QCAS) are proposed to find the concepts for constructing XML query. Findings - Evaluations were performed using structured document for conference domain. For constraint concept selection, the approach CTX + TW achieved better result than its baseline, NCTX, when search term has ambiguous meanings by using context- based scoring for the concepts. CTX + TW also shows its stability on various scoring models like BM25, TFIEF and LM. For target concept selection, CTX + TW outperforms the standard baseline, SLCA, whereas it also records higher coverage than FCA, when structural keywords are used in query. Originality/value - The idea behind this approach is to capture the concepts required for term interpretation based on parts of the collections rather than the entire collection. This allows better selection of concepts, especially when a structured XML document consists many different types of information.","Authors":"Gan, KH (Gan, Keng Hoon) ; Phang, KK (Phang, Keat Keong) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Gan, Keng Hoon  D-1734-2016  ","Title":"Finding target and constraint concepts for XML query construction"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000365947800051 ISBN:978-3-319-24033-6; 978-3-319-24032-9 ISSN: 0302-9743","Keywords":"Textual Georeferencing; Toponym disambiguation; Language models; Information retrieval; Geographical gazetteers","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods","Journal Information":"TEXT, SPEECH, AND DIALOGUE (TSD 2015) Book Series: Lecture Notes in Artificial Intelligence Volume: 9302 Pages: 452-460 DOI: 10.1007/978-3-319-24033-6_51 Published: 2015","Abstract":"This paper describes Knowledge-Based and Data-Driven approaches we have followed for generic Textual Georeferencing of Informal Documents. Textual Georeferencing consists in assigning a set of geographical coordinates to formal (news, reports,..) or informal (blogs, social networks, chats, tagsets,...) texts and documents. The system presented in this paper has been designed to deal with informal documents from social sites. The paper describes four Georeferencing approaches, experiments, and results at the MediaEval 2014 Placing Task (ME2014PT) evaluation, and posterior experiments. The task consisted of predicting the most probable geographical coordinates of Flickr images and videos using its visual, audio and metadata associated features. Our approaches used only Flickr users textual metadata annotations and tagsets. The four approaches used for this task were: 1) a Geographical Knowledge-Based (GeoKB) approach that uses Toponym Disambiguation heuristics, 2) the Hiemstra Language Model (HLM), TFIDF and BM25 Information Retrieval (IR) approaches with Re-Ranking, 3) a combination of the GeoKB and the IR models with Re-Ranking (Geo-Fusion), 4) a combination of the GeoFusion with a HLM model derived from the English Wikipedia georeferenced pages. The HLM approach with Re-Ranking showed the best performance in accuracy within a margin of distance errors ranging from 10m to 1km. The GeoFusion approaches achieved the best results in accuracies from 10km to 5,000km. Both approaches achieved state-of-the-art results at ME2014PT evaluation and posterior experiments, including the best results for distance accuracies of 1000km and 5,000km in the task where only the official training dataset can be used to predict the coordinates.","Authors":"Ferres, D (Ferres, Daniel) ; Rodriguez, H (Rodriguez, Horacio) Edited by:Kral, P; Matousek, V","Title":"Knowledge-Based and Data-Driven Approaches for Georeferencing of Informal Documents"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000365853300003 ISBN:978-3-319-24592-8; 978-3-319-24591-1 ISSN: 0302-9743","Keywords":"Scientific data management; Survey question retrieval; Survey question reuse; Query expansion; Co-occurrence analysis; Thesauri; Evaluation KeyWords Plus:INFORMATION-RETRIEVAL; DIGITAL LIBRARIES","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"RESEARCH AND ADVANCED TECHNOLOGY FOR DIGITAL LIBRARIES Book Series: Lecture Notes in Computer Science Volume: 9316 Pages: 28-39 DOI: 10.1007/978-3-319-24592-8_3 Published: 2015","Abstract":"In recent years, the importance of research data and the need to archive and to share it in the scientific community have increased enormously. This introduces a whole new set of challenges for digital libraries. In the social sciences typical research data sets consist of surveys and questionnaires. In this paper we focus on the use case of social science survey question reuse and on mechanisms to support users in the query formulation for data sets. We describe and evaluate thesaurus-and co-occurrence-based approaches for query expansion to improve retrieval quality in digital libraries and research data archives. The challenge here is to translate the information need and the underlying sociological phenomena into proper queries. As we can show retrieval quality can be improved by adding related terms to the queries. In a direct comparison automatically expanded queries using extracted co-occurring terms can provide better results than queries manually reformulated by a domain expert and better results than a keyword-based BM25 baseline.","Authors":"Dulisch, N (Dulisch, Nadine) ; Kempf, AO (Kempf, Andreas Oskar) ; Schaer, P (Schaer, Philipp) Edited by:Kapidakis, S; Mazurek, C; Werla, M Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number kiaie, robabeh  I-2157-2016 http://orcid.org/0000-0001-5251-3201 kiaie, fatemeh  I-6083-2016  ","Title":"Query Expansion for Survey Question Retrieval in the Social Sciences"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000365863300030 ISBN:978-3-319-23826-5; 978-3-319-23825-8 ISSN: 0302-9743","Keywords":"Information retrieval; Geographical gazetteers; Natural language processing; Toponym disambiguation; Query expansion; Efectiveness measures KeyWords Plus:GEOCLEF","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"STRING PROCESSING AND INFORMATION RETRIEVAL (SPIRE 2015) Book Series: Lecture Notes in Computer Science Volume: 9309 Pages: 311-323 DOI: 10.1007/978-3-319-23826-5_30 Published: 2015","Abstract":"This paper describes and evaluates the use of Geographical Knowledge Re-Ranking, Linguistic Processing, and Query Expansion techniques to improve Geographical Information Retrieval effectiveness. Geographical Knowledge Re-Ranking is performed with Geographical Gazetteers and conservative Toponym Disambiguation techniques that boost the ranking of the geographically relevant documents retrieved by standard state-of-the-art Information Retrieval algorithms. Linguistic Processing is performed in two ways: 1) Part-of-Speech tagging and Named Entity Recognition and Classification are applied to analyze the text collections and topics to detect toponyms, 2) Stemming (Porter's algorithm) and Lemmatization are also applied in combination with default stopwords filtering. The Query Expansion methods tested are the Bose-Einstein (Bo1) and Kullback-Leibler term weighting models. The experiments have been performed with the English Monolingual test collections of the GeoCLEF evaluations (from years 2005, 2006, 2007, and 2008) using the TF-IDF, BM25, and InL2 Information Retrieval algorithms over unprocessed texts as baselines. The experiments have been performed with each GeoCLEF test collection (25 topics per evaluation) separately and with the fusion of all these collections (100 topics). The results of evaluating separately Geographical Knowledge Re-Ranking, Linguistic Processing (lemmatization, stemming, and the combination of both), and Query Expansion with the fusion of all the topics show that all these processes improve the Mean Average Precision (MAP) and RPrecision effectiveness measures in all the experiments and show statistical significance over the baselines in most of them. The best results in MAP and RPrecision are obtained with the InL2 algorithm using the following techniques: Geographical Knowledge Re-Ranking, Lemmatization with Stemming, and Kullback-Leibler Query Expansion. Some configurations with Geographical Knowledge Re-Ranking, Linguistic Processing and Query Expansion have improved the MAP of the best official results at GeoCLEF evaluations of 2005, 2006, and 2007.","Authors":"Ferres, D (Ferres, Daniel) ; Rodriguez, H (Rodriguez, Horacio) Edited by:Iliopoulos, CS; Puglisi, SJ; Yilmaz, E","Title":"Evaluating Geographical Knowledge Re-Ranking, Linguistic Processing and Query Expansion Techniques for Geographical Information Retrieval"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000393162800069 ISBN:978-1-4673-9618-9","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2015 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT), VOL 1 Pages: 409-412 DOI: 10.1109/WI-IAT.2015.159 Published: 2015","Abstract":"Nowadays, an ever increasing number of news articles is published on a daily basis. Especially after notable national and international events or disasters, news coverage rises tremendously. Temporal summarization is an approach to automatically summarize such information in a timely manner. Summaries are created incrementally with progressing time, as soon as new information is available. Given a user-defined query, we designed a temporal summarizer based on probabilistic language models and entity recognition. First, all relevant documents and sentences are extracted from a stream of news documents using BM25 scoring. Second, a general query language model is created which is used to detect typical sentences respective to the query with Kullback-Leibler divergence. Based on the retrieval result, this query model is extended over time by terms appearing frequently during the particular event. Our system is evaluated with a document corpus including test data provided by the Text Retrieval Conference (TREC).","Authors":"Schubotz, T (Schubotz, Tobias) ; Krestel, R (Krestel, Ralf) Book Group Author(s):IEEE","Title":"Online Temporal Summarization of News Events"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000353985500003 PubMed ID: 25560088 ISSN: 1475-925X","Categories":"Engineering Web of Science Categories:Engineering, Biomedical","Journal Information":"BIOMEDICAL ENGINEERING ONLINE Volume: 13 Supplement: 2 Article Number: S3 DOI: 10.1186/1475-925X-13-S2-S3 Published: DEC 11 2014","Abstract":"Background: Different from traditional information retrieval (IR), promoting diversity in IR takes consideration of relationship between documents in order to promote novelty and reduce redundancy thus to provide diversified results to satisfy various user intents. Diversity IR in biomedical domain is especially important as biologists sometimes want diversified results pertinent to their query. Methods: A combined learning-to-rank (LTR) framework is learned through a general ranking model (gLTR) and a diversity-biased model. The former is learned from general ranking features by a conventional learning-to-rank approach; the latter is constructed with diversity-indicating features added, which are extracted based on the retrieved passages' topics detected using Wikipedia and ranking order produced by the general learning-to-rank model; final ranking results are given by combination of both models. Results: Compared with baselines BM25 and DirKL on 2006 and 2007 collections, the gLTR has 0.2292 (+16.23% and +44.1% improvement over BM25 and DirKL respectively) and 0.1873 (+15.78% and +39.0% improvement over BM25 and DirKL respectively) in terms of aspect level of mean average precision (Aspect MAP). The LTR method outperforms gLTR on 2006 and 2007 collections with 4.7% and 2.4% improvement in terms of Aspect MAP. Conclusions: The learning-to-rank method is an efficient way for biomedical information retrieval and the diversity-biased features are beneficial for promoting diversity in ranking results.","Authors":"Wu, JJ (Wu, Jiajin) ; Huang, JX (Huang, Jimmy Xiangji) ; Ye, Z (Ye, Zheng)","Title":"Learning to rank diversified results for biomedical information retrieval from multiple features"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000346182400011 ISSN: 0165-5515 eISSN: 1741-6485","Keywords":"Fuzzy inference system; information retrieval; precision; recall; similarity measure; vector space model KeyWords Plus:RANKING; MODEL; SETS","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF INFORMATION SCIENCE Volume: 40 Issue: 6 Pages: 846-857 DOI: 10.1177/0165551514548989 Published: DEC 2014","Abstract":"A similarity measure is used in information retrieval systems to retrieve and rank the relevant documents. In this paper, a new fuzzy-based approach to develop hybrid similarity measure is proposed and implemented. The proposed approach overcomes the limitations of extensively used similarity measures such as Cosine, Jaccard, Euclidean and Okapi-BM25 along with Genetic Algorithm-based hybrid similarity measures proposed by researchers. This approach uses fuzzy rules to infer the weights of different similarity measures. In this paper, the experiments are performed on CACM and CISI benchmark data collections. The performance of the proposed approach is evaluated in terms of precision, recall and average precision and average recall of retrieved relevant documents. The results are compared with different similarity measures available in literature. The results show the marked improvement in performance of information retrieval systems using the proposed fuzzy logic-based hybrid similarity measure.","Authors":"Gupta, Y (Gupta, Yogesh) ; Saini, A (Saini, Ashish) ; Saxena, AK (Saxena, A. K.)","Title":"Fuzzy logic-based approach to develop hybrid similarity measure for efficient information retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000344720200017 ISSN: 1520-9210 eISSN: 1941-0077","Keywords":"BM25 with exponential IDF; content-based video retrieval (CBVR); instance video search KeyWords Plus:RETRIEVAL; SCALE; VIDEO; TEXT; IR","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications","Journal Information":"IEEE TRANSACTIONS ON MULTIMEDIA Volume: 16 Issue: 6 Pages: 1690-1699 DOI: 10.1109/TMM.2014.2323945 Published: OCT 2014","Abstract":"This paper deals with a novel concept of an exponential IDF in the BM25 formulation and compares the search accuracy with that of the BM25 with the original IDF in a content-based video retrieval (CBVR) task. Our video retrieval method is based on a bag of keypoints (local visual features) and the exponential IDF estimates the keypoint importance weights more accurately than the original IDF. The exponential IDF is capable of suppressing the keypoints from frequently occurring background objects in videos, and we found that this effect is essential for achieving improved search accuracy in CBVR. Our proposed method is especially designed to tackle instance video search, one of the CBVR tasks, and we demonstrate its effectiveness in significantly enhancing the instance search accuracy using the TRECVID2012 video retrieval dataset.","Authors":"Murata, M (Murata, Masaya) ; Nagano, H (Nagano, Hidehisa) ; Mukai, R (Mukai, Ryo) ; Kashino, K (Kashino, Kunio) ; Satoh, S (Satoh, Shin'ichi)","Title":"BM25 With Exponential IDF for Instance Search"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000340233700006 PubMed ID: 24680188 ISSN: 0933-3657 eISSN: 1873-2860","Keywords":"Statistical machine translation; Domain adaptation of statistical machine translation; Intelligent training data selection for machine translation; Compound splitting; Cross-language information retrieval; Medical query translation KeyWords Plus:PERFORMANCE; EXPANSION; SYSTEMS; CORPUS; WEB","Categories":"Computer Science; Engineering; Medical Informatics Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics","Journal Information":"ARTIFICIAL INTELLIGENCE IN MEDICINE Volume: 61 Issue: 3 Pages: 165-185 Special Issue: SI DOI: 10.1016/j.artmed.2014.01.004 Published: JUL 2014","Abstract":"Objective: We investigate machine translation (MT) of user search queries in the context of cross-lingual information retrieval (IR) in the medical domain. The main focus is on techniques to adapt MT to increase translation quality; however, we also explore MT adaptation to improve effectiveness of cross-lingual IR. Methods and data: Our MT system is Moses, a state-of-the-art phrase-based statistical machine translation system. The IR system is based on the BM25 retrieval model implemented in the Lucene search engine. The MT techniques employed in this work include in-domain training and tuning, intelligent training data selection, optimization of phrase table configuration, compound splitting, and exploiting synonyms as translation variants. The IR methods include morphological normalization and using multiple translation variants for query expansion. The experiments are performed and thoroughly evaluated on three language pairs: Czech-English, German-English, and French-English. MT quality is evaluated on data sets created within the Khresmoi project and IR effectiveness is tested on the CLEF eHealth 2013 data sets. Results: The search query translation results achieved in our experiments are outstanding - our systems outperform not only our strong baselines, but also Google Translate and Microsoft Bing Translator in direct comparison carried out on all the language pairs. The baseline BLEU scores increased from 26.59 to 41.45 for Czech-English, from 23.03 to 40.82 for German-English, and from 32.67 to 40.82 for French-English. This is a 55% improvement on average. In terms of the IR performance on this particular test collection, a significant improvement over the baseline is achieved only for French-English. For Czech-English and German-English, the increased MT quality does not lead to better IR results. Conclusions: Most of the MT techniques employed in our experiments improve MT of medical search queries. Especially the intelligent training data selection proves to be very successful for domain adaptation of MT. Certain improvements are also obtained from German compound splitting on the source language side. Translation quality, however, does not appear to correlate with the IR performance - better translation does not necessarily yield better retrieval. We discuss in detail the contribution of the individual techniques and state-of-the-art features and provide future research directions.. (C) 2014 Elsevier B.V. All rights reserved.","Authors":"Pecina, P (Pecina, Pavel) ; Dusek, O (Dusek, Ondrej) ; Goeuriot, L (Goeuriot, Lorraine) ; Hajic, J (Hajic, Jan) ; Hlavacova, J (Hlavacova, Jaroslava) ; Jones, GJF (Jones, Gareth J. F.) ; Kelly, L (Kelly, Liadh) ; Leveling, J (Leveling, Johannes) ; Marecek, D (Marecek, David) ; Novak, M (Novak, Michal) ; Popel, M (Popel, Martin) ; Rosa, R (Rosa, Rudolf) ; Tamchyna, A (Tamchyna, Ales) ; Uresova, Z (Uresova, Zdenka) ...More...Less Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Hajic, Jan  D-3429-2017 http://orcid.org/0000-0002-3503-7730 Rosa, Rudolf  D-4427-2017 http://orcid.org/0000-0003-4908-6127 Marecek, David  F-2855-2017 http://orcid.org/0000-0001-5327-488X Leveling, Johannes  http://orcid.org/0000-0003-0603-4191","Title":"Adaptation of machine translation for multilingual information retrieval in the medical domain"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000338317400023 ISSN: 1380-7501 eISSN: 1573-7721","Keywords":"Information retrieval; Term weighting; Discrimination power; Difference based DP; Evidential weight","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"MULTIMEDIA TOOLS AND APPLICATIONS Volume: 71 Issue: 2 Pages: 769-781 DOI: 10.1007/s11042-013-1420-1 Published: JUL 2014","Abstract":"One of the most important research topics in Information Retrieval is term weighting for document ranking and retrieval, such as TFIDF, BM25, etc. We propose a term weighting method that utilizes past retrieval results consisting of the queries that contain a particular term, retrieval documents, and their relevance judgments. A term's Discrimination Power(DP) is based on the difference degree of the term's average weights obtained from between relevant and non-relevant retrieved document sets. The difference based DP performs better compared to ratio based DP introduced in the previous research. Our experimental result shows that a term weighting scheme based on the discrimination power method outperforms a TF*IDF based scheme.","Authors":"Li, Q (Li, Qing) ; Lee, S (Lee, Seungwoo) ; Jung, H (Jung, Hanmin) ; Lee, YS (Lee, Yeong Su) ; Cho, JH (Cho, Jae-Hyun) ; Song, SK (Song, Sa-kwang)","Title":"Term weighting for information retrieval based on term's discrimination power"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000337030700011 ISSN: 2330-1635 eISSN: 2330-1643","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY Volume: 65 Issue: 7 Pages: 1463-1477 DOI: 10.1002/asi.23052 Published: JUL 2014","Abstract":"The article describes a semi-supervised approach to extracting multiword aspects of user-written reviews that belong to a given category. The method starts with a small set of seed words, representing the target category, and calculates distributional similarity between the candidate and seed words. We compare 3 distributional similarity measures (Lin's, Weeds's, and balAPinc), and a document retrieval function, BM25, adapted as a word similarity measure. We then introduce a method for identifying multiword aspects by using a combination of syntactic rules and a co-occurrence association measure. Finally, we describe a method for ranking multiword aspects by the likelihood of belonging to the target aspect category. The task used for evaluation is extraction of restaurant dish names from a corpus of restaurant reviews.","Authors":"Vechtomova, O (Vechtomova, Olga)","Title":"A Method for Automatic Extraction of Multiword Units Representing Business Aspects From User Reviews"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000335583900004 ISSN: 2330-1635 eISSN: 2330-1643","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY Volume: 65 Issue: 6 Pages: 1134-1148 DOI: 10.1002/asi.23024 Published: JUN 2014","Abstract":"While term independence is a widely held assumption in most of the established information retrieval approaches, it is clearly not true and various works in the past have investigated a relaxation of the assumption. One approach is to use n-grams in document representation instead of unigrams. However, the majority of early works on n-grams obtained only modest performance improvement. On the other hand, the use of information based on supporting terms or \"contexts\" of queries has been found to be promising. In particular, recent studies showed that using new context-dependent term weights improved the performance of relevance feedback (RF) retrieval compared with using traditional bag-of-words BM25 term weights. Calculation of the new term weights requires an estimation of the local probability of relevance of each query term occurrence. In previous studies, the estimation of this probability was based on unigrams that occur in the neighborhood of a query term. We explore an integration of the n-gram and context approaches by computing context-dependent term weights based on a mixture of unigrams and bigrams. Extensive experiments are performed using the title queries of the Text Retrieval Conference (TREC)-6, TREC-7, TREC-8, and TREC-2005 collections, for RF with relevance judgment of either the top 10 or top 20 documents of an initial retrieval. We identify some crucial elements needed in the use of bigrams in our methods, such as proper inverse document frequency (IDF) weighting of the bigrams and noise reduction by pruning bigrams with large document frequency values. We show that enhancing context-dependent term weights with bigrams is effective in further improving retrieval performance.","Authors":"Dang, EKF (Dang, Edward K. F.) ; Luk, RWP (Luk, Robert W. P.) ; Allan, J (Allan, James) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Luk, Robert  B-9382-2015 http://orcid.org/0000-0002-9310-8867","Title":"Beyond Bag-of-Words: Bigram-Enhanced Context-Dependent Term Weights"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000334860600001 ISSN: 1674-733X eISSN: 1869-1919","Keywords":"XML; keywords search; information retrieval; ranking model; keyword distribution; evaluation KeyWords Plus:TERM PROXIMITY","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"SCIENCE CHINA-INFORMATION SCIENCES Volume: 57 Issue: 5 Article Number: 052107 DOI: 10.1007/s11432-012-4781-6 Published: MAY 2014","Abstract":"Keyword search enables web users to easily access XML data without understanding the complex data schemas. However, the native ambiguity of keyword search makes it arduous to select qualified relevant results matching keywords. To solve this problem, researchers have made much effort on establishing ranking models distinguishing relevant and irrelevant passages, such as the highly cited TF*IDF and BM25. However, these statistic based ranking methods mostly consider term frequency, inverse document frequency and length as ranking factors, ignoring the distribution and connection information between different keywords. Hence, these widely used ranking methods are powerless on recognizing irrelevant results when they are with high term frequency, indicating a performance limitation. In this paper, a new searching system XDist is accordingly proposed to attack the problems aforementioned. In XDist, we firstly use the semantic query model maximal lowest common ancestor (MAXLCA) to recognize the returned results of a given query, and then these candidate results are ranked by BM25. Especially, XDist re-ranks the top several results by a combined distribution measurement (CDM) which considers four measure criterions: term proximity, intersection of keyword classes, degree of integration among keywords and quantity variance of keywords. The weights of the four measures in CDM are trained by a listwise learning to optimize method. The experimental results on the evaluation platform of INEX show that the re-ranking method CDM can effectively improve the performance of the baseline BM25 by 22% under iP[0.01] and 18% under MAiP. Also the semantic model MAXLCA and the search engine XDist perform the best in their respective related fields.","Authors":"Gao, N (Gao Ning) ; Deng, ZH (Deng ZhiHong) ; Lu, SL (Lu ShengLong)","Title":"XDist: an effective XML keyword search system with re-ranking model based on keyword distribution"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000335573900002 ISSN: 1046-8188 eISSN: 1558-2868","Keywords":"Theory; Experimentation; Algorithms; Performance; Cross term; BM25; probabilistic information retrieval; kernel; term association; N-gram KeyWords Plus:TEXT RETRIEVAL; PERFORMANCE; PROXIMITY","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"ACM TRANSACTIONS ON INFORMATION SYSTEMS Volume: 32 Issue: 2 Article Number: 7 DOI: 10.1145/2590988 Published: APR 2014","Abstract":"Traditionally, in many probabilistic retrieval models, query terms are assumed to be independent. Although such models can achieve reasonably good performance, associations can exist among terms from a human being's point of view. There are some recent studies that investigate how to model term associations/dependencies by proximity measures. However, the modeling of term associations theoretically under the probabilistic retrieval framework is still largely unexplored. In this article, we introduce a new concept cross term, to model term proximity, with the aim of boosting retrieval performance. With cross terms, the association of multiple query terms can be modeled in the same way as a simple unigram term. In particular, an occurrence of a query term is assumed to have an impact on its neighboring text. The degree of the query-term impact gradually weakens with increasing distance from the place of occurrence. We use shape functions to characterize such impacts. Based on this assumption, we first propose a bigram CRoss TErm Retrieval (CRTER2) model as the basis model, and then recursively propose a generalized n-gram CRoss TErm Retrieval (CRTERn) model for n query terms, where n > 2. Specifically, a bigram cross term occurs when the corresponding query terms appear close to each other, and its impact can be modeled by the intersection of the respective shape functions of the query terms. For an n-gram cross term, we develop several distance metrics with different properties and employ them in the proposed models for ranking. We also show how to extend the language model using the newly proposed cross terms. Extensive experiments on a number of TREC collections demonstrate the effectiveness of our proposed models.","Authors":"Zhao, JS (Zhao, Jiashu) ; Huang, JX (Huang, Jimmy Xiangji) ; Ye, Z (Ye, Zheng)","Title":"Modeling Term Associations for Probabilistic Information Retrieval"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000364227600014 ISBN:978-1-4799-6814-5","Keywords":"clickthrough data; concept based image retrieval; Support Vector Machine; Fuzzy SVM; Power SVM KeyWords Plus:SUPPORT VECTOR MACHINES; FUZZY-SVM; IMAGE RETRIEVAL","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2014 9TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP) Pages: 66-71 DOI: 10.1109/SMAP.2014.22 Published: 2014","Abstract":"In this paper we extend our previous work on strategies for automatically constructing noise resilient SVM detectors from clickthrough data for large scale concept-based image retrieval. First, search log data is used in conjunction with Information Retrieval (IR) models to score images with respect to each concept. The IR models evaluated in this work include Vector Space Models (VSM), BM25 and Language Models (LM). The scored images are then used to create training sets for SVM and appropriate sample weights for two SVM variants: the Fuzzy SVM (FSVM) and the Power SVM (PSVM). These SVM variants incorporate weights for each individual training sample and can therefore be used to model label uncertainty at the classifier level. Experiments on the MSR-Bing Image Retrieval Grand Challenge dataset (consisting of 1M images and 82.3M unique clicks) show that FSVM is the most robust SVM algorithm for handling label noise and that the highest performance is achieved with weights derived from VSM. These results extend our previous findings on the value of FSVM from professional image archives to largescale general purpose search engines, and furthermore identify VSM as the most appropriate sample weighting model.","Authors":"Sarafis, I (Sarafis, Ioannis) ; Diou, C (Diou, Christos) ; Delopoulos, A (Delopoulos, Anastasios) Book Group Author(s):IEEE","Title":"Building robust concept detectors from clickthrough data: A study in the MSR-Bing dataset"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000358999700242 ISBN:978-1-4799-3080-7","Keywords":"Information retrieval; similarity function; fuzzy logic; precision; recall KeyWords Plus:SETS","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI) Pages: 1472-1478 Published: 2014","Abstract":"In this paper, a novel approach is presented to construct a similarity function to make information retrieval efficient. This approach is based on different terms of term-weighting schema like term frequency, inverse document frequency and normalization. The proposed similarity function uses fuzzy logic to determine similarity score of a document against a query. All the experiments are done with CACM benchmark data collection. The experimental results reveal that the performance of proposed similarity function is much better than the fuzzy based ranking function developed by Rubens along with other widely used similarity function Okapi-BM25 in terms of precision rate and recall rate.","Authors":"Gupta, Y (Gupta, Yogesh) ; Saini, A (Saini, Ashish) ; Saxena, AK (Saxena, A. K.) Book Group Author(s):IEEE","Title":"A New Similarity Function for Information Retrieval based on Fuzzy Logic"}, {"Document Information":"Document Type:Proceedings Paper Language:French Accession Number: WOS:000339308100068 ISBN:978-0-9860419-2-1","Categories":"Business & Economics; Environmental Sciences & Ecology; Public Administration Web of Science Categories:Business; Economics; Environmental Studies; Planning & Development","Journal Information":"VISION 2020: SUSTAINABLE GROWTH, ECONOMIC DEVELOPMENT, AND GLOBAL COMPETITIVENESS, VOLS 1-5 Pages: 596-605 Published: 2014","Abstract":"The multilingual encyclopedia Wikipedia has become a very useful resource for the construction and enrichment of linguistic resources, such as dictionaries and ontologies. In this study, we are interested by the exploitation of Wikipedia for query translation in Cross-Language Information Retrieval. An application is completed for the Arabic-English pair of languages. All possible translation candidates are extracted from the titles of Wikipedia articles based on the inter-links between Arabic and English; which is considered as direct translation. Furthermore, other links such as Arabic to French and French to English are exploited for a transitive translation. A slight stemming and segmentation of the query into multiple tokens can be made if no translation can be found for the entire query. Assessments monolingual and cross-lingual systems were conducted using three weighting schemes of the Lucene search engine (default, Tf-Idf and BM25). In addition, the performance of the so-called translation method was compared with those of GoogleTranslate and MyMemory.","Authors":"Chakour, H (Chakour, Habiba) ; Sadat, F (Sadat, Fatiha) Edited by:Soliman, KS","Title":"Acquisition of Translations of Requests from Wikipedia for the Research of Translingual Information"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000331830800001 ISSN: 1537-744X","Categories":"Science & Technology - Other Topics Web of Science Categories:Multidisciplinary Sciences","Journal Information":"SCIENTIFIC WORLD JOURNAL Article Number: 404518 DOI: 10.1155/2014/404518 Published: 2014","Abstract":"XML document is now widely used for modelling and storing structured documents. The structure is very rich and carries important information about contents and their relationships, for example, e-Commerce. XML data-centric collections require query terms allowing users to specify constraints on the document structure; mapping structure queries and assigning the weight are significant for the set of possibly relevant documents with respect to structural conditions. In this paper, we present an extension to the MEXIR search system that supports the combination of structural and content queries in the form of content-and-structure queries, which we call the Exponentiation function. It has been shown the structural information improve the effectiveness of the search system up to 52.60% over the baseline BM25 at MAP.","Authors":"Wichaiwong, T (Wichaiwong, Tanakorn) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Wichaiwong, Tanakorn  http://orcid.org/0000-0002-6936-3120","Title":"An Exponentiation Method for XML Element Retrieval"}, {"Keywords":"Short text stream; Incremental clustering; BM25; Cluster cohesion; Keyword similarity","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2014 IEEE 3rd International Conference on Cloud Computing and Intelligence Systems (CCIS) Book Series: International Conference on Cloud Computing and Intelligence Systems Pages: 8-12 Published: 2014","Abstract":"Since short text is short of keywords and has sparse features, it brings about the similarity drift problem. The traditional clustering algorithms are usually ineffective and a waste of resources on dealing with short text stream. To overcome the above problems, this paper proposes an incremental clustering algorithm in short text streams based on BM25. The approach makes full use of BM25 to extract keywords and weights of each cluster, and applies extracted parameters to similarity calculation. Theoretical analysis and experiments show that the proposed incremental clustering algorithm solves the similarity drift problem well and achieves satisfactory accuracy and performance in terms of short text stream clustering, compared with the traditional clustering algorithms.","Authors":"Xu, LX (Xu, Lixin) ; Chen, G (Chen, Guang) ; Yang, L (Yang, Lei) Edited by:Ma, H; Wang, W; Zhang, Y","Title":"INCREMENTAL CLUSTERING IN SHORT TEXT STREAMS BASED ON BM25"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380531000050 ISBN:978-1-4799-8075-8 ISSN: 2330-4588","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"2014 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER SCIENCE AND INFORMATION SYSTEMS (ICACSIS) Book Series: International Conference on Advanced Computer Science and Information Systems Pages: 309-314 Published: 2014","Abstract":"One important task in cross-language information retrieval (CLIR) is to determine the relevance of a document from a number of documents based on user query. In this paper we applied pointwise learning to rank in SVM (Support Vector Machine) to determine the relevance of a document and used BM25 (Best Match 25) ranking function for selecting words as features. We did the experiment in Indonesian English CLIR. The results show an average ability of SVM to identify relevant documents is 88.51%, while the average accuracy of SVM to identify non relevant documents is 88%.","Authors":"Sari, S (Sari, Syandra) ; Adriani, M (Adriani, Mirna) Book Group Author(s):IEEE","Title":"Learning to Rank for Determining Relevant Document in Indonesian-English Cross Language Information Retrieval using BM25"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000324233500018 PubMed ID: 23788705 ISSN: 0022-0949 eISSN: 1477-9145","Keywords":"Microcystis sp.; cyanotoxins; Daphnia; protease inhibitors; nutrient limitation; grazer defence KeyWords Plus:BLUE-GREEN-ALGAE; MICROCYSTIS-AERUGINOSA; NUTRITIONAL CONSTRAINTS; PHOSPHORUS LIMITATION; CHEMICAL-COMPOSITION; SEASONAL SUCCESSION; GENE-EXPRESSION; FOOD QUALITY; FATTY-ACIDS; PHYTOPLANKTON","Categories":"Life Sciences & Biomedicine - Other Topics Web of Science Categories:Biology","Journal Information":"JOURNAL OF EXPERIMENTAL BIOLOGY Volume: 216 Issue: 19 Pages: 3649-3655 DOI: 10.1242/jeb.088849 Published: OCT 2013","Abstract":"Herbivore-plant interactions have been well studied in both terrestrial and aquatic ecosystems as they are crucial for the trophic transfer of energy and matter. In nutrient-rich freshwater ecosystems, the interaction between primary producers and herbivores is to a large extent represented by Daphnia and cyanobacteria. The occurrence of cyanobacterial blooms in lakes and ponds has, at least partly, been attributed to cyanotoxins, which negatively affect the major grazer of planktonic cyanobacteria, i.e. Daphnia. Among these cyanotoxins are the widespread protease inhibitors. These inhibitors have been shown (both in vitro and in situ) to inhibit the most important group of digestive proteases in the gut of Daphnia, i.e. trypsins and chymotrypsins, and to reduce Daphnia growth. In this study we grew cultures of the cyanobacterium Microcystis sp. strain BM25 on nutrient-replete, N-depleted or P-depleted medium. We identified three different micropeptins to be the cause for the inhibitory activity of BM25 against chymotrypsins. The micropeptin content depended on nutrient availability: whereas N limitation led to a lower concentration of micropeptins per biomass, P limitation resulted in a higher production of these chymotrypsin inhibitors. The altered micropeptin content of BM25 was accompanied by changed effects on the fitness of Daphnia magna: a higher content of micropeptins led to lower IC50 values for D. magna gut proteases and vice versa. Following expectations, the lower micropeptin content in the N-depleted BM25 caused higher somatic growth of D. magna. Therefore, protease inhibitors can be regarded as a nutrient-dependent defence against grazers. Interestingly, although the P limitation of the cyanobacterium led to a higher micropeptin content, high growth of D. magna was observed when they were fed with P-depleted BM25. This might be due to reduced digestibility of P-depleted cells with putatively thick mucilaginous sheaths. These findings indicate that both the grazer and the cyanobacterium benefit from P reduction in terms of digestibility and growth inhibition, which is an interesting starting point for further studies.","Authors":"Schwarzenberger, A (Schwarzenberger, Anke) ; Sadler, T (Sadler, Thomas) ; Von Elert, E (Von Elert, Eric) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Sadler, Thomas  http://orcid.org/0000-0002-8621-379X","Title":"Effect of nutrient limitation of cyanobacteria on protease inhibitor production and fitness of Daphnia magna"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000322870300009 ISSN: 1532-2882 eISSN: 1532-2890","Keywords":"bibliometrics; text mining KeyWords Plus:FREQUENCY; RETRIEVAL","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY Volume: 64 Issue: 9 Pages: 1852-1863 DOI: 10.1002/asi.22883 Published: SEP 2013","Abstract":"In this article, we use innovative full-text citation analysis along with supervised topic modeling and network-analysis algorithms to enhance classical bibliometric analysis and publication/author/venue ranking. By utilizing citation contexts extracted from a large number of full-text publications, each citation or publication is represented by a probability distribution over a set of predefined topics, where each topic is labeled by an author-contributed keyword. We then used publication/citation topic distribution to generate a citation graph with vertex prior and edge transitioning probability distributions. The publication importance score for each given topic is calculated by PageRank with edge and vertex prior distributions. To evaluate this work, we sampled 104 topics (labeled with keywords) in review papers. The cited publications of each review paper are assumed to be \"important publications\" for the target topic (keyword), and we use these cited publications to validate our topic-ranking result and to compare different publication-ranking lists. Evaluation results show that full-text citation and publication content prior topic distribution, along with the classical PageRank algorithm can significantly enhance bibliometric analysis and scientific publication ranking performance, comparing with term frequency-inverted document frequency (tf-idf), language model, BM25, PageRank, and PageRank + language model (p < .001), for academic information retrieval (IR) systems.","Authors":"Liu, XZ (Liu, Xiaozhong) ; Zhang, JS (Zhang, Jinsong) ; Guo, C (Guo, Chun)","Title":"Full-text citation analysis: A new method to enhance scholarly networks"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000324614200004 ISSN: 1365-8816 eISSN: 1362-3087","Keywords":"temporal query context; geographical query context; pattern mining; context-aware IR KeyWords Plus:RELEVANCE FEEDBACK; RETRIEVAL; PERFORMANCE; INFORMATION","Categories":"Computer Science; Geography; Physical Geography; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science","Journal Information":"INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE Volume: 27 Issue: 8 Pages: 1530-1549 DOI: 10.1080/13658816.2012.756883 Published: AUG 1 2013","Abstract":"The explosive growth of geographic and temporal data has attracted much attention in information retrieval (IR) field. Since geographic and temporal information are often available in unstructured text, the IR task becomes a non-straightforward process. In this article, we propose a novel geo-temporal context mining approach and a geo-temporal ranking model for improving the search performance. Queries target implicitly what', when' and where' components. We model geographic and temporal query-dependent frequent patterns, called contexts. These contexts are derived based on extracting and ranking geographic and temporal entities found in pseudo-relevance feedback documents. Two methods are proposed for inferring the query-dependent contexts: (1) a frequency-based statistical approach and (2) a frequent pattern mining approach using a support threshold. The derived geographic and temporal query contexts are then exploited into a probabilistic ranking model. Finally, geographic, temporal and content-based scores are combined together for improving the geo-temporal search performance. We evaluate our approach on the New York Times news collection. The experimental results show that our proposed approach outperforms significantly a well-known baseline search, namely the probabilistic BM25 ranking model and state-of-the-art approaches in the field as well.","Authors":"Daoud, M (Daoud, Mariam) ; Huang, JX (Huang, Jimmy Xiangji)","Title":"Mining query-driven contexts for geographic and temporal search"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000319253300004 ISSN: 0168-9002","Keywords":"X-Ray Reflectivity; Surface Diffraction; Single Crystal Diffraction; Reciprocal Space Maps; Grazing Incidence Diffraction; High Resolution Powder Diffraction KeyWords Plus:DIFFRACTOMETER; ABSORPTION","Categories":"Instruments & Instrumentation; Nuclear Science & Technology; Physics Web of Science Categories:Instruments & Instrumentation; Nuclear Science & Technology; Physics, Nuclear; Physics, Particles & Fields","Journal Information":"NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT Volume: 716 Pages: 23-28 DOI: 10.1016/j.nima.2013.03.019 Published: JUL 11 2013","Abstract":"The Spanish BM25-SpLine beamline at the European Synchrotron Radiation Facility allocates in the first focal point of Branch B a versatile experimental set-up devoted to X-ray diffraction studies. X-Ray Reflectivity, Reciprocal Space Maps, Surface, Single Crystal, Grazing Incidence and High Resolution Powder Diffraction can be performed using a point detector or a 2D detector (Charge-Coupled Device), in combination with many sample environment setups. A detailed description of the end-station is presented, including several examples that demonstrate the excellent capabilities of the setup. (c) 2013 Elsevier B.V. All rights reserved.","Authors":"Rubio-Zuazo, J (Rubio-Zuazo, J.) ; Ferrer, P (Ferrer, P.) ; Lopez, A (Lopez, A.) ; Gutierrez-Leon, A (Gutierrez-Leon, A.) ; da Silva, I (da Silva, I.) ; Castro, GR (Castro, G. R.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number da Silva, Ivan  C-5545-2014 http://orcid.org/0000-0002-4472-9675 Ferrer, Pilar  E-7836-2014 http://orcid.org/0000-0001-9807-7679 Rubio Zuazo, Juan  M-3346-2014 http://orcid.org/0000-0003-0614-5334 Castro, German  H-6679-2015 http://orcid.org/0000-0003-4251-3245","Title":"The multipurpose X-ray diffraction end-station of the BM25B-SpLine synchrotron beamline at the ESRF"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000319273400004 ISSN: 1386-4564 eISSN: 1573-7659","Keywords":"Information retrieval; Document smoothing; Lexical association KeyWords Plus:LATENT SEMANTIC ANALYSIS; LANGUAGE MODELS; QUERY EXPANSION; TRANSFORM","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL Volume: 16 Issue: 3 Pages: 391-425 DOI: 10.1007/s10791-012-9202-3 Published: JUN 2013","Abstract":"In this paper, a novel neighborhood based document smoothing model for information retrieval has been proposed. Lexical association between terms is used to provide a context sensitive indexing weight to the document terms, i.e. the term weights are redistributed based on the lexical association with the context words. A generalized retrieval framework has been presented and it has been shown that the vector space model (VSM), divergence from randomness (DFR), Okapi Best Matching 25 (BM25) and the language model (LM) based retrieval frameworks are special cases of this generalized framework. Being proposed in the generalized retrieval framework, the neighborhood based document smoothing model is applicable to all the indexing models that use the term-document frequency scheme. The proposed smoothing model is as efficient as the baseline retrieval frameworks at runtime. Experiments over the TREC datasets show that the neighborhood based document smoothing model consistently improves the retrieval performance of VSM, DFR, BM25 and LM and the improvements are statistically significant.","Authors":"Goyal, P (Goyal, Pawan) ; Behera, L (Behera, Laxmidhar) ; McGinnity, TM (McGinnity, T. M.)","Title":"A novel neighborhood based document smoothing model for information retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000317604800011 PubMed ID: 23592627 ISSN: 0909-0495","Keywords":"portable chamber; in situ X-ray scattering; cooling-heating system; environment set-up; mixed-valence manganites; oxygen vacancies; atomic structure KeyWords Plus:THIN-FILMS; VACUUM CHAMBER; DIFFRACTION; MAGNETORESISTANCE; LA0.7CA0.3MNO3; INTERFACES; ABSORPTION; SURFACES; SRTIO3","Categories":"Instruments & Instrumentation; Optics; Physics Web of Science Categories:Instruments & Instrumentation; Optics; Physics, Applied","Journal Information":"JOURNAL OF SYNCHROTRON RADIATION Volume: 20 Pages: 474-481 Part: 3 DOI: 10.1107/S0909049513002598 Published: MAY 2013","Abstract":"The multipurpose portable ultra-high-vacuum-compatible chamber described in detail in this article has been designed to carry out grazing-incidence X-ray scattering techniques on the BM25-SpLine CRG beamline at the ESRF. The chamber has a cylindrical form, built on a 360 degrees beryllium double-ended conflate flange (CF) nipple. The main advantage of this chamber design is the wide sample temperature range, which may be varied between 60 and 1000 K. Other advantages of using a cylinder are that the wall thickness is reduced to a minimum value, keeping maximal solid angle accessibility and keeping wall absorption of the incoming X-ray beam constant. The heat exchanger is a customized compact liquid-nitrogen (LN2) continuous-flow cryostat. LN2 is transferred from a storage Dewar through a vacuum-isolated transfer line to the heat exchanger. The sample is mounted on a molybdenum support on the heat exchanger, which is equipped with a BORALECTRIC heater element. The chamber versatility extends to the operating pressure, ranging from ultra-high vacuum (<10(-10) mbar) to high pressure (up to 3 x 10(3) mbar). In addition, it is equipped with several CF ports to allocate auxiliary components such as capillary gas-inlet, viewports, leak valves, ion gun, turbo pump, etc., responding to a large variety of experiment requirements. A movable slits set-up has been foreseen to reduce the background and diffuse scattering produced at the beryllium wall. Diffraction data can be recorded either with a point detector or with a bi-dimensional CCD detector, or both detectors simultaneously. The system has been designed to carry out a multitude of experiments in a large variety of environments. The system feasibility is demonstrated by showing temperature-dependence grazing-incidence X-ray diffraction and conductivity measurements on a 20 nm-thick La0.7Ca0.3MnO3 thin film grown on a SrTiO3(001) substrate.","Authors":"Ferrer, P (Ferrer, Pilar) ; Rubio-Zuazo, J (Rubio-Zuazo, Juan) ; Heyman, C (Heyman, Catherine) ; Esteban-Betegon, F (Esteban-Betegon, Fatima) ; Castro, GR (Castro, German R.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Ferrer, Pilar  E-7836-2014 http://orcid.org/0000-0001-9807-7679 Esteban-Betegon, Fatima  L-2490-2014   Rubio Zuazo, Juan  M-3346-2014 http://orcid.org/0000-0003-0614-5334 Castro, German  H-6679-2015 http://orcid.org/0000-0003-4251-3245","Title":"Multi-use high/low-temperature and pressure compatible portable chamber for in situ grazing-incidence X-ray scattering studies"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000316767100011 ISSN: 1568-4946 eISSN: 1872-9681","Keywords":"Ranking; Search engine; Reinforcement Learning; Artificial intelligence; Value function; Agent","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications","Journal Information":"APPLIED SOFT COMPUTING Volume: 13 Issue: 4 Pages: 1686-1692 DOI: 10.1016/j.asoc.2012.12.023 Published: APR 2013","Abstract":"Ranking web pages for presenting the most relevant web pages to user's queries is one of the main issues in any search engine. In this paper, two new ranking algorithms are offered, using Reinforcement Learning (RL) concepts. RL is a powerful technique of modern artificial intelligence that tunes agent's parameters, interactively. In the first step, with formulation of ranking as an RL problem, a new connectivity-based ranking algorithm, called RL Rank, is proposed. In RL Rank, agent is considered as a surfer who travels between web pages by clicking randomly on a link in the current page. Each web page is considered as a state and value function of state is used to determine the score of that state (page). Reward is corresponded to number of out links from the current page. Rank scores in RL Rank are computed in a recursive way. Convergence of these scores is proved. In the next step, we introduce a new hybrid approach using combination of BM25 as a content-based algorithm and RL Rank. Both proposed algorithms are evaluated by well known benchmark datasets and analyzed according to concerning criteria. Experimental results show using RL concepts leads significant improvements in raking algorithms. (C) 2013 Elsevier B. V. All rights reserved.","Authors":"Derhami, V (Derhami, Vali) ; Khodadadian, E (Khodadadian, Elahe) ; Ghasemzadeh, M (Ghasemzadeh, Mohammad) ; Bidoki, AMZ (Bidoki, Ali Mohammad Zareh)","Title":"Applying reinforcement learning for web pages ranking algorithms"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000342805300004 ISBN:978-3-642-41154-0; 978-3-642-41153-3 ISSN: 0302-9743","Keywords":"Opinion Retrieval; Twitter; Retweet; Propagation Analysis","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"WEB INFORMATION SYSTEMS ENGINEERING - WISE 2013, PT II Book Series: Lecture Notes in Computer Science Volume: 8181 Pages: 16-28 Published: 2013","Abstract":"Twitter has become an important source for people to collect opinions to make decisions. However the amount and the variety of opinions constitute the major challenge to using them effectively. Here we consider the problem of finding propagated opinions - tweets that express an opinion about some topics, but will be retweeted. Within a learning-to-rank framework, we explore a wide of spectrum features, such as retweetability, opinionatedness and textual quality of a tweet. The experimental results show the effectiveness of our features for this task. Moreover the best ranking model with all features can outperform a BM25 baseline and state-of-the-art for Twitter opinion retrieval approach. Finally, we show that our approach equals human performance on this task.","Authors":"Luo, ZC (Luo, Zhunchen) ; Tang, JT (Tang, Jintao) ; Wang, T (Wang, Ting) Edited by:Lin, X; Manolopoulos, Y; Srivastava, D; Huang, G","Title":"Propagated Opinion Retrieval in Twitter"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000339501000009 ISBN:978-1-4799-2190-4","Keywords":"Visual Bag of Words; Fundamental matrix; Homography; SIFT features; Indoor localization","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013) Pages: 38-42 DOI: 10.1109/ACPR.2013.26 Published: 2013","Abstract":"This paper reports on experiments for indoor image-based location recognition. The basic method makes use of three stages: visual bag-of-words for ranking, a voting method, and a final verification method, if the voting method does not produce a consensus. Such a tiered approach is necessary when there are several visually similar locations in the image database, such as often occurs in office buildings. Three experiments are reported here. In the first, three common term-weighting schemes are compared: ntf, ntfidf and BM25. Surprisingly ntf, the simplest scheme, is shown to be as accurate as BM25, and both are better than ntfidf. These results are surprising because BM25 has been experimentally shown to be one of the best weighting schemes for document information retrieval over many years, and ntfidf has been the preferred weighting scheme for visual BoW in most other image retrieval work. In the second experiment, two verification methods are compared: one based on the fundamental matrix; and one based on a simpler homography computation. Again, surprisingly, the simpler and more efficient homography based method is shown to perform as well as the fundamental matrix method despite the fact that the fundamental matrix method is more physically plausible. The overall system achieves a recognition rate of approximately 80% with a wrong match rate of only 2% (no decision on 18%) on a very challenging office building data set. In the third experiment, the system is evaluated on the same office building dataset with more than one query image. A significant improvement is observed in localisation performance and the overall system achieves a recognition rate of 96% with only two wrong image matches.","Authors":"Khan, N (Khan, Nabeel) ; McCane, B (McCane, Brendan) Book Group Author(s):IEEE","Title":"Analysis of verification methods for indoor image matching"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000323479300038 ISBN:978-1-4673-5786-9; 978-1-4673-5787-6","Keywords":"Data search and retrieval; Generating time sensitive queries; Document ranking","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"2013 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES) Pages: 196-200 Published: 2013","Abstract":"Time is one of the important criteria which we have to consider in day-to-day life. Every one's passion is to retrieve the optimum data within a short span of time. In this paper we are observing the general time sensitive queries. Queries are also important along with finding topic similarity and final document ranking process. The proposal of this paper is to construct a general framework which will handles the time sensitive queries and also identifies sensitive time intervals for those queries. we construct BM25 techniques which will provides the overall ranking mechanism. We analyse extended experimental results with various news articles, TREC data and news archives. Finally we provide a conclusion that our techniques are more efficient and it significantly improves the quality results of time sensitive queries compared to the state-of-the-art retrieval techniques.","Authors":"Prasanna, S (Prasanna, S.) ; Kumar, SS (Kumar, S. Sanjeeve) Book Group Author(s):IEEE","Title":"Measuring the Wide Ranging Instant Perceptive Query"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000324860100003 ISSN: 0127-9084","Keywords":"information retrieval; cross-terms; kernel; proximity; language model","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Theory & Methods","Journal Information":"MALAYSIAN JOURNAL OF COMPUTER SCIENCE Volume: 26 Issue: 3 Pages: 196-210 Published: 2013","Abstract":"Traditional retrieval models were effective in the early stage of the Web; however, with the huge amount of information that is available on the Web today further optimization is required to enhance the performance of these models in extracting the most relevant information. Utilization of the term proximity is one of the techniques that have been introduced for this purpose by many researchers. It assumes that the words in the user query are correlated and thus proximity between them should be considered in the matching process. Density-based proximity is an effectual type of term proximity measures which is still not fully considered in the retrieval models. In this paper we investigate the application of a recent density-based measure called Cross-Terms which has achieved significant scores when applied on the effective BM25 retrieval model. We applied cross-terms on another effective retrieval model that is the Language Modeling Approach. The performance of the enhanced language model was measured and evaluated through several experiments and metrics. Experiments results show that the cross-terms measure was able to improve the performance of the basic language model in all the applied evaluation metrics. Performance improvement reached (+4%) with the MAP metric and (+8%) with P@5 and P@20 metrics.","Authors":"Barakat, HM (Barakat, Huda Mohammed) ; Ismail, MA (Ismail, Maizatul Akmar) ; Ravana, SD (Ravana, Sri Devi) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number ISMAIL, MAIZATUL AKMAR  B-8922-2010   RAVANA, SRI DEVI  B-9833-2010  ","Title":"UTILIZATION OF CROSS-TERMS TO ENHANCE THE LANGUAGE MODEL FOR INFORMATION RETRIEVAL"}, {"Categories":"Instruments & Instrumentation; Physics Web of Science Categories:Instruments & Instrumentation; Physics, Applied; Physics, Multidisciplinary","Journal Information":"11TH INTERNATIONAL CONFERENCE ON SYNCHROTRON RADIATION INSTRUMENTATION (SRI 2012) Book Series: Journal of Physics Conference Series Volume: 425 Article Number: UNSP 132002 DOI: 10.1088/1742-6596/425/13/132002 Published: 2013","Abstract":"A low/high temperature (60-1000K) and pressure (10(-10)-3x10(3) mbar) \"baby chamber\", specially adapted to the grazing-incidence X-ray scattering station, has been designed, developed and installed at the Spanish CRG BM25 SpLine beamline at European Synchrotron Radiation Facility. The chamber has a cylindrical form with 100 mm of diameter, built on a 360 degrees beryllium nipple of 150 mm height. The UHV equipment and a turbo pump are located on the upper part of the chamber to leave a wide solid angle for exploring reciprocal space. The chamber features 4 CF16 and 5 CF40 ports for electrical feed through and leak valves, ion gun, etc. The heat exchanger is a customized compact LN2 (or LHe) continuous flow cryostat. The sample is mounted on a Mo support on the heat exchanger, which has in the back side a BORALECTRIC (R) Heater Elements. Experiments of surfaces/interfaces/multilayer materials, thin films or single crystals in a huge variety of environments can be performed, also in situ studies of growth or evolution of the samples. Data measurement can be collected with a punctual and a bi-dimensional detector, being possible to simultaneously use them.","Authors":"Ferrer, P (Ferrer, P.) ; Rubio-Zuazo, J (Rubio-Zuazo, J.) ; Heyman, C (Heyman, C.) ; Esteban-Betegon, F (Esteban-Betegon, F.) ; Castro, GR (Castro, G. R.) Edited by:Susini, J; Dumas, P Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Ferrer, Pilar  E-7836-2014 http://orcid.org/0000-0001-9807-7679 Esteban-Betegon, Fatima  L-2490-2014   Rubio Zuazo, Juan  M-3346-2014 http://orcid.org/0000-0003-0614-5334 Castro, German  H-6679-2015 http://orcid.org/0000-0003-4251-3245","Title":"A multipurpose ultra-high vacuum-compatible chamber for in situ X-ray surface scattering studies over a wide range of temperature and pressure environment conditions"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000320403700177 ISSN: 1742-6588","Categories":"Instruments & Instrumentation; Physics Web of Science Categories:Instruments & Instrumentation; Physics, Applied; Physics, Multidisciplinary","Journal Information":"11TH INTERNATIONAL CONFERENCE ON SYNCHROTRON RADIATION INSTRUMENTATION (SRI 2012) Book Series: Journal of Physics Conference Series Volume: 425 Article Number: UNSP 132001 DOI: 10.1088/1742-6596/425/13/132001 Published: 2013","Abstract":"A portable powder-liquid high corrosion-resistant reaction cell has been designed to follow in situ reactions by X-ray powder diffraction and X-ray absorption spectroscopy techniques in transmission mode. The cell has been conceived to be mounted on the experimental stations for diffraction and absorption of the Spanish CRG SpLine-BM25 beamline at the ESRF. In the case of the diffraction technique, data can be collected with either a point detector or a two-dimensional CCD detector. Using the 2D-CCD camera, the cell can be used for time-resolved in situ studies of phase transitions and reactions. Powder reactants and/or products are kept at a fixed position in a vertical geometry in the X-ray pathway, which is minimized in order to reduce the X-ray absorption by the reaction bath. Sample is fixed by a porous membrane under forced liquid reflux circulation, assuring total powder-liquid contact, with an accurate temperature control in the range from 20 to 220 degrees C.","Authors":"Ferrer, P (Ferrer, P.) ; da Silva, I (da Silva, I.) ; Heyman, C (Heyman, C.) ; Rubio-Zuazo, J (Rubio-Zuazo, J.) ; Castro, GR (Castro, G. R.) Edited by:Susini, J; Dumas, P Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number da Silva, Ivan  C-5545-2014 http://orcid.org/0000-0002-4472-9675 Ferrer, Pilar  E-7836-2014 http://orcid.org/0000-0001-9807-7679 Rubio Zuazo, Juan  M-3346-2014 http://orcid.org/0000-0003-0614-5334 Castro, German  H-6679-2015 http://orcid.org/0000-0003-4251-3245","Title":"A portable powder-liquid high corrosion-resistant reaction cell for in situ X-ray diffraction and absorption studies of heterogeneous powder-liquid reactions and phase transformations"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000320403700295 ISSN: 1742-6588","Categories":"Instruments & Instrumentation; Physics Web of Science Categories:Instruments & Instrumentation; Physics, Applied; Physics, Multidisciplinary","Journal Information":"11TH INTERNATIONAL CONFERENCE ON SYNCHROTRON RADIATION INSTRUMENTATION (SRI 2012) Book Series: Journal of Physics Conference Series Volume: 425 Article Number: UNSP 212013 DOI: 10.1088/1742-6596/425/21/212013 Published: 2013","Abstract":"An on-axis-visualization stage for accurate sample alignment respect to X-ray beam has been designed and implemented at the diffraction and absorption/fluorescence stations of the BM25-SpLine synchrotron beamline at the ESRF. It is mostly intended for studies involving heterogeneous samples where the analysis is restricted to a particular area of the sample. The OAV system provides a parallax-free image of the sample. This is accomplished by a front-surface mirror at an angle of 45 degrees degrees to reflect the visible sample image 90 degrees up to a zoom optics and digital colour CCD camera. A pinhole (PH) on the mirror in combination with a second PH 100 mm backward provides an on-axis collimated X-ray beam at image centre. The collimator is aligned to the beam axis by two angular and two translational high-precision motorized motions. The OAV stage is synchronized with the sample positioning stage, by a computer software so that the desired sample region is aligned on the X-ray beam by selecting it on the image produced by the video camera. In this work, a complete description of the on-axis-visualization system will be presented including the experimental determination of the alignment accuracy.","Authors":"Gutierrez-Leon, A (Gutierrez-Leon, A.) ; Heyman, C (Heyman, C.) ; Rubio-Zuazo, J (Rubio-Zuazo, J.) ; Castro, GR (Castro, G. R.) Edited by:Susini, J; Dumas, P Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Rubio Zuazo, Juan  M-3346-2014 http://orcid.org/0000-0003-0614-5334 Castro, German  H-6679-2015 http://orcid.org/0000-0003-4251-3245","Title":"Development of an on-axis-visualization stage to observe and align sample with an x-ray beam"}, {"Categories":"Instruments & Instrumentation; Physics Web of Science Categories:Instruments & Instrumentation; Physics, Applied; Physics, Multidisciplinary","Journal Information":"11TH INTERNATIONAL CONFERENCE ON SYNCHROTRON RADIATION INSTRUMENTATION (SRI 2012) Book Series: Journal of Physics Conference Series Volume: 425 Article Number: UNSP 052005 DOI: 10.1088/1742-6596/425/5/052005 Published: 2013","Abstract":"The CRG BM25-SpLine Beamline is located at bending magnet 25 of the ESRF. The beamline, which is split in two branches, is devoted to XAS, XRD and HAXPES. The photon energy covered by both branches range between 5 and 45 keV. The beamline double crystal monochromator (DCM) uses two parallel Si(111) crystals in (+, -) configuration to produce a monochromatic exit beam parallel to the incident white X-ray beam. It accepts 2mrad of radiation from the bending magnet. The DCM has been recently upgraded. Several special features concerning the cooling of the first crystal, second crystal positioning and sagittal focusing mechanism has been improved. In this work a detailed description of the performed modifications is presented.","Authors":"Rubio-Zuazo, J (Rubio-Zuazo, J.) ; Collado-Negro, V (Collado-Negro, Victor) ; Heyman, C (Heyman, C.) ; Ferrer, P (Ferrer, Pilar) ; da Silva, I (da Silva, Ivan) ; Gallastegui, JA (Gallastegui, J. A.) ; Gutierrez-Leon, A (Gutierrez-Leon, A.) ; Castro, GR (Castro, G. R.) Edited by:Susini, J; Dumas, P Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number da Silva, Ivan  C-5545-2014 http://orcid.org/0000-0002-4472-9675 Ferrer, Pilar  E-7836-2014 http://orcid.org/0000-0001-9807-7679 Rubio Zuazo, Juan  M-3346-2014 http://orcid.org/0000-0003-0614-5334 Castro, German  H-6679-2015 http://orcid.org/0000-0003-4251-3245","Title":"A double crystal X-ray monochromator for the SpLine diffraction and absorption synchrotron bending magnet beamline at the ESRF"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000319490600010 ISSN: 1335-9150","Keywords":"Ranking strategies; indexing units; XML retrieval; BM25F","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"COMPUTING AND INFORMATICS Volume: 32 Issue: 2 Pages: 411-440 Published: 2013","Abstract":"Efficient retrieval of XML elements and documents is essential in the effective application of the XML format. The ranking function BM25F is composed of several document fields with potentially different degrees of importance; these fields are known as selected fields that give substantial improvements over the baseline BM25. The BM25F function has performed well in past evaluations; however, there are issues that require additional attention. In the first instance, which elements should be treated as fields? Secondly, what is an appropriate weight for each field? Previously, document fields were selected manually, and the weight for each chosen field was tuned before being assigned. Two automatic methods are introduced in this paper that enable the extraction of fields in document-centric XML documents and the assignment weights to the selected fields. Our experiments show an improvement of up to 28% over BM25, and up to 15% over BM25F at iP[0.01] based on INEX evaluations.","Authors":"Wichaiwong, T (Wichaiwong, Tanakorn) ; Jaruskulchai, C (Jaruskulchai, Chuleerat)","Title":"A DOUBLE SCORING METHOD FOR XML ELEMENT RETRIEVAL"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000357013800061 ISBN:978-0-7695-5125-8","Keywords":"index pruning; inverted index; index construction","Categories":"Computer Science Web of Science Categories:Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods","Journal Information":"2013 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND APPLICATIONS (CSA) Pages: 262-265 DOI: 10.1109/CSA.2013.67 Published: 2013","Abstract":"Static index pruning can significantly reduce index size and query processing time. An online static index pruning algorithm is presented, which is a term-centric method and adopts BM25 weighting as the pruning measure. The algorithm scans through documents set with one pass and directly builds pruned index, and therefore avoids the construction of original index. The experiments based on TREC data set show that the online static index pruning algorithm requires less time to build pruned index, and the pruning effectiveness outperforms the baseline method.","Authors":"Liu, XF (Liu Xiaofeng) Book Group Author(s):IEEE","Title":"An Online Static Index Pruning Algorithm"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000371995200009 ISBN:978-1-4503-2524-0","Keywords":"Text indexing; information retrieval; performance KeyWords Plus:RETRIEVAL","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"PROCEEDINGS OF THE 18TH AUSTRALASIAN DOCUMENT COMPUTING SYMPOSIUM (ADCS 2013) Pages: 58-65 Published: 2013","Abstract":"Web search services process thousands of queries per second, and filter their answers from collections containing very large amounts of data. Fast response to queries is a critical service expectation. The well-known WAND processing strategy is one way of reducing the amount of computation necessary when executing such a query. The value of WAND has now been validated in a wide range of studies, and has become one of the key baselines against which all new top-k processing algorithms are benchmarked. However, most previous implementations of WAND-based retrieval approaches have been in the context of the BM25 Okapi similarity scoring regime. Here we measure the performance of WAND in the context of the alternative Language Model similarity score computation, and find that the dramatic efficiency gains reported in previous studies are no longer achievable. That is, when the primary goal of a retrieval system is to maximize effectiveness, WAND is relatively unhelpful in terms of attaining the secondary objective of maximizing query throughput rates. However, the BM-WAND algorithm does in fact help reducing the percentage of postings to be scored, but with additional computational overhead. We explore a variety of trade-offs between scoring metric and processing regime and present new insight into how score-safe algorithms interact with rank scoring.","Authors":"Petri, M (Petri, Matthias) ; Culpepper, JS (Culpepper, J. Shane) ; Moffatt, A (Moffatt, Alistair) Edited by:Culpepper, JS; Sitbon, L; Zuccon, G Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Culpepper, Shane  http://orcid.org/0000-0002-1902-9087 Moffat, Alistair  http://orcid.org/0000-0002-6638-0232","Title":"Exploring the Magic of WAND"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000313146300024 ISSN: 0916-8532","Keywords":"order preserving encryption; paillier public key encryption; okapi BM25","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS Volume: E95D Issue: 12 Pages: 2954-2955 DOI: 10.1587/transinf.E95.D.2954 Published: DEC 2012","Abstract":"Ranking the encrypted documents stored on secure cloud computing servers is becoming prominent with the expansion of the encrypted data collection. In our work, order preserving encryption is employed to pre-rank the encrypted documents. Paillier's additive homomorphic encryption is used to re-rank the top pre-ranked documents of some considerate scale.","Authors":"Zhang, JL (Zhang, Jiuling) ; Deng, BX (Deng, Beixing) ; Li, X (Li, Xing) ; Zhang, XL (Zhang, Xiao-lei)","Title":"Secure Ranking over Encrypted Documents"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000309914400011 ISSN: 1041-4347","Keywords":"Information retrieval; lexical association; query expansion; language model KeyWords Plus:RELEVANCE; EXPANSION; SCIENCE; MODEL; WEB","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING Volume: 24 Issue: 12 Pages: 2260-2273 DOI: 10.1109/TKDE.2011.171 Published: DEC 2012","Abstract":"A user query for information retrieval (IR) applications may not contain the most appropriate terms (words) as actually intended by the user. This is usually referred to as the term mismatch problem and is a crucial research issue in IR. Using the notion of relevance, we provide a comprehensive theoretical analysis of a parametric query vector, which is assumed to represent the information needs of the user. A lexical association function has been derived analytically using the system relevance criteria. The derivation is further justified using an empirical evidence from the user relevance criteria. Such analytical derivation as presented in this paper provides a proper mathematical framework to the query expansion techniques, which have largely been heuristic in the existing literature. By using the generalized retrieval framework, the proposed query representation model is equally applicable to the vector space model (VSM), Okapi best matching 25 (Okapi BM25), and Language Model (LM). Experiments over various data sets from TREC show that the proposed query representation gives statistically significant improvements over the baseline Okapi BM25 and LM as well as other well-known global query expansion techniques. Empirical results along with the theoretical foundations of the query representation confirm that the proposed model extends the state of the art in global query expansion.","Authors":"Goyal, P (Goyal, Pawan) ; Behera, L (Behera, Laxmidhar) ; McGinnity, TM (McGinnity, Thomas Martin)","Title":"Query Representation through Lexical Association for Information Retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000309483900005 ISSN: 1540-9589","Keywords":"Information Retrieval; Ranking; Relevance Propagation; Popularity Measure","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering; Computer Science, Theory & Methods","Journal Information":"JOURNAL OF WEB ENGINEERING Volume: 11 Issue: 4 Pages: 350-364 Published: DEC 2012","Abstract":"It is evident that information resources on the World Wide Web (WWW) are growing rapidly with unpredictable rate. Under these circumstances, web search engines help users to find useful information. Ranking the retrieved results is the main challenge of every search engine. There are some ranking algorithms based on content and connectivity such as BM25 and PageRank. Due to low precision of these algorithms for ranking on the web, combinational algorithms have been proposed. Recently, relevance propagation methods as one of the salient combinational algorithms, has attracted many information retrieval (IR) researchers' attention. In these methods the content-based attributes are propagated from one page to another through web graph. In this paper, we propose a generic method for exploiting the estimated popularity degree of pages (such as their PageRank score) to improve the propagation process. Experimental results based on TREC 2003 and 2004 gathered in Microsoft LETOR 3.0 benchmark collection show that this idea can improve the precision of the corresponding models without any additional online complexity.","Authors":"Mousakazemi, E (Mousakazemi, Ehsan) ; Sarram, MA (Sarram, Mehdi Agha) ; Bidoki, AMZ (Bidoki, Ali Mohammad Zareh)","Title":"POPULARITY-BASED RELEVANCE PROPAGATION"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000310637200010 ISSN: 0218-2130 eISSN: 1793-6349","Keywords":"Bayesian networks; modern Greek; AhR; Ad-hoc retrieval; lemmatization KeyWords Plus:INFORMATION-RETRIEVAL; AUTOMATIC LEMMATIZATION; MODERN GREEK; NETWORKS; MODEL; RELEVANCE; ENGLISH","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications","Journal Information":"INTERNATIONAL JOURNAL ON ARTIFICIAL INTELLIGENCE TOOLS Volume: 21 Issue: 5 Special Issue: SI Article Number: 1250024 DOI: 10.1142/S0218213012500248 Published: OCT 2012","Abstract":"The present paper describes a Bayesian network approach to Information Retrieval (IR) from Web documents. The network structure provides an intuitive representation of uncertainty relationships and the embedded conditional probability table is used by inference algorithms in an attempt to identify documents that are relevant to the user's needs, expressed in the form of Boolean queries. Our research has been directed in constructing a probabilistic IR framework that focus on assisting users to perform Ad-hoc retrieval of documents from the various domains such as economics, news, sports, etc. Furthermore, users can integrate feedback regarding the relevance of the retrieved documents in an attempt to improve performance on upcoming requests. Towards these goals, we have expanded the traditional Bayesian network IR system and tested it on several Greek web corpora on different application domains. We have developed two different approaches with regards to the structure: a simple one, where the structure is manually provided, and an automated one, where data mining is used in order to extract the network's structure. Results have depicted competitive performance against successful IR models of different theoretical backgrounds, such as the vector space utilizing tf-idf and the probabilistic model of BM25 in terms of precision-recall curves. In order to further improve the performance of the IR system, we have implemented a novel similarity-based lemmatization framework, reducing thus the ambiguity posed by the plethora of morphological variations of the languages in question. The employed lemmatization framework comprises of 3 core components (i.e. the word segregation, the data cleansing and the lemmatization modules) and is language-independent (i.e. can be applied to other languages with morphological peculiarities and thus improve Ad-hoc retrieval) since it achieves the mapping of an input word to its normalized form by employing two state-of-the-art language independent distance metric models, meaning the Levenshtein Edit distance and the Dice coefficient similarity measure, combined with a language model describing the most frequent inflectional suffixes of the examined language. Experimental results support our claim on the significance of this incorporation to Greek texts web retrieval as results improve by a factor of 4% to 11%.","Authors":"Maragoudakis, M (Maragoudakis, Manolis) ; Lyras, DP (Lyras, Dimitrios P.) ; Sgarbas, K (Sgarbas, Kyriakos)","Title":"BAYESIAN RETRIEVAL USING A SIMILARITY-BASED LEMMATIZER"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000304707500008 ISSN: 1380-7501","Keywords":"Learning to Rank; Text-image retrieval; OWPC; Visuo-textual fusion; Pooling for Learning to Rank","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"MULTIMEDIA TOOLS AND APPLICATIONS Volume: 60 Issue: 1 Pages: 161-180 DOI: 10.1007/s11042-011-0806-1 Published: SEP 2012","Abstract":"We present a framework based on a Learning to Rank setting for a text-image retrieval task. In Information Retrieval, the goal is to compute the similarity between a document and an user query. In the context of text-image retrieval where several similarities exist, human intervention is often needed to decide on the way to combine them. On the other hand, with the Learning to Rank approach the combination of the similarities is done automatically. Learning to Rank is a paradigm where the learnt objective function is able to produce a ranked list of images when a user query is given. These score functions are generally a combination of similarities between a document and a query. In the past, Learning to Rank algorithms were successfully applied to text retrieval where they outperformed baselines such as BM25 or TFIDF. This inspired us to apply our state-of-the-art algorithm, called OWPC (Usunier et al. 2009), to the text-image retrieval task. At this time, no benchmarks are available, therefore we present a framework for building one. The empirical validation of this algorithm is done on the dataset constructed through comparison of typical text-image retrieval similarities. In both cases, visual only and text and visual, our algorithm performs better than a simple baseline.","Authors":"Buffoni, D (Buffoni, David) ; Tollari, S (Tollari, Sabrina) ; Gallinari, P (Gallinari, Patrick)","Title":"A Learning to Rank framework applied to text-image retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000305692000009 ISSN: 0219-1377 eISSN: 0219-3116","Keywords":"Probabilistic information retrieval model; Structured information retrieval; XML; Tags; Weighting scheme; BM25 KeyWords Plus:XML RETRIEVAL; RELEVANCE","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"KNOWLEDGE AND INFORMATION SYSTEMS Volume: 32 Issue: 1 Pages: 217-241 DOI: 10.1007/s10115-011-0426-0 Published: JUL 2012","Abstract":"This paper addresses the integration of XML tags into a term-weighting function for focused XML information retrieval (IR). Our model allows us to consider a certain kind of structural information: tags that represent a logical structure (e.g., title, section, paragraph, etc.) as well as other tags (e.g., bold, italic, center, etc.). We take into account the influence of a tag by estimating the probability for this tag to distinguish relevant terms from the others. Then, these weights are integrated in a term-weighting function. Experiments on a large collection from the INEX 2008 XML IR evaluation campaign showed improvements on focused XML retrieval.","Authors":"Gery, M (Gery, Mathias) ; Largeron, C (Largeron, Christine)","Title":"BM25t: a BM25 extension for focused information retrieval"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000304307800002 ISSN: 1386-4564 eISSN: 1573-7659","Keywords":"Social media mining; Microblog analysis; Vector space model; Term weighting; Information extraction; Evaluation KeyWords Plus:INFORMATION; SYSTEM","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL Volume: 15 Issue: 3-4 Pages: 183-217 Special Issue: SI DOI: 10.1007/s10791-012-9187-y Published: JUN 2012","Abstract":"Different term weighting techniques such as or BM25 have been used intensely for manifold text-based information retrieval tasks. Their use for modeling term profiles for named entities and subsequent calculation of similarities between these named entities have been studied to a much smaller extent. The recent trend of microblogging made available massive amounts of information about almost every topic around the world. Therefore, microblogs represent a valuable source for text-based named entity modeling. In this paper, we present a systematic and comprehensive evaluation of different term weighting measures, normalization techniques, query schemes, index term sets, and similarity functions for the task of inferring similarities between named entities, based on data extracted from microblog posts. We analyze several thousand combinations of choices for the above mentioned dimensions, which influence the similarity calculation process, and we investigate in which way they impact the quality of the similarity estimates. Evaluation is performed using three real-world data sets: two collections of microblogs related to music artists and one related to movies. For the music collections, we present results of genre classification experiments using as benchmark genre information from allmusic.com . For the movie collection, we present results of multi-class classification experiments using as benchmark categories from IMDb . We show that microblogs can indeed be exploited to model named entity similarity with remarkable accuracy, provided the correct settings for the analyzed aspects are used. We further compare the results to those obtained when using Web pages as data source.","Authors":"Schedl, M (Schedl, Markus)","Title":"#nowplaying Madonna: a large-scale evaluation on estimating similarities between music artists and between movies from microblogs"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000299920200003 ISSN: 1386-4564 eISSN: 1573-7659","Keywords":"Information retrieval; Graph theory; Natural language processing KeyWords Plus:SMALL-WORLD NETWORKS; SCALE-FREE NETWORKS; METABOLIC NETWORKS; COMPLEX NETWORKS; COMMUNITY STRUCTURE; ORGANIZATION; MODEL; TEXT; WEB; CONNECTIVITY","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL Volume: 15 Issue: 1 Pages: 54-92 DOI: 10.1007/s10791-011-9172-x Published: FEB 2012","Abstract":"A standard approach to Information Retrieval (IR) is to model text as a bag of words. Alternatively, text can be modelled as a graph, whose vertices represent words, and whose edges represent relations between the words, defined on the basis of any meaningful statistical or linguistic relation. Given such a text graph, graph theoretic computations can be applied to measure various properties of the graph, and hence of the text. This work explores the usefulness of such graph-based text representations for IR. Specifically, we propose a principled graph-theoretic approach of (1) computing term weights and (2) integrating discourse aspects into retrieval. Given a text graph, whose vertices denote terms linked by co-occurrence and grammatical modification, we use graph ranking computations (e.g. PageRank Page et al. in The pagerank citation ranking: Bringing order to the Web. Technical report, Stanford Digital Library Technologies Project, 1998) to derive weights for each vertex, i.e. term weights, which we use to rank documents against queries. We reason that our graph-based term weights do not necessarily need to be normalised by document length (unlike existing term weights) because they are already scaled by their graph-ranking computation. This is a departure from existing IR ranking functions, and we experimentally show that it performs comparably to a tuned ranking baseline, such as BM25 (Robertson et al. in NIST Special Publication 500-236: TREC-4, 1995). In addition, we integrate into ranking graph properties, such as the average path length, or clustering coefficient, which represent different aspects of the topology of the graph, and by extension of the document represented as a graph. Integrating such properties into ranking allows us to consider issues such as discourse coherence, flow and density during retrieval. We experimentally show that this type of ranking performs comparably to BM25, and can even outperform it, across different TREC (Voorhees and Harman in TREC: Experiment and evaluation in information retrieval, MIT Press, 2005) datasets and evaluation measures.","Authors":"Blanco, R (Blanco, Roi) ; Lioma, C (Lioma, Christina) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Lioma, Christina  N-2203-2016 http://orcid.org/0000-0003-2600-2701","Title":"Graph-based term weighting for information retrieval"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000323927701038 ISBN:978-2-9517408-7-7","Keywords":"cross-lingual information retrieval; biomedical information retrieval; query expansion; CMeSH","Categories":"Linguistics Web of Science Categories:Linguistics; Language & Linguistics","Journal Information":"LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION Pages: 1148-1155 Published: 2012","Abstract":"Cross-lingual information retrieval (CLIR) involving the Chinese language has been thoroughly studied in the general language domain, but rarely in the biomedical domain, due to the lack of suitable linguistic resources and parsing tools. In this paper, we describe a Chinese-English CLIR system for biomedical literature, which exploits a bilingual ontology, the \"eCMeSH Tree\". This is an extension of the Chinese Medical Subject Headings (CMeSH) Tree, based on Medical Subject Headings (MeSH). Using the 2006 and 2007 TREC Genomics track data, we have evaluated the performance of the eCMeSH Tree in expanding queries. We have compared our results to those obtained using two other approaches, i.e. pseudo-relevance feedback (PRF) and document translation (DT). Subsequently, we evaluate the performance of different combinations of these three retrieval methods. Our results show that our method of expanding queries using the eCMeSH Tree can outperform the PRF method. Furthermore, combining this method with PRF and DT helps to smooth the differences in query expansion, and consequently results in the best performance amongst all experiments reported. All experiments compare the use of two different retrieval models, i.e. Okapi BM25 and a query likelihood language model. In general, the former performs slightly better.","Authors":"Wang, XK (Wang, Xinkai) ; Thompson, P (Thompson, Paul); Tsujii, J (Tsujii, Jun'ichi); Ananiadou, S (Ananiadou, Sophia) Edited by:Calzolari, N; Choukri, K; Declerck, T; Dogan, MU; Maegaard, B; Mariani, J; Odijk, J; Piperidis, S","Title":"Biomedical Chinese-English CLIR Using an Extended CMeSH Resource to Expand Queries"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000317101700008 ISBN:978-3-642-31020-1 ISSN: 0302-9743","Keywords":"Order preserving encryption; Okapi BM25; Additive order preserving encryption KeyWords Plus:KEYWORD SEARCH","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"ADVANCES IN SWARM INTELLIGENCE, ICSI 2012, PT II Book Series: Lecture Notes in Computer Science Volume: 7332 Pages: 58-65 Published: 2012","Abstract":"Ranking the encrypted documents stored on cloud storage servers is important in encrypted information retrieval. Order preserving encryption (OPE) could be used to help ranking the encrypted documents. However, order preserving encryption schemes don't support additions over cipher texts. A new additive order preserving encryption is proposed. Both the cipher text and the sum of the cipher texts preserve orders. By summing up the encryptions of term weights, the relevance between encrypted documents and queries are obtained. According to the relevance the documents are ranked. Experimental results show that the proposed encryption scheme based ranking could achieve very good retrieval performance.","Authors":"Zhang, JL (Zhang, Jiuling) ; Deng, BX (Deng, Beixing) ; Li, X (Li, Xing) Edited by:Tan, Y; Shi, Y; Ji, Z","Title":"Additive Order Preserving Encryption Based Encrypted Documents Ranking in Secure Cloud Storage"}, {"Keywords":"bug reports; duplication detection; term weighting; BM25","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic","Journal Information":"2012 CONFERENCE ON TECHNOLOGIES AND APPLICATIONS OF ARTIFICIAL INTELLIGENCE (TAAI) Book Series: Conference on Technologies and Applications of Artificial Intelligence Pages: 33-38 DOI: 10.1109/TAAI.2012.20 Published: 2012","Abstract":"Handling bug reports is an important issue in software maintenance. Recently, detection on duplicate bug reports has received much attention. There are two main reasons. First, duplicate bug reports may waste human resource to process these redundant reports. Second, duplicate bug reports may provide abundant information for further software maintenance. In the past studies, many schemes have been proposed using the information retrieval and natural language processing techniques. In this thesis, we propose a novel detection scheme based on a BM25 term weighting scheme. We have conducted empirical experiments on three open source projects, Apache, ArgoUML, and SVN. The experimental results show that the BM25-based scheme can effectively improve the detection performance in nearly all cases.","Authors":"Yang, CZ (Yang, Cheng-Zen) ; Du, HH (Du, Hung-Hsueh) ; Wu, SS (Wu, Sin-Sian) ; Chen, IX (Chen, Ing-Xiang) Edited by:Kuo, YH; Tseng, VSM; Kao, HY; Hong, TP; Horng, MF","Title":"Duplication Detection for Software Bug Reports based on BM25 Term Weighting"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000310761500048 ISBN:978-3-642-28764-0 ISSN: 1867-5662","Keywords":"Query expansion; Biomedical information retrieval; Lemur; MEDLINE KeyWords Plus:MEDLINE","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture","Journal Information":"DISTRIBUTED COMPUTING AND ARTIFICIAL INTELLIGENCE Book Series: Advances in Intelligent and Soft Computing Volume: 151 Pages: 403-410 Published: 2012","Abstract":"The increase in the amount of available biomedical information has resulted in a higher demand on biomedical information retrieval systems. However, traditional information retrieval systems do not achieve the desired performance in this area. Query expansion techniques have improved the effectiveness of ranked retrieval by automatically adding additional terms to a query. In this work we test several automatic query expansion techniques using the Lemur Language Modelling Toolkit. The objective is to evaluate a set of query expansion techniques when they are applied to biomedical information retrieval. In the first step of the information retrieval searching, indexing, we compare the use of several techniques of stemming and stopwords. In the second step, matching, we compare the well-known weighting algorithms Okapi and TF-IDF BM25. The best results are obtained with the combination of Krovetz stemmer, SMART stopword list and TF-IDF. Moreover, we analyze the document retrieval based on Abstract, Title and Mesh fields. We conclude that seems more effective than looking at each of these fields individually. Also, we show that the use of feedback in document retrieval results a improvement in retrieving. The corpus used in the experiments was extracted from the biomedical text Cystic Fibrosis Corpus (CF).","Authors":"Rivas, AR (Rivas, A. R.) ; Borrajo, L (Borrajo, L.) ; Iglesias, EL (Iglesias, E. L.) ; Romero, R (Romero, R.) Edited by:Omatu, S; Santana, JFD; Gonzalez, SR; Molina, JM; Bernardos, AM; Rodriguez, JMC Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Borrajo Diz, Lourdes  http://orcid.org/0000-0002-6089-6166","Title":"Applying Lemur Query Expansion Techniques in Biomedical Information Retrieval"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000310555900075 ISBN:978-3-642-29389-4 ISSN: 1867-5662","Keywords":"SDST; information retrieval; index pruning; index compression","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications","Journal Information":"ADVANCES IN FUTURE COMPUTER AND CONTROL SYSTEMS, VOL 2 Book Series: Advances in Intelligent and Soft Computing Volume: 160 Pages: 471-476 Published: 2012","Abstract":"As an efficient index structure, Streamline Dynamic Successive Trees (SDST) is very suitable for Chinese information retrieval. Given the dependencies between terms in SDST and Chinese scenarios, we present a new bigram-centric pruning strategy and corresponding algorithm, utilizing our improved BM25 formula, to decide whether certain index information should remain in the index or not. This technology can be used to significantly reduce the size of SDST index, and still gives good enough answers. Thus, we make SDST index model more applicable in Chinese information retrieval.","Authors":"Huo, L (Huo, Lin) ; Zou, XZ (Zou, Xianze) ; Xing, X (Xing, Xiao) ; Zhao, Y (Zhao, Ying) Edited by:Jin, D; Lin, S","Title":"Static Pruning of Index Based on SDST"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000305314200010 ISSN: 1335-9150","Keywords":"User reputation; social network; Web 2.0; You Tube KeyWords Plus:RELIABILITY; TRUST","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"COMPUTING AND INFORMATICS Volume: 31 Issue: 2 Pages: 447-462 Published: 2012","Abstract":"In the Web 2.0 era, people not only read web contents but create, upload, view, share and evaluate all contents on the web. This leads us to introduce a new type of social network based on user activity and content metadata. We notice that we can determine the quality of related contents using this new social network. Based on this observation, we introduce a user evaluation algorithm for user-generated video sharing website. First, we make a social network of users from video contents and related social activities such as subscription, uploading or favorite. We then use a modified PageRank algorithm to compute user reputation from the social network. We re-calculate the content scores using user reputations and compare the results with a standard BM25 result. We apply the proposed approach to YouTube and demonstrate that the user reputation is closely related to the number of subscriptions and the number of uploaded contents. Furthermore, we show that the new ranking results relied on the user reputation is better than the standard BM25 approach by experiments.","Authors":"Han, YS (Han, Yo-Sub) ; Kim, L (Kim, Laehyun) ; Cha, JW (Cha, Jeong-Won)","Title":"COMPUTING USER REPUTATION IN A SOCIAL NETWORK OF WEB 2.0"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000298483400012 PubMed ID: 22186649 ISSN: 0909-0495","Keywords":"powder-liquid reaction cell; cell design; in situ reaction; X-ray absorption spectroscopy; X-ray diffraction; layered titanium phosphates KeyWords Plus:LAYERED TITANIUM PHOSPHATE; HYDROTHERMAL SYNTHESIS","Categories":"Instruments & Instrumentation; Optics; Physics Web of Science Categories:Instruments & Instrumentation; Optics; Physics, Applied","Journal Information":"JOURNAL OF SYNCHROTRON RADIATION Volume: 19 Pages: 93-100 Part: 1 DOI: 10.1107/S0909049511040374 Published: JAN 2012","Abstract":"A portable powder-liquid high-corrosion-resistant reaction cell has been designed to follow in situ reactions by X-ray powder diffraction (XRD) and X-ray absorption spectroscopy (XAS) techniques. The cell has been conceived to be mounted on the experimental stations for diffraction and absorption of the Spanish CRG SpLine-BM25 beamline at the European Synchrotron Radiation Facility. Powder reactants and/or products are kept at a fixed position in a vertical geometry in the X-ray pathway by a porous membrane, under forced liquid reflux circulation. Owing to the short pathway of the X-ray beam through the cell, XRD and XAS measurements can be carried out in transmission configuration/mode. In the case of the diffraction technique, data can be collected with either a point detector or a two-dimensional CCD detector, depending on specific experimental requirements in terms of space or time resolution. Crystallization processes, heterogeneous catalytic processes and several varieties of experiments can be followed by these techniques with this cell. Two experiments were carried out to demonstrate the cell feasibility: the phase transformations of layered titanium phosphates in boiling aqueous solutions of phosphoric acid, and the reaction of copper carbonate and L-isoleucine amino acid powders in boiling aqueous solution. In this last case the shrinking of the solid reactants and the formation of Cu(isoleucine)(2) is observed. The crystallization processes and several phase transitions have been observed during the experiments, as well as an unexpected reaction pathway.","Authors":"Ferrer, P (Ferrer, Pilar) ; da Silva, I (da Silva, Ivan) ; Rubio-Zuazo, J (Rubio-Zuazo, Juan) ; Alfonso, BF (Alfonso, Belen F.) ; Trobajo, C (Trobajo, Camino) ; Khainakov, S (Khainakov, Sergei) ; Garcia, JR (Garcia, Jose R.) ; Garcia-Granda, S (Garcia-Granda, Santiago) ; Castro, GR (Castro, German R.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Alfonso, Belen  M-3535-2014 http://orcid.org/0000-0002-7066-1547 Garcia-Granda, Santiago  F-8258-2012 http://orcid.org/0000-0002-2373-0247 da Silva, Ivan  C-5545-2014 http://orcid.org/0000-0002-4472-9675 Ferrer, Pilar  E-7836-2014 http://orcid.org/0000-0001-9807-7679 Rubio Zuazo, Juan  M-3346-2014 http://orcid.org/0000-0003-0614-5334 Castro, German  H-6679-2015 http://orcid.org/0000-0003-4251-3245 Garcia-Menendez, Jose Ruben  http://orcid.org/0000-0001-7944-7398 Trobajo-Fernandez, Maria del Camino  http://orcid.org/0000-0002-1593-6683","Title":"A flow-through reaction cell for in situ X-ray diffraction and absorption studies of heterogeneous powder-liquid reactions and phase transformations"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000294960300002 ISSN: 1386-4564","Keywords":"Document clustering; Feature weighting; Okapi BM25","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL Volume: 14 Issue: 5 Pages: 466-487 DOI: 10.1007/s10791-011-9163-y Published: OCT 2011","Abstract":"We investigate the effect of feature weighting on document clustering, including a novel investigation of Okapi BM25 feature weighting. Using eight document datasets and 17 well-established clustering algorithms we show that the benefit of tf-idf weighting over tf weighting is heavily dependent on both the dataset being clustered and the algorithm used. In addition, binary weighting is shown to be consistently inferior to both tf-idf weighting and tf weighting. We investigate clustering using both BM25 term saturation in isolation and BM25 term saturation with idf, confirming that both are superior to their non-BM25 counterparts under several common clustering quality measures. Finally, we investigate estimation of the k1 BM25 parameter when clustering. Our results indicate that typical values of k1 from other IR tasks are not appropriate for clustering; k1 needs to be higher.","Authors":"Whissell, JS (Whissell, John S.) ; Clarke, CLA (Clarke, Charles L. A.)","Title":"Improving document clustering using Okapi BM25 feature weighting"}, {"Document Information":"Document Type:Article; Proceedings Paper Language:English Accession Number: WOS:000303930900006 PubMed ID: 21989123 ISSN: 1471-2105","Categories":"Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology Web of Science Categories:Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology","Journal Information":"BMC BIOINFORMATICS Volume: 12 Supplement: 5 Article Number: S6 DOI: 10.1186/1471-2105-12-S5-S6 Published: JUL 27 2011","Abstract":"Background: The users desire to be provided short, specific answers to questions and put them in context by linking original sources from the biomedical literature. Through the use of information retrieval technologies, information systems retrieve information to index data based on all kinds of pre-defined searching techniques/functions such that various ranking strategies are designed depending on different sources. In this paper, we propose a robust approach to optimizing multi-source information for improving genomics retrieval performance. Results: In the proposed approach, we first consider a common scenario for a metasearch system that has access to multiple baselines with retrieving and ranking documents/passages by their own models. Then, given selected baselines from multiple sources, we investigate three modified fusion methods in the proposed approach, reciprocal, CombMNZ and CombSUM, to re-rank the candidates as the outputs for evaluation. Our empirical study on both 2007 and 2006 genomics data sets demonstrates the viability of the proposed approach for obtaining better performance. Furthermore, the experimental results show that the reciprocal method provides notable improvements on the individual baseline, especially on the passage2-level MAP and the aspect-level MAP. Conclusions: From the extensive experiments on two TREC genomics data sets, we draw the following conclusions. For the three fusion methods proposed in the robust approach, the reciprocal method outperforms the CombMNZ and CombSUM methods obviously, and CombSUM works well on the passage2-level when compared with CombMNZ. Based on the multiple sources of DFR, BM25 and language model, we can observe that the alliance of giants achieves the best result. Meanwhile, under the same combination, the better the baseline performance is, the more contribution the baseline provides. These conclusions are very useful to direct the fusion work in the field of biomedical information retrieval.","Authors":"Hu, QM (Hu, Qinmin) ; Huang, JX (Huang, Jimmy Xiangji) ; Miao, J (Miao, Jun)","Title":"A robust approach to optimizing multi-source information for enhancing genomics retrieval performance"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000290973100007 ISSN: 0020-0255","Keywords":"Proximity; Probabilistic models; BM25 KeyWords Plus:PERSPECTIVE; WEB","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION SCIENCES Volume: 181 Issue: 14 Pages: 3017-3031 DOI: 10.1016/j.ins.2011.03.007 Published: JUL 15 2011","Abstract":"Proximity among query terms has been found to be useful for improving retrieval performance. However, its application to classical probabilistic information retrieval models, such as Okapi's BM25, remains a challenging research problem. In this paper, we propose to improve the classical BM25 model by utilizing the term proximity evidence. Four novel methods, namely a window-based N-gram Counting method, Survival Analysis over different statistics, including the Poisson process, an exponential distribution and an empirical function, are proposed to model the proximity between query terms. Through extensive experiments on standard TREC collections, our proposed proximity-based BM25 model, called BM25P, is compared to strong state-of-the-art evaluation baselines, including the original unigram BM25 model, the Markov Random Field model, and the positional language model. According to the experimental results, the window-based N-gram Counting method, and Survival Analysis over an exponential distribution are the most effective among all four proposed methods, which lead to marked improvement over the baselines. This shows that the use of term proximity considerably enhances the retrieval effectiveness of the classical probabilistic models. It is therefore recommended to deploy a term proximity component in retrieval systems that employ probabilistic models. Crown Copyright (C) 2011 Published by Elsevier Inc. All rights reserved.","Authors":"He, B (He, Ben) ; Huang, JX (Huang, Jimmy Xiangji) ; Zhou, XF (Zhou, Xiaofeng)","Title":"Modeling term proximity for probabilistic information retrieval models"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000291953800010 ISSN: 1532-2882 eISSN: 1532-2890","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY Volume: 62 Issue: 7 Pages: 1325-1344 DOI: 10.1002/asi.21547 Published: JUL 2011","Abstract":"In a previous question answering study, we identified nine semantic-relationship types, including synonyms, hypernyms, word chains, and holonyms, that exist between terms in Text Retrieval Conference queries and those in their supporting sentences in the Advanced Question Answering for Intelligence (Graff, 2002) corpus. The most frequently occurring relationship type was the hypernym(e. g., Katherine Hepburn is an actress). The aim of the present work, therefore, was to develop a method for determining a person's occupation from syntactic data in a text corpus. First, in the P-System, we compared predicate-argument data involving a proper name for different occupations using Okapi's BM25 weighting algorithm. When classifying actors and using sufficiently frequent names, an accuracy of 0.955 was attained. For evaluation purposes, we also implemented a standard apposition-based classifier (A-System). This performs well, but only if a particular name happens to appear in apposition with the corresponding occupation. Last, we created a hybrid (H-System) which combines the strengths of P with those of A. Using data with a minimum of 100 predicate-argument pairs, H performed best with an overall lenient accuracy of 0.750 while A and P scored 0.615 and 0.656, respectively. We therefore conclude that a hybrid approach combining information from different sources is the best way to predict occupations.","Authors":"White, K (White, Kieran) ; Sutcliffe, RFE (Sutcliffe, Richard F. E.)","Title":"Butcher, Baker, or Candlestick Maker? Predicting Occupations Using Predicate-Argument Relations"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000288343900131 ISSN: 0957-4174","Keywords":"Information retrieval; Query expansion; Regression model; Re-ranking model","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 38 Issue: 6 Pages: 7569-7574 DOI: 10.1016/j.eswa.2010.12.108 Published: JUN 2011","Abstract":"Document ranking is an essential problem in the field of information retrieval (IR). Traditional weighting models such as BM25 and Language model can only take advantage of query terms. IR is a complex process that may be affected by a series of heterogeneous features. It is necessary to refine first-pass retrieval results by taking rich features into account. Traditional heuristic re-ranking approaches can only take advantage of a small number of homogeneous features that may affect information retrieval performance. In this paper, we propose and evaluate a regression-based document re-ranking approach for IR, in which we use SVM regression model to learn a re-ranking function automatically. Under this regression-based framework, we can take advantage of rich features to re-rank the firs-pass retrieved documents by traditional weighting models. We conduct a series of experiments on four standard IR collections in two different languages. The experimental results show that our proposed approach can significantly improve the retrieval performance over the first-pass retrieval. Moreover, by refining the first-pass retrieved document set, the traditional pseudo relevant feedback approaches can also be enhanced. Crown Copyright (C) 2010 Published by Elsevier Ltd. All rights reserved.","Authors":"Ye, Z (Ye, Zheng) ; Huang, JXJ (Huang, Jimmy Xiangji) ; Lin, HF (Lin, Hongfei)","Title":"Incorporating rich features to boost information retrieval performance: A SVM-regression based re-ranking approach"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000292304000001 ISSN: 1532-4435","Keywords":"search; term mismatch; kernel machines; similarity learning; s-function; s-kernel KeyWords Plus:USER LOGS; REGULARIZATION","Categories":"Automation & Control Systems; Computer Science Web of Science Categories:Automation & Control Systems; Computer Science, Artificial Intelligence","Journal Information":"JOURNAL OF MACHINE LEARNING RESEARCH Volume: 12 Pages: 1429-1458 Published: MAY 2011","Abstract":"This paper points out that many search relevance models in information retrieval, such as the Vector Space Model, BM25 and Language Models for Information Retrieval, can be viewed as a similarity function between pairs of objects of different types, referred to as an S-function. An S-function is specifically defined as the dot product between the images of two objects in a Hilbert space mapped from two different input spaces. One advantage of taking this view is that one can take a unified and principled approach to address the issues with regard to search relevance. The paper then proposes employing a kernel method to learn a robust relevance model as an S-function, which can effectively deal with the term mismatch problem, one of the biggest challenges in search. The kernel method exploits a positive semi-definite kernel referred to as an S-kernel. The paper shows that when using an S-kernel the model learned by the kernel method is guaranteed to be an S-function. The paper then gives more general principles for constructing S-kernels. A specific implementation of the kernel method is proposed using the Ranking SVM techniques and click-through data. The proposed approach is employed to learn a relevance model as an extension of BM25, referred to as Robust BM25. Experimental results on web search and enterprise search data show that Robust BM25 significantly outperforms baseline methods and can successfully tackle the term mismatch problem.","Authors":"Wu, W (Wu, Wei) ; Xu, J (Xu, Jun) ; Li, H (Li, Hang) ; Oyama, S (Oyama, Satoshi) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Xu, Jun  E-9681-2013 http://orcid.org/0000-0001-5861-5110","Title":"Learning a Robust Relevance Model for Search Using Kernel Methods"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000288514600022 PubMed ID: 21437291 ISSN: 1932-6203","Categories":"Science & Technology - Other Topics Web of Science Categories:Multidisciplinary Sciences","Journal Information":"PLOS ONE Volume: 6 Issue: 3 Article Number: e18029 DOI: 10.1371/journal.pone.0018029 Published: MAR 17 2011","Abstract":"Background: We investigate the accuracy of different similarity approaches for clustering over two million biomedical documents. Clustering large sets of text documents is important for a variety of information needs and applications such as collection management and navigation, summary and analysis. The few comparisons of clustering results from different similarity approaches have focused on small literature sets and have given conflicting results. Our study was designed to seek a robust answer to the question of which similarity approach would generate the most coherent clusters of a biomedical literature set of over two million documents. Methodology: We used a corpus of 2.15 million recent (2004-2008) records from MEDLINE, and generated nine different document-document similarity matrices from information extracted from their bibliographic records, including titles, abstracts and subject headings. The nine approaches were comprised of five different analytical techniques with two data sources. The five analytical techniques are cosine similarity using term frequency-inverse document frequency vectors (tf-idf cosine), latent semantic analysis (LSA), topic modeling, and two Poisson-based language models - BM25 and PMRA (PubMed Related Articles). The two data sources were a) MeSH subject headings, and b) words from titles and abstracts. Each similarity matrix was filtered to keep the top-n highest similarities per document and then clustered using a combination of graph layout and average-link clustering. Cluster results from the nine similarity approaches were compared using (1) within-cluster textual coherence based on the Jensen-Shannon divergence, and (2) two concentration measures based on grant-to-article linkages indexed in MEDLINE. Conclusions: PubMed's own related article approach (PMRA) generated the most coherent and most concentrated cluster solution of the nine text-based similarity approaches tested, followed closely by the BM25 approach using titles and abstracts. Approaches using only MeSH subject headings were not competitive with those based on titles and abstracts.","Authors":"Boyack, KW (Boyack, Kevin W.) ; Newman, D (Newman, David) ; Duhon, RJ (Duhon, Russell J.) ; Klavans, R (Klavans, Richard) ; Patek, M (Patek, Michael) ; Biberstine, JR (Biberstine, Joseph R.) ; Schijvenaars, B (Schijvenaars, Bob) ; Skupin, A (Skupin, Andre) ; Ma, NAL (Ma, Nianli) ; Borner, K (Boerner, Katy) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Schijvenaars, Bob  http://orcid.org/0000-0002-8508-3225 Skupin, Andre  http://orcid.org/0000-0002-8398-8119 Boyack, Kevin  http://orcid.org/0000-0001-7814-8951","Title":"Clustering More than Two Million Biomedical Publications: Comparing the Accuracies of Nine Text-Based Similarity Approaches"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000287329900002 ISSN: 1386-4564","Keywords":"Retrieval constraints; Burstiness; Information retrieval theory; Log-logistic distribution KeyWords Plus:INFORMATION-RETRIEVAL","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL Volume: 14 Issue: 1 Pages: 5-25 Special Issue: SI DOI: 10.1007/s10791-010-9143-7 Published: FEB 2011","Abstract":"We first present in this paper an analytical view of heuristic retrieval constraints which yields simple tests to determine whether a retrieval function satisfies the constraints or not. We then review empirical findings on word frequency distributions and the central role played by burstiness in this context. This leads us to propose a formal definition of burstiness which can be used to characterize probability distributions with respect to this phenomenon. We then introduce the family of information-based IR models which naturally captures heuristic retrieval constraints when the underlying probability distribution is bursty and propose a new IR model within this family, based on the log-logistic distribution. The experiments we conduct on several collections illustrate the good behavior of the log-logistic IR model: It significantly outperforms the Jelinek-Mercer and Dirichlet prior language models on most collections we have used, with both short and long queries and for both the MAP and the precision at 10 documents. It also compares favorably to BM25 and has similar performance to classical DFR models such as InL2 and PL2.","Authors":"Clinchant, S (Clinchant, Stephane) ; Gaussier, E (Gaussier, Eric)","Title":"Retrieval constraints and word frequency distributions a log-logistic model for IR"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000287329900003 ISSN: 1386-4564 eISSN: 1573-7659","Keywords":"Score distribution; Normalization; Distributed retrieval; Fusion; Filtering KeyWords Plus:RELEVANCE","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL Volume: 14 Issue: 1 Pages: 26-46 Special Issue: SI DOI: 10.1007/s10791-010-9145-5 Published: FEB 2011","Abstract":"We review the history of modeling score distributions, focusing on the mixture of normal-exponential by investigating the theoretical as well as the empirical evidence supporting its use. We discuss previously suggested conditions which valid binary mixture models should satisfy, such as the Recall-Fallout Convexity Hypothesis, and formulate two new hypotheses considering the component distributions, individually as well as in pairs, under some limiting conditions of parameter values. From all the mixtures suggested in the past, the current theoretical argument points to the two gamma as the most-likely universal model, with the normal-exponential being a usable approximation. Beyond the theoretical contribution, we provide new experimental evidence showing vector space or geometric models, and BM25, as being 'friendly' to the normal-exponential, and that the non-convexity problem that the mixture possesses is practically not severe. Furthermore, we review recent non-binary mixture models, speculate on graded relevance, and consider methods such as logistic regression for score calibration.","Authors":"Arampatzis, A (Arampatzis, Avi) ; Robertson, S (Robertson, Stephen)","Title":"Modeling score distributions in information retrieval"}]