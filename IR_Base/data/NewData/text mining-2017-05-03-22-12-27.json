[{"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397691800022 ISSN: 0736-5853","Keywords":"Kansei engineering; Text mining; Cross-border logistics service; Service design; Partial least squares KeyWords Plus:CONSUMER-ORIENTED TECHNOLOGY; PRODUCT DEVELOPMENT; BIG DATA; SYSTEM; MODEL; MANAGEMENT; QUALITY; FORM","Categories":"Information Science & Library Science Web of Science Categories:Information Science & Library Science","Journal Information":"TELEMATICS AND INFORMATICS Volume: 34 Issue: 4 Pages: 284-302 DOI: 10.1016/j.tele.2016.08.002 Published: JUL 2017","Abstract":"With the rapid development of cross-border e-commerce, the demand for and importance of cross-border logistics service (CBLS) also increase. A satisfactory CBLS can help promote business activities in cross-border e-commerce. Because customers' logistical needs are increasingly complex and the logistics market is increasingly competitive, a CBLS provider has to be devoted to continually improving and differentiating services to maintain its competitive advantage. Kansei engineering (ICE) is an approach to design the elements which satisfy customers' affective and emotional perceptions into services and products. In this study, the ICE approach is applied to derive ideas for the development of CBLS. For this purpose, Partial Least Squares (PLS) is used to analyze the relationships between the feelings of customers and service elements of CBLS. Moreover, this study demonstrates the applications of text mining techniques to analyze the online contents regarding CBLS. Online content mining assists in identifying the service elements and Kansei words for CBLS. Importantly, the relationship between the feelings of customers and service elements of CBLS obtained by online content mining provides complementary results for CBLS design. Relevance to industry: this study offers an exemplification on applying the integration of Kansei engineering and online content analysis to obtain ideas for the process Kansei design in service industry. Our findings imply that in addition to conventional customer survey, user generated online content analysis should be effective way of catching customer-oriented design elements; they provide complementary effects for Kansei design. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Hsiao, YH (Hsiao, Yu-Hsiang) ; Chen, MC (Chen, Mu-Chen) ; Liao, WC (Liao, Wei-Chien)","Title":"Logistics service design for cross-border E-commerce using Kansei engineering with text-mining-based online content analysis"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000394070100002 ISSN: 1566-2535 eISSN: 1872-6305","Keywords":"Opinion mining; Sentiment analysis; Natural language processing; Deep learning; Machine learning KeyWords Plus:SENTIMENT ANALYSIS INTRODUCTION; CLASSIFICATION","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Theory & Methods","Journal Information":"INFORMATION FUSION Volume: 36 Pages: 10-25 DOI: 10.1016/j.inffus.2016.10.004 Published: JUL 2017","Abstract":"As the prevalence of social media on the Internet, opinion mining has become an essential approach to analyzing so many data. Various applications appear in a wide range of industrial domains. Meanwhile, opinions have diverse expressions which bring along research challenges. Both of the practical demands and research challenges make opinion mining an active research area in recent years. In this paper, we present a review of Natural Language Processing (NLP) techniques for opinion mining. First, we introduce general NLP techniques which are required for text preprocessing. Second, we investigate the approaches of opinion mining for different levels and situations. Then we introduce comparative opinion mining and deep learning approaches for opinion mining. Opinion summarization and advanced topics are introduced later. Finally, we discuss some challenges and open problems related to opinion mining. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Sun, SL (Sun, Shiliang) ; Luo, C (Luo, Chen) ; Chen, JY (Chen, Junyu)","Title":"A review of natural language processing techniques for opinion mining systems"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394077500011 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Short text summarization; Social networks; Ant colony optimization; Graph coloring; Text mining; Local search KeyWords Plus:TEXT","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 74 Pages: 115-126 DOI: 10.1016/j.eswa.2017.01.010 Published: MAY 15 2017","Abstract":"Due to the increasing popularity of contents of social media platforms, the number of posts and messages is steadily increasing. A huge amount of data is generated daily as an outcome of the interactions between fans of the networking platforms. It becomes extremely troublesome to find the most relevant, interactive information for the subscribers. The aim of this work is to enable the users to get a powerful brief of comments without reading the entire list. This paper opens up a new field of short text summarization (STS) predicated on a hybrid ant colony optimization coming with a mechanism of local search, called ACO-LS-STS, to produce an optimal or near-optimal summary. Initially, the graph coloring algorithm, called GC-ISTS, was employed before to shrink the solution area of ants to small sets. Evidently, the main purpose of using the GC algorithm is to make the search process more facilitated, faster and prevents the ants from falling into the local optimum. First, the dissimilar comments are assembled together into the same color, at the same time preserving the information ratio as for an original list of comment. Subsequently, activating the ACO-LS-STS algorithm, which is a novel technique concerning the extraction of the most interactive comments from each color in a parallel form. At the end, the best summary is picked from the best color. This problem is formalized as an optimization problem utilizing GC and ACO-LS to generate the optimal solution. Eventually, the proposed algorithm was evaluated and tested over a collection of Facebook messages with their associated comments. Indeed, it was found that the proposed algorithm has an ability to capture a good solution that is guaranteed to be near optimal and had realized notable performance in comparison with traditional document summarization algorithms. (C) 2017 Elsevier Ltd. All rights reserved.","Authors":"Mosa, MA (Mosa, Mohamed Atef) ; Hamouda, A (Hamouda, Alaa) ; Marei, M (Marei, Mahmoud)","Title":"Graph coloring and ACO based summarization for social networks"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395095800004 ISSN: 1751-7575 eISSN: 1751-7583","Keywords":"Intelligent agent; market surveillance; text mining; financial application KeyWords Plus:SYSTEM; INFORMATION","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"ENTERPRISE INFORMATION SYSTEMS Volume: 11 Issue: 5 Pages: 652-671 DOI: 10.1080/17517575.2015.1075593 Published: MAY 2017","Abstract":"Market surveillance systems have increasingly gained in usage for monitoring trading activities in stock markets to maintain market integrity. Existing systems primarily focus on the numerical analysis of market activity data and generally ignore textual information. To fulfil the requirements of information-based surveillance, a multi-agent-based architecture that uses agent intercommunication and incremental learning mechanisms is proposed to provide a flexible and adaptive inspection process. A prototype system is implemented using the techniques of text mining and rule-based reasoning, among others. Based on experiments in the scalping surveillance scenario, the system can identify target information evidence up to 87.50% of the time and automatically identify 70.59% of cases depending on the constraints on the available information sources. The results of this study indicate that the proposed information surveillance system is effective. This study thus contributes to the market surveillance literature and has significant practical implications.","Authors":"Chen, K (Chen, Kun) ; Li, X (Li, Xin) ; Xu, BX (Xu, Baoxun) ; Yan, JQ (Yan, Jiaqi) ; Wang, HQ (Wang, Huaiqing)","Title":"Intelligent agents for adaptive security market surveillance"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396972300009 ISSN: 0306-4573 eISSN: 1873-5371","Keywords":"Sentiment analysis; Multilingual sentiment analysis; Emotion mining KeyWords Plus:SENTIMENT CLASSIFICATION; BASIC EMOTIONS; REVIEWS","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"INFORMATION PROCESSING & MANAGEMENT Volume: 53 Issue: 3 Pages: 684-704 DOI: 10.1016/j.ipm.2016.12.008 Published: MAY 2017","Abstract":"The importance of emotion mining is acknowledged in a wide range of new applications, thus broadening the potential market already proven for opinion mining. However, the lack of resources for languages other than English is even more critical for emotion mining. In this article, we investigate whether Multilingual Sentiment Analysis delivers reliable and effective results when applied to emotions. For this purpose, we developed experiments involving machine translations over corpora originally written in two languages. Our experimental framework for emotion classification assesses variations on (i) the language of the original text and its translations; (ii) strategies to combine multiple languages to overcome losses due to translation; (iii) options for data pre-processing (tokenization, feature representation and feature selection); and (iv) classification algorithms, including meta classifiers. The results show that emotion classification performance improve significantly with the use of texts in multiple languages, particularly by adopting a stacking of weak monolingual classifiers. Our study also sheds light into the impacts of data preparation strategies and their combination with classification algorithms, and compares differences between polarity and emotion classification according to the same experimental settings. (c) 2017 Elsevier Ltd. All rights reserved.","Authors":"Becker, K (Becker, Karin) ; Moreira, VP (Moreira, Viviane P.) ; dos Santos, AGL (dos Santos, Aline G. L.)","Title":"Multilingual emotion classification using supervised learning: Comparative experiments"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394632200009 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Information extraction; N-ary relation; Ontology; Data mining; Sequential pattern; Quantitative data; Linguistic pattern KeyWords Plus:INFORMATION; ONTOLOGY; PATTERNS; UNITS","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 73 Pages: 115-124 DOI: 10.1016/j.eswa.2016.12.028 Published: MAY 1 2017","Abstract":"Here we present the Xart system based on a three-step hybrid method using data mining approaches and syntactic analysis to automatically discover and extract relevant data modeled as n-ary relations in plain text. A n-ary relation links a studied object with its features considered as several arguments. We addressed the challenge of designing a novel method to handle the identification and extraction of heterogeneous arguments such as symbolic arguments, quantitative arguments composed of numbers and various measurement units. We thus developed the Xart system, which relies on a domain ontology for discovering patterns, in plain text, to identify arguments involved in n-ary relations. The discovered patterns take advantage of different ontological levels that facilitate identification of all arguments and pool them in the sought n-ary relation. (c) 2016 Elsevier Ltd. All rights reserved.","Authors":"Berrahou, SL (Berrahou, Soumia Lilia) ; Buche, P (Buche, Patrice) ; Dibie, J (Dibie, Juliette) ; Roche, M (Roche, Mathieu)","Title":"Xart: Discovery of correlated arguments of n-ary relations in text"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394632200010 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Stock market; Twitter; Data and text mining; Regression KeyWords Plus:INVESTOR SENTIMENT; INFORMATION-CONTENT; MESSAGE BOARDS; NEWS; MEDIA; NOISE; ACCURACY; PRICES; TALK","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 73 Pages: 125-144 DOI: 10.1016/j.eswa.2016.12.036 Published: MAY 1 2017","Abstract":"In this paper, we propose a robust methodology to assess the value of microblogging data to forecast stock market variables: returns, volatility and trading volume of diverse indices and portfolios. The methodology uses sentiment and attention indicators extracted from microblogs (a large Twitter dataset is adopted) and survey indices (AAII and II, USMC and Sentix), diverse forms to daily aggregate these indicators, usage of a Kalman Filter to merge microblog and survey sources, a realistic rolling windows evaluation, several Machine Learning methods and the Diebold-Mariano test to validate if the sentiment and attention based predictions are valuable when compared with an autoregressive baseline. We found that Twitter sentiment and posting volume were relevant for the forecasting of returns of S&P 500 index, portfolios of lower market capitalization and some industries. Additionally, KF sentiment was informative for the forecasting of returns. Moreover, Twitter and KF sentiment indicators were useful for the prediction of some survey sentiment indicators. These results confirm the usefulness of microblogging data for financial expert systems, allowing to predict stock market behavior and providing a valuable alternative for existing survey measures with advantages (e.g., fast and cheap creation, daily frequency). (c) 2016 Elsevier Ltd. All rights reserved.","Authors":"Oliveira, N (Oliveira, Nuno) ; Cortez, P (Cortez, Paulo) ; Areal, N (Areal, Nelson) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Oliveira, Nuno  http://orcid.org/0000-0003-1773-3684 Areal, Nelson  http://orcid.org/0000-0002-1157-0178","Title":"The impact of microblogging data for stock market prediction: Using Twitter to predict returns, volatility, trading volume and survey sentiment indices"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394197700013 ISSN: 0031-3203 eISSN: 1873-5142","Keywords":"Co-embedding generation; Relational information; Heterogeneous object analysis; Joint space projection KeyWords Plus:DIMENSIONALITY REDUCTION; CLASSIFICATION","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic","Journal Information":"PATTERN RECOGNITION Volume: 65 Pages: 146-163 DOI: 10.1016/j.patcog.2016.12.004 Published: MAY 2017","Abstract":"Dimensionality reduction and data embedding methods generate low dimensional representations of a single type of homogeneous data objects. In this work, we examine the problem of generating co-embeddings or pattern representations from two different types of objects within a joint common space of controlled dimensionality, where the only available information is assumed to be a set of pairwise relations or similarities between instances of the two groups. We propose a new method that models the embedding of each object type symmetrically to the other type, subject to flexible scale constraints and weighting parameters. The embedding generation relies on an efficient optimization dispatched using matrix decomposition, that is also extended to support multidimensional co-embeddings. We also propose a scheme of heuristically reducing the parameters of the model, and a simple way of measuring the conformity between the original object relations and the ones re estimated from the co-embeddings, in order to achieve model selection by identifying the optimal model parameters with a simple search procedure. The capabilities of the proposed method are demonstrated with multiple synthetic and real-world datasets from the text mining domain. The experimental results and comparative analyses indicate that the proposed algorithm outperforms existing methods for co-embedding generation.","Authors":"Wu, Y (Wu, Yu) ; Mu, TT (Mu, Tingting) ; Liatsis, P (Liatsis, Panos) ; Goulermas, JY (Goulermas, John Y.)","Title":"Computation of heterogeneous object co-embeddings from relational measurements"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398640800001 PubMed ID: 28387367 ISSN: 2045-2322","Categories":"Science & Technology - Other Topics Web of Science Categories:Multidisciplinary Sciences","Journal Information":"SCIENTIFIC REPORTS Volume: 7 Article Number: 46290 DOI: 10.1038/srep46290 Published: APR 7 2017","Abstract":"The complicated, evolving landscape of cancer mutations poses a formidable challenge to identify cancer genes among the large lists of mutations typically generated in NGS experiments. The ability to prioritize these variants is therefore of paramount importance. To address this issue we developed OncoScore, a text-mining tool that ranks genes according to their association with cancer, based on available biomedical literature. Receiver operating characteristic curve and the area under the curve (AUC) metrics on manually curated datasets confirmed the excellent discriminating capability of OncoScore (OncoScore cut-off threshold = 21.09; AUC = 90.3%, 95% CI: 88.1-92.5%), indicating that OncoScore provides useful results in cases where an efficient prioritization of cancer-associated genes is needed.","Authors":"Rocco, P (Rocco, Piazza) ; Daniele, R (Daniele, Ramazzotti) ; Roberta, S (Roberta, Spinelli) ; Alessandra, P (Alessandra, Pirola) ; Luca, D (Luca, De Sano) ; Pierangelo, F (Pierangelo, Ferrari) ; Vera, M (Vera, Magistroni) ; Nicoletta, C (Nicoletta, Cordani) ; Nitesh, S (Nitesh, Sharma) ; Carlo, GP (Carlo, Gambacorti-Passerini)","Title":"OncoScore: a novel, Internetbased tool to assess the oncogenic potential of genes"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398645300019 PubMed ID: 28225587 ISSN: 0003-2700 eISSN: 1520-6882","Categories":"Chemistry Web of Science Categories:Chemistry, Analytical","Journal Information":"ANALYTICAL CHEMISTRY Volume: 89 Issue: 7 Pages: 3919-3928 DOI: 10.1021/acs.analchem.6b02394 Published: APR 4 2017","Abstract":"A long-standing challenge of untargeted meta-bolomic profiling by ultrahigh-performance liquid chomatography-high-resolution mass spectrometry (UHPLC-HRMS) is efficient transition from unknown mass spectral features to confident metabolite annotations. The compMS(2)Miner (Comprehensive MS2 Miner) package was developed in the R langauge to facilitate rapid, comprehensive feature anntation using a peak-picker-output and MS2 data files as inputs The number of MS2 spectra that can be collected during a metabolomic profiling experiment far outweight the amount of time required for pain-staking manual interpretatipon;therefore,a degree of software workflow autonomy is required for broad-scale metabolic annotatian. CompMS(2)Miner integrates many useful tools in a single workflow for metabolite annotation and also provides a means to overview the MS2 data with a web appication GUI compMS(2)Explorer (Comprehensive MS(2)Explorer) that also facilitates data-sharing and transparency. The automatable compMS(2)Miner workflow consists of the following steps:,(i) matching unknown MS' features to precursor MS2 scans,(ii) filtration of spectral noise (dynamic noise filter),. (iii) generation of composite mass spectra by multiple similar spectrum signal summation and redundant/contaminant spectra removal, (iv) interpretation of possible fragment ion substructure using an internal database, (v) annotation of unknowns with chemical and spectral databases with prediction of mammalian biotransformation metabolites, wrapper functions for in silico fragmentation software, nearest neighbor chemical similarity scoring, random forest based retention time prediction, text-mining based false positive removal/true positive ranking, chemical taxonomic prediction and differential evolution based global annotation score optimization, and (vi) network graph visualizations, data curation, and sharing are made possible via the compMS(2)Explorer application. Metabolite identities and comments can also be recorded using an interactive table within compMS(2)Explorer. The utility of the package is illustrated with a data set of blood serum samples from 7 diet induced obese (DIO) and 7 nonobese (NO) C57BL/6J mice, which were also treated with an antibiotic (streptomycin) to knockdown the gut microbiota. The results of fully autonomous and objective usage of compMS2Miner are presented here. All automatically annotated spectra output by the workflow are provided in the Supporting Information and can alternatively be explored as publically available compMS2Explorer applications for both positive and negative modes (https://wmbedmands.shinyapps.io/compMS2_mouseSera_POS and https://wmbedmands.shinyapps.io/compMS2_ rnouseSera NEG). The workflow provided rapid annotation of a diversity of endogenous and gut microbially derived metabolites affected by both diet and antibiotic treatment, which conformed to previously published reports. Composite spectra (n = 173) were autonomously matched to entries of the Massbank of North America (MoNA) spectral repository. These experimental and virtual (lipidBlast) spectra corresponded to 29 common endogenous compound classes (e.g., 51 lysophosphatidylcholines spectra) and were then used to calculate the ranking capability of 7 individual scoring metrics. It was found that an average of the 7 individual scoring metrics provided the most effective weighted average ranking ability of 3 for the MoNA matched spectra in spite of potential risk of false positive annotations,emerging from automation. Minor structural differences such as relative carbon carbon double bond positions were found in several cases to affect the correct rank of the MoNA annotated metabolite. The latest release and an example workflow is available in the package vignette (https://github.com/WMBEdmands/ compMS2Miner) and a version of the published application is available on the shinyapps.io site (https://wrribedmands.shinyapps. io/compMS2Example).","Authors":"Edmands, WMB (Edmands, William M. B.) ; Petrick, L (Petrick, Lauren) ; Barupal, DK (Barupal, Dinesh K.) ; Scalbert, A (Scalbert, Augustin) ; Wilson, MJ (Wilson, Mark J.) ; Wickliffe, JK (Wickliffe, Jeffrey K.) ; Rappaport, SM (Rappaport, Stephen M.)","Title":"compMS2Miner: An Automatable Metabolite Identification, Visualization, and Data-Sharing R Package for High-Resolution LC-MS Data Sets"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397506200003 ISSN: 0269-2821 eISSN: 1573-7462","Keywords":"Natural language processing; Sentiment analysis; Data mining KeyWords Plus:TWITTER","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"ARTIFICIAL INTELLIGENCE REVIEW Volume: 47 Issue: 4 Pages: 485-505 DOI: 10.1007/s10462-016-9489-3 Published: APR 2017","Abstract":"People express their opinions about things like products, celebrities and services using social media channels. The analysis of these textual contents for sentiments is a gold mine for marketing experts as well as for research in humanities, thus automatic sentiment analysis is a popular area of applied artificial intelligence. The chief objective of this paper is to investigate automatic sentiment analysis on social media contents over various text sources and languages. The comparative findings of the investigation may give useful insights to artificial intelligence researchers who develop sentiment analyzers for a new textual source. To achieve this, we describe supervised machine learning based systems which perform sentiment analysis and we comparatively evaluate them on seven publicly available English and Hungarian databases, which contain text documents taken from Twitter and product review sites. We discuss the differences among these text genres and languages in terms of document- and target-level sentiment analysis.","Authors":"Hangya, V (Hangya, Viktor) ; Farkas, R (Farkas, Richard)","Title":"A comparative empirical study on social media sentiment analysis over various genres and languages"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000398126100013 ISSN: 2055-7671 eISSN: 2055-768X","Categories":"Arts & Humanities - Other Topics; Linguistics Web of Science Categories:Humanities, Multidisciplinary; Linguistics","Journal Information":"DIGITAL SCHOLARSHIP IN THE HUMANITIES Volume: 32 Issue: 1 Pages: 195-208 DOI: 10.1093/llc/fqv031 Published: APR 2017","Abstract":"A Systematic Literature Review (SLR) identifies, evaluates, and synthesizes the literature available for a given topic. This generally requires a significant human workload and has subjectivity bias that could affect the results of such a review. Automated document classification can be a valuable tool for recommending the selection of studies. In this article, we propose an automated pre-selection approach based on text mining and semantic enrichment techniques. Each document is firstly processed by a named entity extractor. The DBpedia URIs coming from the entity linking process are used as external sources of information. Our system collects the bag of words of those sources and it adds them to the initial document. A Multinomial Naive Bayes classifier discriminates whether the enriched document belongs to the positive example set or not. We used an existing manually performed SLR as benchmark data set. We trained our system with different configurations of relevant documents and we tested the goodness of our approach with an empirical assessment. Results show a reduction of the manual workload of 18% that a human researcher has to spend, while holding a remarkable 95% of recall, important condition for the nature itself of SLRs. We measure the effect of the enrichment process to the precision of the classifier and we observed a gain up to 5%.","Authors":"Rizzo, G (Rizzo, Giuseppe) ; Tomassetti, F (Tomassetti, Federico) ; Vetro, A (Vetro, Antonio) ; Ardito, L (Ardito, Luca) ; Torchiano, M (Torchiano, Marco) ; Morisio, M (Morisio, Maurizio) ; Troncy, R (Troncy, Raphael)","Title":"Semantic enrichment for recommendation of primary studies in a systematic literature review"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397581000005 ISSN: 1041-4347 eISSN: 1558-2191","Keywords":"Generative model; comparison mining; comparative sentences KeyWords Plus:EXTRACTION","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING Volume: 29 Issue: 4 Pages: 771-783 DOI: 10.1109/TKDE.2016.2640281 Published: APR 1 2017","Abstract":"Online reviews are important decision aids to consumers. Other than helping users to evaluate individual products, reviews also support comparison shopping by comparing two (or more) products based on a specific aspect. However, making a comparison across two different reviews, written by different authors, is not always equitable due to the different standards and preferences of authors. Therefore, we focus on comparative sentences, whereby two products are compared directly by a review author within a sentence. We study the problem of comparative relation mining. Given a set of comparative sentences, each relating a pair of entities, our objective is three-fold: to interpret the comparative direction in each sentence, to identify the aspect of each sentence, and to determine the relative merits of each entity with respect to that aspect. This requires mining comparative relations at two levels of resolution: at the sentence level, and at the entity level. Our insight is that there is a significant synergy between the two levels. We propose a generative model for comparative text, which jointly models comparative directions at the sentence level, and ranking at the entity level. This model is tested comprehensively on Amazon reviews dataset with good empirical outperformance over pipelined baselines.","Authors":"Tkachenko, M (Tkachenko, Maksim) ; Lauw, HW (Lauw, Hady W.)","Title":"Comparative Relation Generative Model"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398827200007 ISSN: 0219-8770 eISSN: 1793-6950","Keywords":"Technology trend monitoring; emerging trend; early detection; promising solution; maturity level; semantic indicator; knowledge extraction; full text analysis; ontology; hype cycle; weak signal KeyWords Plus:PATENT ANALYSIS; GRAPHENE OXIDE; EXPECTATIONS; STATE; HYPE","Categories":"Business & Economics Web of Science Categories:Management","Journal Information":"INTERNATIONAL JOURNAL OF INNOVATION AND TECHNOLOGY MANAGEMENT Volume: 14 Issue: 2 Special Issue: SI Article Number: 1740012 DOI: 10.1142/S0219877017400120 Published: APR 2017","Abstract":"A novel domain-independent approach to technology trend monitoring is presented in the paper. It is based on the ontology of a technology trend, hype cycles methodology, and semantic indicators which provide evidence of a maturity level of a technology. This approach forms the basis for implementation of text-mining software tools. Algorithms behind these tools allow users to escape from getting too general or garbage results which make it impossible to identify promising technologies at early stages (early detection, weak signals). Besides, these algorithms provide high-quality results in extraction of complex multiword terms which correspond to technological concepts forming a trend. Methodology and software developed as a result of this study are applicable to various industries with minor adjustments and require no deep expert knowledge from a user.","Authors":"Efimenko, IV (Efimenko, Irina V.) ; Khoroshevsky, VF (Khoroshevsky, Vladimir F.)","Title":"Peaks, Slopes, Canyons and Plateaus: Identifying Technology Trends Throughout the Life Cycle"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398827200006 ISSN: 0219-8770 eISSN: 1793-6950","Keywords":"Research profiling; technology intelligence; text mining; bibliometric; biomedical engineering; Thailand KeyWords Plus:SCIENTIFIC COLLABORATION; NETWORKS; NANOTECHNOLOGY; MANAGEMENT; PATTERNS; SCIENCE; FIELD","Categories":"Business & Economics Web of Science Categories:Management","Journal Information":"INTERNATIONAL JOURNAL OF INNOVATION AND TECHNOLOGY MANAGEMENT Volume: 14 Issue: 2 Special Issue: SI Article Number: 1740011 DOI: 10.1142/S0219877017400119 Published: APR 2017","Abstract":"This study focuses on applying bibliometric analysis and text mining technique to generate technology intelligence from publication databases. The intelligence represents the research profile and landscape by highlighting active research areas and revealing professional communities along with their social networks. Professional communities can be not just existing networks, but also hidden ones. In this paper, the analysis of biomedical engineering (BME) field in Thailand is presented as the case study. The findings can be used as key inputs for the development of effective policies and incentives to promote the research activities as well as the collaboration among different groups of experts.","Authors":"Gerdsri, N (Gerdsri, Nathasit) ; Kongthon, A (Kongthon, Alisa) ; Puengrusme, S (Puengrusme, Sudatip)","Title":"Profiling the Research Landscape in Emerging Areas Using Bibliometrics and Text Mining: A Case Study of Biomedical Engineering (BME) in Thailand"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398288100001 ISSN: 0093-5301 eISSN: 1537-5277","Keywords":"consumer sentiment; speech act theory; text mining; online reviews; sales ranks; social media KeyWords Plus:WORD-OF-MOUTH; ILLOCUTIONARY FORCE; NATURAL-LANGUAGE; REVIEWS; TEXT; EMOTION; SPEECH; SALES; CONSUMPTION; EXPERIENCE","Categories":"Business & Economics Web of Science Categories:Business","Journal Information":"JOURNAL OF CONSUMER RESEARCH Volume: 43 Issue: 6 Pages: 875-894 DOI: 10.1093/jcr/ucw070 Published: APR 2017","Abstract":"Deciphering consumers' sentiment expressions from big data (e.g., online reviews) has become a managerial priority to monitor product and service evaluations. However, sentiment analysis, the process of automatically distilling sentiment from text, provides little insight regarding the language granularities beyond the use of positive and negative words. Drawing on speech act theory, this study provides a fine-grained analysis of the implicit and explicit language used by consumers to express sentiment in text. An empirical text-mining study using more than 45,000 consumer reviews demonstrates the differential impacts of activation levels (e.g., tentative language), implicit sentiment expressions (e.g., commissive language), and discourse patterns (e.g., incoherence) on overall consumer sentiment (i.e., star ratings). In two follow-up studies, we demonstrate that these speech act features also influence the readers' behavior and are generalizable to other social media contexts, such as Twitter and Facebook. We contribute to research on consumer sentiment analysis by offering a more nuanced understanding of consumer sentiments and their implications.","Authors":"Ordenes, FV (Ordenes, Francisco Villarroel) ; Ludwig, S (Ludwig, Stephan) ; De Ruyter, K (De Ruyter, Ko) ; Grewal, D (Grewal, Dhruv) ; Wetzels, M (Wetzels, Martin)","Title":"Unveiling What Is Written in the Stars: Analyzing Explicit, Implicit, and Discourse Patterns of Sentiment in Social Media"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397501000006 ISSN: 0934-9839 eISSN: 1435-6066","Keywords":"Service evolution map; Text mining; Co-word analysis; Formal concept analysis; Service documents KeyWords Plus:CO-WORD ANALYSIS; SCIENCE-AND-TECHNOLOGY; BUSINESS SERVICES; SYSTEM-DESIGN; PRODUCT; INFORMATION; OPPORTUNITIES; INTELLIGENCE; ENCOUNTERS; MANAGEMENT","Categories":"Engineering Web of Science Categories:Engineering, Multidisciplinary; Engineering, Industrial; Engineering, Manufacturing","Journal Information":"RESEARCH IN ENGINEERING DESIGN Volume: 28 Issue: 2 Pages: 251-273 DOI: 10.1007/s00163-016-0240-5 Published: APR 2017","Abstract":"As digital convergence has proliferated and products have become smarter, various service concepts have emerged based on the capabilities of products. It has become a main concern to illuminate historical changes and status of service concepts according to the utilisation of product elements to provide valuable information for service development. However, a lacuna still remains in the literature regarding a systematic and quantitative approach on this problem. This study proposes a service evolution map as a tool for analysing the evolutionary paths of service concepts based on the utilisation of product elements. The proposed service evolution map consists of two layers with the time dimension: a product element layer for the utilisation of product elements and a service concept layer for the evolutionary paths of service concepts. Based on the service documents describing what the services are, text mining, co-word analysis, and modified formal concept analysis are employed to develop the product element and service concept layers, respectively. A case study of mobile application services is presented to illustrate the proposed approach. This study is expected to be a basis of future research on the interaction between products and services and service concept design based on the creative utilisation of product elements.","Authors":"Song, B (Song, Bomi) ; Yoon, B (Yoon, Byungun) ; Lee, C (Lee, Changyong) ; Park, Y (Park, Yongtae)","Title":"Development of a service evolution map for service design through application of text mining to service documents"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396962500003 ISSN: 0040-1625 eISSN: 1873-5509","Keywords":"Technology forecasting; Bibliometrics; Technology roadmapping; Data mining; Web content mining; Cloud computing KeyWords Plus:INNOVATION; SCIENCE; BIBLIOMETRICS; FORESIGHT","Categories":"Business & Economics; Public Administration Web of Science Categories:Business; Planning & Development","Journal Information":"TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE Volume: 117 Pages: 25-37 DOI: 10.1016/j.techfore.2017.01.015 Published: APR 2017","Abstract":"One of the biggest challenges for current enterprises is the adoption of emerging technologies as soon as these provide competitive improvements. In this sense, several types of technology forecasting and surveillance activities are present in their daily activity. From the academic point of view, technology forecasting activities involve the combination of methods of a diverse nature, with which the technology is depicted and its potential future paths are discussed. Within this conceptual framework, the present work aims at describing a noire! approach, known as TeknoRoadmap, which combines bibliometrics and technology forecasting methods to depict emerging technologies. Thus, this contribution aims to widen the scope compared to those provided by previous works within the field, and to that end, the depiction of emerging technologies is provided based on two main elements, namely: the profile of the research activity; and a complete technology roadmap. The approach combines consolidated methods such as text mining and roadmapping, and novel ones such as web content mining, with special attention given to forecasting activities. The work provides a detailed description of the steps on which the approach is structured, as well as the results of one specific application to a cutting edge emerging technology: cloud computing. (C) 2017 Elsevier Inc. All rights reserved.","Authors":"Bildosola, I (Bildosola, Inaki) ; Rio-Belver, RM (Maria Rio-Belver, Rosa) ; Garechana, G (Garechana, Gaizka) ; Cilleruelo, E (Cilleruelo, Ernesto)","Title":"TeknoRoadmap, an approach for depicting emerging technologies"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000395391600005 ISSN: 0013-161X eISSN: 1552-3519","Keywords":"text data mining; educational leadership; probabilistic latent topic modeling; literature review; high-performance computing KeyWords Plus:STUDENT-ACHIEVEMENT; SPECIAL-ISSUE; MANAGEMENT; BEHAVIOR; FIELD; DISCIPLINE; PRINCIPALS; SOCIOLOGY; KNOWLEDGE; JOURNALS","Categories":"Education & Educational Research Web of Science Categories:Education & Educational Research","Journal Information":"EDUCATIONAL ADMINISTRATION QUARTERLY Volume: 53 Issue: 2 Pages: 289-323 DOI: 10.1177/0013161X16660585 Published: APR 2017","Abstract":"Purpose: The purpose of this study is to describe the underlying topics and the topic evolution in the 50-year history of educational leadership research literature. Method: We used automated text data mining with probabilistic latent topic models to examine the full text of the entire publication history of all 1,539 articles published in Educational Administration Quarterly (EAQ) from 1965 to 2014. Given the computationally intensive data analysis required by probabilistic topic models, relying on high-performance computing, we used a 10-fold cross-validation to estimate the model in which we categorized each article in each year into one of 19 latent topics and illustrated the rise and fall of topics over the EAQ's 50-year history. Findings: Our model identified a total of 19 topics from the 1965 to 2014 EAQ corpus. Among them, five topics-inequity and social justice, female leadership, school leadership preparation and development, trust, and teaching and instructional leadership-gained research attention over the 50-year time period, whereas the research interest appears to have declined for the topic of epistemology of educational leadership since the 2000s. Other topics waxed and waned over the past five decades. Implications: This study maps the temporal terrain of topics in the educational leadership field over the past 50 years and sheds new light on the development and current status of the central topics in educational leadership research literature. More important, the panoramic view of topical landscape provides a unique backdrop as scholars contemplate the future of educational leadership research.","Authors":"Wang, YY (Wang, Yinying) ; Bowers, AJ (Bowers, Alex J.) ; Fikis, DJ (Fikis, David J.)","Title":"Automated Text Data Mining Analysis of Five Decades of Educational Leadership Research Literature: Probabilistic Topic Modeling of EAQ Articles From 1965 to 2014"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395395600003 ISSN: 0165-5515 eISSN: 1741-6485","Keywords":"Feature selection; text classification; TTC-3600 dataset; Turkish text categorization KeyWords Plus:HYBRID APPROACH; CLASSIFICATION; RETRIEVAL","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF INFORMATION SCIENCE Volume: 43 Issue: 2 Pages: 174-185 DOI: 10.1177/0165551515620551 Published: APR 2017","Abstract":"Owing to the rapid growth of the World Wide Web, the number of documents that can be accessed via the Internet explosively increases with each passing day. Considering news portals in particular, sometimes documents related to categories such as technology, sports and politics seem to be in the wrong category or documents are located in a generic category called others. At this point, text categorization (TC), which is generally addressed as a supervised learning task is needed. Although there are substantial number of studies conducted on TC in other languages, the number of studies conducted in Turkish is very limited owing to the lack of accessibility and usability of datasets created. In this paper, a new dataset named TTC-3600, which can be widely used in studies of TC of Turkish news and articles, is created. TTC-3600 is a well-documented dataset and its file formats are compatible with well-known text mining tools. Five widely used classifiers within the field of TC and two feature selection methods are evaluated on TTC-3600. The experimental results indicate that the best accuracy criterion value 91.03% is obtained with the combination of Random Forest classifier and attribute ranking-based feature selection method in all comparisons performed after pre-processing and feature selection steps. The publicly available TTC-3600 dataset and the experimental results of this study can be utilized in comparative experiments by other researchers.","Authors":"Kilinc, D (Kilinc, Deniz) ; Ozcift, A (Ozcift, Akin) ; Bozyigit, F (Bozyigit, Fatma) ; Yildirim, P (Yildirim, Pelin) ; Yucalar, F (Yucalar, Fatih) ; Borandag, E (Borandag, Emin)","Title":"TTC-3600: A new benchmark dataset for Turkish text categorization"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395395600009 ISSN: 0165-5515 eISSN: 1741-6485","Keywords":"Latent Dirichlet allocation; text clustering; text mining KeyWords Plus:K-MEANS; MODELS; TOPICS","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF INFORMATION SCIENCE Volume: 43 Issue: 2 Pages: 275-292 DOI: 10.1177/0165551516638784 Published: APR 2017","Abstract":"Document clustering can be applied in document organisation and browsing, document summarisation and classification. The identification of an appropriate representation for textual documents is extremely important for the performance of clustering or classification algorithms. Textual documents suffer from the high dimensionality and irrelevancy of text features. Besides, conventional clustering algorithms suffer from several shortcomings, such as slow convergence and sensitivity to the initial value. To tackle the problems of conventional clustering algorithms, metaheuristic algorithms are frequently applied to clustering. In this paper, an improved ant clustering algorithm is presented, where two novel heuristic methods are proposed to enhance the clustering quality of ant-based clustering. In addition, the latent Dirichlet allocation (LDA) is used to represent textual documents in a compact and efficient way. The clustering quality of the proposed ant clustering algorithm is compared to the conventional clustering algorithms using 25 text benchmarks in terms of F-measure values. The experimental results indicate that the proposed clustering scheme outperforms the compared conventional and metaheuristic clustering methods for textual documents.","Authors":"Onan, A (Onan, Aytug) ; Bulut, H (Bulut, Hasan) ; Korukoglu, S (Korukoglu, Serdar)","Title":"An improved ant algorithm with LDA-based representation for text document clustering"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395506500003 ISSN: 1841-9836 eISSN: 1841-9844","Keywords":"web usage behaviour; network topic detection; clicking mode analysis; retrieval mode analysis","Categories":"Automation & Control Systems; Computer Science Web of Science Categories:Automation & Control Systems; Computer Science, Information Systems","Journal Information":"INTERNATIONAL JOURNAL OF COMPUTERS COMMUNICATIONS & CONTROL Volume: 12 Issue: 2 Pages: 183-200 Published: APR 2017","Abstract":"This research has caught researchers' wide attention for detecting network topic exactly with the arrival of big data era characterized by semi-structured or unstructured text. This paper proposes a model of network topic detection based on web usage behaviour mode analysis and mining technology taking Web news as object of research. The author elaborates main function and method proposed in this model, which include the analysis module of Web news instance clicking mode, the analysis module of Web news instance retrieval mode, the analysis module of Web news instance seed and the analysis module of similar Web news instance supporting topics. Based on these functions and methods, the author elaborates main algorithm proposed in this model, which include the mining algorithm of Web news seed instances and the mining algorithm of similar Web news instances supporting topics. These functional algorithms have been applied in processing module of model, and focus on how to detect network topic efficiently from a large number of web usage behaviour towards to Web news instances, in order to explore a research method for network topic detection. The process of experimental analysis includes three steps, firstly, the author analyses the precision of topic detection under different method, secondly, the author completes the impact analysis of Web news topic detection quality from the number of Web news instances concerned and seed threshold, finally, the author completes the quality impact analysis of Web news instances mined supporting topic from the number of Web news instances concerned and probability threshold. The results of experimental analysis show the feasibility, validity and superiority of model design and play an important role in constructing topic-focused Web news corpus so as to provide a real-time data source for topic evolution tracking.","Authors":"Chen, M (Chen, M.)","Title":"Model of Network Topic Detection Based on Web Usage Behaviour Mode Analysis and Mining Technology"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395664200001 PubMed ID: 28241931 ISSN: 1386-5056 eISSN: 1872-8243","Keywords":"Text mining; Emergency departments; Clinical decision support KeyWords Plus:LENGTH-OF-STAY; RANDOM FORESTS; CLASSIFICATION; ADABOOST; IDENTIFICATION; INFORMATION; TRANSFORM; DEMAND; SYSTEM; TREES","Categories":"Computer Science; Health Care Sciences & Services; Medical Informatics Web of Science Categories:Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics","Journal Information":"INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS Volume: 100 Pages: 1-8 DOI: 10.1016/j.ijmedinf.2017.01.001 Published: APR 2017","Abstract":"Objective: Emergency department (ED) overcrowding is a serious issue for hospitals. Early information on short-term inward bed demand from patients receiving care at the ED may reduce the overcrowding problem, and optimize the use of hospital resources. In this study, we use text mining methods to process data from early ED patient records using the SOAP framework, and predict future hospitalizations and discharges. Design: We try different approaches for pre-processing of text records and to predict hospitalization. Sets of-words are obtained via binary representation, term frequency, and term frequency-inverse document frequency. Unigrams, bigrams and trigrams are tested for feature formation. Feature selection is based on chi(2) and F-score metrics. In the prediction module, eight text mining methods are tested: Decision Tree, Random Forest, Extremely Randomized Tree, AdaBoost, Logistic Regression, Multinomial Naive Bayes, Support Vector Machine (Kernel linear) and Nu-Support Vector Machine (Kernel linear). Measurements: Prediction performance is evaluated by F1-scores. Precision and Recall values are also informed for all text mining methods tested. Results: Nu-Support Vector Machine was the text mining method with the best overall performance. Its average F1-score in predicting hospitalization was 77.70%, with a standard deviation (SD) of 0.66%. Conclusions: The method could be used to manage daily routines in EDs such as capacity planning and resource allocation. Text mining could provide valuable information and facilitate decision-making by inward bed management teams. (C) 2017 Elsevier Ireland Ltd. All rights reserved.","Authors":"Lucini, FR (Lucini, Filipe R.) ; Fogliatto, FS (Fogliatto, Flavio S.) ; da Silveira, GJC (da Silveira, Giovani J. C.) ; Neyeloff, JL (Neyeloff, Jeruza L.) ; Anzanello, MJ (Anzanello, Michel J.) ; Kuchenbecker, RD (Kuchenbecker, Ricardo de S.) ; Schaan, BD (Schaan, Beatriz D.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Lucini, Filipe  http://orcid.org/0000-0002-6090-6846","Title":"Text mining approach to predict hospital admissions using early medical records from the emergency department"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395664200012 PubMed ID: 28241932 ISSN: 1386-5056 eISSN: 1872-8243","Keywords":"Defect discovery; Text mining; Quality management KeyWords Plus:SOCIAL MEDIA; SENTIMENT ANALYSIS; DEFECT DISCOVERY; SURVEILLANCE","Categories":"Computer Science; Health Care Sciences & Services; Medical Informatics Web of Science Categories:Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics","Journal Information":"INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS Volume: 100 Pages: 108-120 DOI: 10.1016/j.ijmedinf.2017.01.005 Published: APR 2017","Abstract":"Objectives: Product issues can cost companies millions in lawsuits and have devastating effects on a firm's sales, image and goodwill, especially in the era of social media. The ability for a system to detect the presence of safety and efficacy (S&E) concerns early on could not only protect consumers from injuries due to safety hazards, but could also mitigate financial damage to the manufacturer. Prior studies in the field of automated defect discovery have found industry-specific techniques appropriate to the automotive, consumer electronics, home appliance, and toy industries, but have not investigated pain relief medicines and medical devices. In this study, we focus specifically on automated discovery of S&E concerns in over-the-counter (OTC) joint and muscle pain relief remedies and devices. Methods: We select a dataset of over 32,000 records for three categories of Joint & Muscle Pain Relief treatments from Amazon's online product reviews, and train \"smoke word\" dictionaries which we use to score holdout reviews, for the presence of safety and efficacy issues. We also score using conventional sentiment analysis techniques. Results: Compared to traditional sentiment analysis techniques, we found that smoke term dictionaries were better suited to detect product concerns from online consumer reviews, and significantly outperformed the sentiment analysis techniques in uncovering both efficacy and safety concerns, across all product subcategories. Conclusion: Our research can be applied to the healthcare and pharmaceutical industry in order to detect safety and efficacy concerns, reducing risks that consumers face using these products. These findings can be highly beneficial to improving quality assurance and management in joint and muscle pain relief. (C) 2017 Elsevier B.V. All rights reserved.","Authors":"Adams, DZ (Adams, David Z.) ; Gruss, R (Gruss, Richard) ; Abrahams, AS (Abrahams, Alan S.)","Title":"Automated discovery of safety and efficacy concerns for joint & muscle pain relief treatments from online reviews"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396395500004 ISSN: 1520-9210 eISSN: 1941-0077","Keywords":"Dancelets; dance style; LDA detector; normalized cuts; spatiotemporal features; video recommendation KeyWords Plus:ACTION RECOGNITION; CLASSIFICATION; FEATURES","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications","Journal Information":"IEEE TRANSACTIONS ON MULTIMEDIA Volume: 16 Issue: 4 Pages: 712-724 DOI: 10.1109/TMM.2016.2631881 Published: APR 2017","Abstract":"Dance is a unique and meaningful type of human expression, composed of abundant and various action elements. However, existing methods based on associated texts and spatial visual features have difficulty capturing the highly articulated motion patterns. To overcome this limitation, we propose to take advantage of the intrinsic motion information in dance videos to solve the video recommendation problem. We present a novel system that recommends dance videos based on a mid-level action representation, termed Dancelets. The Dancelets are used to bridge the semantic gap between video content and high-level concept, dance style, which plays a significant role in characterizing different types of dances. The proposed method executes automatic mining of dancelets with a concatenation of normalized cut clustering and linear discriminant analysis. This ensures that the discovered dancelets are both representative and discriminative. Additionally, to exploit the motion cues in videos, we employ motion boundaries as saliency priors to generate volumes of interest and extract C3D features to capture spatiotemporal information from the mid-level patches. Extensive experiments validated on our proposed large dance dataset, HIT Dances dataset, demonstrate the effectiveness of the proposed methods for dance style-based video recommendation.","Authors":"Han, TT (Han, Tingting) ; Yao, HX (Yao, Hongxun) ; Xu, CL (Xu, Chenliang) ; Sun, XS (Sun, Xiaoshuai) ; Zhang, YH (Zhang, Yanhao) ; Corso, JJ (Corso, Jason J.)","Title":"Dancelets Mining for Video Recommendation Based on Dance Styles"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000396413900001 ISSN: 2330-1635 eISSN: 2330-1643","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY Volume: 68 Issue: 4 Pages: 811-829 DOI: 10.1002/asi.23716 Published: APR 2017","Abstract":"Opinion mining refers to the use of natural language processing, text analysis, and computational linguistics to identify and extract subjective information in textual material. Opinion mining, also known as sentiment analysis, has received a lot of attention in recent times, as it provides a number of tools to analyze public opinion on a number of different topics. Comparative opinion mining is a subfield of opinion mining which deals with identifying and extracting information that is expressed in a comparative form (e.g., \"paper X is better than the Y\"). Comparative opinion mining plays a very important role when one tries to evaluate something because it provides a reference point for the comparison. This paper provides a review of the area of comparative opinion mining. It is the first review that cover specifically this topic as all previous reviews dealt mostly with general opinion mining. This survey covers comparative opinion mining from two different angles. One from the perspective of techniques and the other from the perspective of comparative opinion elements. It also incorporates preprocessing tools as well as data set that were used by past researchers that can be useful to future researchers in the field of comparative opinion mining.","Authors":"Varathan, KD (Varathan, Kasturi Dewi) ; Giachanou, A (Giachanou, Anastasia) ; Crestani, F (Crestani, Fabio)","Title":"Comparative Opinion Mining: A Review"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393631700001 ISSN: 0306-4379 eISSN: 1873-6076","Keywords":"Latent semantic indexing; Text-mining; Job market analysis; Web data extraction","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION SYSTEMS Volume: 65 Pages: 1-6 DOI: 10.1016/j.is.2016.10.009 Published: APR 2017","Abstract":"In challenging economic times, the ability to monitor trends and shifts in the job market would be hugely valuable to job-seekers, employers, policy makers and investors. To analyze the job market, researchers are increasingly turning to data science and related techniques which are able to extract underlying patterns from large collections of data. One database which is of particular relevance in the presence context is O*NET, which is one of the most comprehensive publicly accessible databases of occupational requirements for skills, abilities and knowledge. However, by itself the information in O*NET is not enough to characterize the distribution of occupations required in a given market or region. In this paper, we suggest a data mining based approach for identifying the most in-demand occupations in the modern job market. To achieve this, a Latent Semantic Indexing (LSI) model was developed that is capable of matching job advertisement extracted from the Web with occupation description data in the O*NET database. The findings of this study demonstrate the general usefulness and applicability of the proposed method for highlighting job trends in different industries and geographical areas, identifying occupational clusters, studying the changes in jobs context over time and for various other research embodiments.","Authors":"Karakatsanis, I (Karakatsanis, Ioannis) ; AlKhader, W (AlKhader, Wala) ; MacCrory, F (MacCrory, Frank) ; Alibasic, A (Alibasic, Armin) ; Omar, MA (Omar, Mohammad Atif) ; Aung, Z (Aung, Zeyar) ; Woon, WL (Woon, Wei Lee)","Title":"Data mining approach to monitoring the requirements of the job market: A case study"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393631700005 ISSN: 0306-4379 eISSN: 1873-6076","Keywords":"Text mining; User profile; Clustering; Text categorization; Recommendation systems; Social media","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION SYSTEMS Volume: 65 Pages: 52-64 DOI: 10.1016/j.is.2016.11.003 Published: APR 2017","Abstract":"Social media has become an important source of information and a medium for following and spreading trends, news, and ideas all over the world. Although determining the subjects of individual posts is important to extract users' interests from social media, this task is nontrivial because posts are highly contextualized and informal and have limited length. To address this problem, we propose a user modeling framework that maps the content of texts in social media to relevant categories in news media. In our framework, the semantic gaps between social media and news media are reduced by using Wikipedia as an external knowledge base. We map term based features from a short text and a news category into Wikipedia-based features such as Wikipedia categories and article entities. A user's microposts are thus represented in a rich feature space of words. Experimental results show that our proposed method using Wikipedia-based features outperforms other existing methods of identifying users' interests from social media.","Authors":"Kang, J (Kang, Jaeyong) ; Lee, H (Lee, Hyunju)","Title":"Modeling user interest in social media using news media and wikipedia"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000392768700036 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Service quality; Text mining; Healthcare KeyWords Plus:SERVQUAL SCALE; ONLINE; REVIEWS; SATISFACTION; DOCTORS; MODEL","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 71 Pages: 479-492 DOI: 10.1016/j.eswa.2016.11.004 Published: APR 1 2017","Abstract":"Mechanisms for collecting unstructured feedback (i.e., text comments) from patients of healthcare providers have become commonplace, but analysis techniques to examine such feedback have not been frequently applied in this domain. To fill this gap, we apply a text mining methodology to a large set of textual feedback of physicians by their patients and relate the textual commentary to their numeric ratings. While perceptions of healthcare service quality in the form of numeric ratings are easy to aggregate, freeform textual commentary presents more challenges to extracting useful information. Our methodology explores aggregation of the textual commentary using a topic analysis procedure (i.e., latent Dirichlet allocation) and a sentiment tool (i.e., Diction). We then explore how the extracted topic areas and expressed sentiments relate to the physicians' quantitative ratings of service quality from both patients and other physicians. We analyze 23,537 numeric ratings plus textual feedback provided by patients of 3,712 physicians who have also been recommended by other physicians, and determine process quality satisfaction is an important driver of patient perceived quality, whereas clinical quality better reflects physician perceived quality. Our findings lead us to suggest that to maximize the usefulness of online reviews of physicians, potential patients should parse them for particular quality elements they wish to assess and interpret them within the scope of those quality elements. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"James, TL (James, Tabitha L.) ; Calderon, EDV (Calderon, Eduardo D. Villacis) ; Cook, DF (Cook, Deborah F.)","Title":"Exploring patient perceptions of healthcare service quality through analysis of unstructured feedback"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397739600001 PubMed ID: 28359255 ISSN: 1471-2105","Keywords":"Biomedical text; Entity recognition; Relation extraction; Neural network; Joint model KeyWords Plus:CORPUS","Categories":"Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology Web of Science Categories:Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology","Journal Information":"BMC BIOINFORMATICS Volume: 18 Article Number: 198 DOI: 10.1186/s12859-017-1609-9 Published: MAR 31 2017","Abstract":"Background: Extracting biomedical entities and their relations from text has important applications on biomedical research. Previous work primarily utilized feature-based pipeline models to process this task. Many efforts need to be made on feature engineering when feature-based models are employed. Moreover, pipeline models may suffer error propagation and are not able to utilize the interactions between subtasks. Therefore, we propose a neural joint model to extract biomedical entities as well as their relations simultaneously, and it can alleviate the problems above. Results: Our model was evaluated on two tasks, i.e., the task of extracting adverse drug events between drug and disease entities, and the task of extracting resident relations between bacteria and location entities. Compared with the state-of-the-art systems in these tasks, our model improved the F1 scores of the first task by 5.1% in entity recognition and 8.0% in relation extraction, and that of the second task by 9.2% in relation extraction. Conclusions: The proposed model achieves competitive performances with less work on feature engineering. We demonstrate that the model based on neural networks is effective for biomedical entity and relation extraction. In addition, parameter sharing is an alternative method for neural models to jointly process this task. Our work can facilitate the research on biomedical text mining.","Authors":"Li, F (Li, Fei) ; Zhang, MS (Zhang, Meishan) ; Fu, GH (Fu, Guohong) ; Ji, DH (Ji, Donghong)","Title":"A neural joint model for entity and relation extraction from biomedical text"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397471600003 PubMed ID: 28347342 ISSN: 1471-2180","Keywords":"Genomic Island; Pathogenicity Island; B. cenocepacia AU1054; Virulence factor KeyWords Plus:CYSTIC-FIBROSIS PATIENTS; ARGININE DEIMINASE PATHWAY; CEPACIA COMPLEX; LARIBACTER-HONGKONGENSIS; INTRACELLULAR SURVIVAL; BACTERIAL PATHOGENS; VIRULENCE FACTORS; GENE; EPIDEMIOLOGY; EVOLUTION","Categories":"Microbiology Web of Science Categories:Microbiology","Journal Information":"BMC MICROBIOLOGY Volume: 17 Article Number: 73 DOI: 10.1186/s12866-017-0986-6 Published: MAR 27 2017","Abstract":"Background: Genomic islands (GIs) are genomic regions that reveal evidence of horizontal DNA transfer. They can code for many functions and may augment a bacterium's adaptation to its host or environment. GIs have been identified in strain J2315 of Burkholderia cenocepacia, whereas in strain AU 1054 there has been no published works on such regions according to our text mining and keyword search in Medline. Results: In this study, we identified 21 GIs in AU 1054 by combining two computational tools. Feature analyses suggested that the predictions are highly reliable and hence illustrated the advantage of joint predictions by two independent methods. Based on putative virulence factors, four GIs were further identified as pathogenicity islands (PAIs). Through experiments of gene deletion mutants in live bacteria, two putative PAIs were confirmed, and the virulence factors involved were identified as lipA and copR. The importance of the genes lipA (from PAI 1) and copR (from PAI 2) for bacterial invasion and replication indicates that they are required for the invasive properties of B. cenocepacia and may function as virulence determinants for bacterial pathogenesis and host infection. Conclusions: This approach of in silico prediction of GIs and subsequent identification of potential virulence factors in the putative island regions with final validation using wet experiments could be used as an effective strategy to rapidly discover novel virulence factors in other bacterial species and strains.","Authors":"Guo, FB (Guo, Feng-Biao) ; Xiong, LF (Xiong, Lifeng) ; Zhang, KY (Zhang, Kai-Yue) ; Dong, C (Dong, Chuan) ; Zhang, FZ (Zhang, Fa-Zhan) ; Woo, PCY (Woo, Patrick C. Y.)","Title":"Identification and analysis of genomic islands in Burkholderia cenocepacia AU 1054 with emphasis on pathogenicity islands"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397970600008 PubMed ID: 28348935 ISSN: 2167-8359","Keywords":"Drug repositioning; Drug repurposing; Indication discovery; ClinicalTrials.gov; Text mining KeyWords Plus:CELL-LINES; VITAMIN-K; TELMISARTAN; APOPTOSIS; PROLIFERATION; GAMMA","Categories":"Science & Technology - Other Topics Web of Science Categories:Multidisciplinary Sciences","Journal Information":"PEERJ Volume: 5 Article Number: e3154 DOI: 10.7717/peerj.3154 Published: MAR 23 2017","Abstract":"Drug repositioning (i.e., drug repurposing) is the process of discovering new uses for marketed drugs. Historically, such discoveries were serendipitous. However, the rapid growth in electronic clinical data and text mining tools makes it feasible to systematically identify drugs with the potential to be repurposed. Described here is a novel method of drug repositioning by mining ClinicalTrials.gov. The text mining tools I2E (Linguamatics) and PolyAnalyst (Megaputer) were utilized. An I2E query extracts Serious Adverse Events (SAE) data from randomized trials in ClinicalTrials.gov. Through a statistical algorithm, a PolyAnalyst workflow ranks the drugs where the treatment arm has fewer predefined SAEs than the control arm, indicating that potentially the drug is reducing the level of SAE. Hypotheses could then be generated for the new use of these drugs based on the predefined SAE that is indicative of disease (for example, cancer).","Authors":"Su, EW (Su, Eric Wen) ; Sanger, TM (Sanger, Todd M.)","Title":"Systematic drug repositioning through mining adverse event data in ClinicalTrials.gov"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397531600001 ISSN: 1758-0463","Categories":"Mathematical & Computational Biology Web of Science Categories:Mathematical & Computational Biology","Journal Information":"DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION Article Number: bax012 DOI: 10.1093/database/bax012 Published: MAR 18 2017","Abstract":"Experimentally generated biological information needs to be organized and structured in order to become meaningful knowledge. However, the rate at which new information is being published makes manual curation increasingly unable to cope. Devising new curation strategies that leverage upon data mining and text analysis is, therefore, a promising avenue to help life science databases to cope with the deluge of novel information. In this article, we describe the integration of text mining technologies in the curation pipeline of the RegulonDB database, and discuss how the process can enhance the productivity of the curators. Specifically, a named entity recognition approach is used to pre-annotate terms referring to a set of domain entities which are potentially relevant for the curation process. The annotated documents are presented to the curator, who, thanks to a custom-designed interface, can select sentences containing specific types of entities, thus restricting the amount of text that needs to be inspected. Additionally, a module capable of computing semantic similarity between sentences across the entire collection of articles to be curated is being integrated in the system. We tested the module using three sets of scientific articles and six domain experts. All these improvements are gradually enabling us to obtain a high throughput curation process with the same quality as manual curation.","Authors":"Rinaldi, F (Rinaldi, Fabio) ; Lithgow, O (Lithgow, Oscar) ; Gama-Castro, S (Gama-Castro, Socorro) ; Solano, H (Solano, Hilda) ; Lopez, A (Lopez, Alejandra) ; Rascado, LJM (Rascado, Luis Jose Muniz) ; Ishida-Gutierrez, C (Ishida-Gutierrez, Cecilia) ; Mendez-Cruz, CF (Mendez-Cruz, Carlos-Francisco) ; Collado-Vides, J (Collado-Vides, Julio)","Title":"Strategies towards digital and semi-automated curation in RegulonDB"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395213300003 ISSN: 0950-7051 eISSN: 1872-7409","Keywords":"Satiric news; Satire detection; Irony detection; Customer reviews; Ensembled feature subset selection; Sentiment analysis; LIWC; TAALES KeyWords Plus:NETWORKS; SARCASM","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"KNOWLEDGE-BASED SYSTEMS Volume: 120 Pages: 15-33 DOI: 10.1016/j.knosys.2016.12.018 Published: MAR 15 2017","Abstract":"Figurative language detection has always been a difficult task for human beings while being a more difficult proposition, even if automated using text and data mining. The available computational approaches are also quite limited in their capabilities and scope. In this regard, we propose an ensembled text feature selection method followed by a new framework in the paradigm of text and data mining to automatically detect satire, sarcasm, and irony found in news and customer reviews. The effectiveness of the proposed approach was demonstrated on three datasets including two satiric and one ironic dataset. The proposed methodology performed well on one satiric dataset and yielded promising results on the remaining two datasets. Moreover, we found out some interesting common characteristics of satire and irony like affective process (negative emotion), personal concern (leisure), biological process (body and sexual), perception (see), informal language (swear), social process (male), cognitive process (certain), and psycholinguistic (concreteness and imageability), which were extracted from three corpora. Of particular significance is the comparison of our approach with human annotators' evaluations, which served as a baseline in these tasks. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Ravi, K (Ravi, Kumar) ; Ravi, V (Ravi, Vadlamani)","Title":"A novel automatic satire and irony detection using ensembled feature selection and data mining"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396651200001 PubMed ID: 28294141 ISSN: 2045-2322","Categories":"Science & Technology - Other Topics Web of Science Categories:Multidisciplinary Sciences","Journal Information":"SCIENTIFIC REPORTS Volume: 7 Article Number: 44085 DOI: 10.1038/srep44085 Published: MAR 15 2017","Abstract":"Drug resistance is becoming a serious problem that leads to the failure of standard treatments, which is generally developed because of genetic mutations of certain molecules. Here, we present GEAR (A database of Genomic Elements Associated with drug Resistance) that aims to provide comprehensive information about genomic elements (including genes, single-nucleotide polymorphisms and microRNAs) that are responsible for drug resistance. Right now, GEAR contains 1631 associations between 201 human drugs and 758 genes, 106 associations between 29 human drugs and 66 miRNAs, and 44 associations between 17 human drugs and 22 SNPs. These relationships are firstly extracted from primary literature with text mining and then manually curated. The drug resistome deposited in GEAR provides insights into the genetic factors underlying drug resistance. In addition, new indications and potential drug combinations can be identified based on the resistome. The GEAR database can be freely accessed through http://gear.comp-sysbio.org.","Authors":"Wang, YY (Wang, Yin-Ying) ; Chen, WH (Chen, Wei-Hua) ; Xiao, PP (Xiao, Pei-Pei) ; Xie, WB (Xie, Wen-Bin) ; Luo, QB (Luo, Qibin) ; Bork, P (Bork, Peer) ; Zhao, XM (Zhao, Xing-Ming)","Title":"GEAR: A database of Genomic Elements Associated with drug Resistance"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396087900050 PubMed ID: 28278243 ISSN: 1932-6203","Categories":"Science & Technology - Other Topics Web of Science Categories:Multidisciplinary Sciences","Journal Information":"PLOS ONE Volume: 12 Issue: 3 Article Number: e0173152 DOI: 10.1371/journal.pone.0173152 Published: MAR 9 2017","Abstract":"How does scientific research affect the world around us? Being able to answer this question is of great importance in order to appropriately channel efforts and resources in science. The impact by scientists in academia is currently measured by citation based metrics such as h-index, i-index and citation counts. These academic metrics aim to represent the dissemination of knowledge among scientists rather than the impact of the research on the wider world. In this work we are interested in measuring scientific impact beyond academia, on the economy, society, health and legislation (comprehensive impact). Indeed scientists are asked to demonstrate evidence of such comprehensive impact by authoring case studies in the context of the Research Excellence Framework (REF). We first investigate the extent to which existing citation based metrics can be indicative of comprehensive impact. We have collected all recent REF impact case studies from 2014 and we have linked these to papers in citation networks that we constructed and derived from CiteSeerX, arXiv and PubMed Central using a number of text processing and information retrieval techniques. We have demonstrated that existing citation-based metrics for impact measurement do not correlate well with REF impact results. We also consider metrics of online attention surrounding scientific works, such as those provided by the Altmetric API. We argue that in order to be able to evaluate wider non-academic impact we need to mine information from a much wider set of resources, including social media posts, press releases, news articles and political debates stemming from academic work. We also provide our data as a free and reusable collection for further analysis, including the PubMed citation network and the correspondence between REF case studies, grant applications and the academic literature.","Authors":"Ravenscroft, J (Ravenscroft, James) ; Liakata, M (Liakata, Maria) ; Clare, A (Clare, Amanda) ; Duma, D (Duma, Daniel)","Title":"Measuring scientific impact beyond academia: An assessment of existing impact metrics and proposed improvements"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396021100063 PubMed ID: 28257498 ISSN: 1932-6203","Categories":"Science & Technology - Other Topics Web of Science Categories:Multidisciplinary Sciences","Journal Information":"PLOS ONE Volume: 12 Issue: 3 Article Number: e0173132 DOI: 10.1371/journal.pone.0173132 Published: MAR 3 2017","Abstract":"Chemical exposure assessments are based on information collected via different methods, such as biomonitoring, personal monitoring, environmental monitoring and questionnaires. The vast amount of chemical-specific exposure information available from web-based databases, such as PubMed, is undoubtedly a great asset to the scientific community. However, manual retrieval of relevant published information is an extremely time consuming task and overviewing the data is nearly impossible. Here, we present the development of an automatic classifier for chemical exposure information. First, nearly 3700 abstracts were manually annotated by an expert in exposure sciences according to a taxonomy exclusively created for exposure information. Natural Language Processing (NLP) techniques were used to extract semantic and syntactic features relevant to chemical exposure text. Using these features, we trained a supervised machine learning algorithm to automatically classify PubMed abstracts according to the exposure taxonomy. The resulting classifier demonstrates good performance in the intrinsic evaluation. We also show that the classifier improves information retrieval of chemical exposure data compared to keyword-based PubMed searches. Case studies demonstrate that the classifier can be used to assist researchers by facilitating information retrieval and classification, enabling data gap recognition and overviewing available scientific literature using chemical-specific publication profiles. Finally, we identify challenges to be addressed in future development of the system.","Authors":"Larsson, K (Larsson, Kristin) ; Baker, S (Baker, Simon) ; Silins, I (Silins, Ilona) ; Guo, YF (Guo, Yufan) ; Stenius, U (Stenius, Ulla) ; Korhonen, A (Korhonen, Anna) ; Berglund, M (Berglund, Marika) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Larsson, Kristin  http://orcid.org/0000-0003-0398-0289","Title":"Text mining for improved exposure assessment"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397647400001 ISSN: 1176-9351","Keywords":"Clinical data warehouse; precision medicine; semantic interoperability; synoptic pathology reports KeyWords Plus:SEMANTIC INTEROPERABILITY; HL7; ARCHITECTURE; MANAGEMENT; STANDARDS; CANCER; MODEL; CARE","Categories":"Mathematical & Computational Biology Web of Science Categories:Mathematical & Computational Biology","Journal Information":"CANCER INFORMATICS Volume: 16 Pages: 1-10 DOI: 10.1177/1176935117694349 Published: MAR 2 2017","Abstract":"Leading institutions throughout the country have established Precision Medicine programs to support personalized treatment of patients. A cornerstone for these programs is the establishment of enterprise-wide Clinical Data Warehouses. Working shoulder-to-shoulder, a team of physicians, systems biologists, engineers, and scientists at Rutgers Cancer Institute of New Jersey have designed, developed, and implemented the Warehouse with information originating from data sources, including Electronic Medical Records, Clinical Trial Management Systems, Tumor Registries, Biospecimen Repositories, Radiology and Pathology archives, and Next Generation Sequencing services. Innovative solutions were implemented to detect and extract unstructured clinical information that was embedded in paper/ text documents, including synoptic pathology reports. Supporting important precision medicine use cases, the growing Warehouse enables physicians to systematically mine and review the molecular, genomic, image-based, and correlated clinical information of patient tumors individually or as part of large cohorts to identify changes and patterns that may influence treatment decisions and potential outcomes.","Authors":"Foran, DJ (Foran, David J.) ; Chen, WJ (Chen, Wenjin) ; Chu, HQ (Chu, Huiqi) ; Sadimin, E (Sadimin, Evita) ; Loh, D (Loh, Doreen) ; Riedlinger, G (Riedlinger, Gregory) ; Goodell, LA (Goodell, Lauri A.) ; Ganesan, S (Ganesan, Shridar) ; Hirshfield, K (Hirshfield, Kim) ; Rodriguez, L (Rodriguez, Lorna) ; DiPaola, RS (DiPaola, Robert S.) ...More...Less","Title":"Roadmap to a Comprehensive Clinical Data Warehouse for Precision Medicine Applications in Oncology"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398919900002 ISSN: 1073-0516 eISSN: 1557-7325","Keywords":"Color semantics; topic modeling; generative models; visual design mining; visual design language; interaction design; aesthetics; color palette recommendation; design example retrieval; image retrieval; image color selection; pattern recoloring KeyWords Plus:RUSSIAN BLUES; PREFERENCE; EMOTION; CULTURE","Categories":"Computer Science Web of Science Categories:Computer Science, Cybernetics; Computer Science, Information Systems","Journal Information":"ACM TRANSACTIONS ON COMPUTER-HUMAN INTERACTION Volume: 24 Issue: 1 Article Number: 2 DOI: 10.1145/3009924 Published: MAR 2017","Abstract":"We study the concept of color semantics by modeling a dataset of magazine cover designs, evaluating the model via crowdsourcing, and demonstrating several prototypes that facilitate color-related design tasks. We investigate a probabilistic generative modeling framework that expresses semantic concepts as a combination of color and word distributions-color-word topics. We adopt an extension to Latent Dirichlet Allocation (LDA) topic modeling, called LDA-dual, to infer a set of color-word topics over a corpus of 2,654 magazine covers spanning 71 distinct titles and 12 genres. Although LDA models text documents as distributions over word topics, we model magazine covers as distributions over color-word topics. The results of our crowdsourcing experiments confirm that the model is able to successfully discover the associations between colors and linguistic concepts. Finally, we demonstrate several prototype applications that use the learned model to enable more meaningful interactions in color palette recommendation, design example retrieval, pattern recoloring, image retrieval, and image color selection.","Authors":"Jahanian, A (Jahanian, Ali) ; Keshvari, S (Keshvari, Shaiyan) ; Vishwanathan, SVN (Vishwanathan, S. V. N.) ; Allebach, JP (Allebach, Jan P.)","Title":"Colors - Messengers of Concepts: Visual Design Mining for Learning Color Semantics"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000398927700004 ISSN: 1567-4223 eISSN: 1873-7846","Keywords":"Review entropy; Online WOM effect; Text mining; Movie; Information search behavior KeyWords Plus:WORD-OF-MOUTH; K SELECTION QUERIES; PERCEIVED HELPFULNESS; INTERNATIONAL MARKETS; RELATIONAL DATABASES; PRODUCT REVIEWS; NEGATIVITY BIAS; MOTION-PICTURES; FILM-CRITICS; COMMUNICATION","Categories":"Business & Economics; Computer Science Web of Science Categories:Business; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications","Journal Information":"ELECTRONIC COMMERCE RESEARCH AND APPLICATIONS Volume: 22 Pages: 42-52 DOI: 10.1016/j.elerap.2017.03.001 Published: MAR-APR 2017","Abstract":"Sentiments from online word-of-mouth (WOM) are often controversial, since individuals have different preferences toward the same products. Past studies have focused on online WOM effects by measuring WOM volume and valence. However, few studies have investigated how the entropy of the review text sentiment influences the relationship between online WOM and product sales. As WOM valence and volume are usually provided at an aggregated level, consumers often do not have enough information to make a decision. In this case, reading online review text has become an important process for consumers to make purchasing decisions. However, when consumers encounter too many positive review texts, they may doubt the credibility of online WOM itself. Thus, we analyzed the entropy of the review text sentiments by conducting text-mining techniques. We classified review text sentiment into positive, negative, and neutral categories and created an entropy variable. A high level of entropy in review texts indicates that sentiment from review texts are equally distributed, but not biased, towards positive or negative sentiment. We estimated our research model with the entropy variable in a panel dataset for 204 movies over a half-year period. The results suggest that the entropy level in the review texts has a positive moderating impact on the relationship between WOM (e. g., valence and volume) and movie box office sales. The findings imply that deleting negative reviews to enhance product sales may not help online retailers or related parties. (C) 2017 Elsevier B.V. All rights reserved.","Authors":"Lee, JH (Lee, Jong Hyup) ; Jung, SH (Jung, Sun Ho) ; Park, J (Park, JaeHong)","Title":"The role of entropy of review text sentiments on online WOM and movie box office sales"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398736700146 ISSN: 1996-1073","Keywords":"deep learning; recurrent neural network (RNN); natural language processing (NLP); long short-term memory (LSTM); unstructured data; malfunction inspection report KeyWords Plus:CONDITION-BASED MAINTENANCE; SHORT-TERM-MEMORY; POWER TRANSFORMER; DIAGNOSIS; NETWORKS","Categories":"Energy & Fuels Web of Science Categories:Energy & Fuels","Journal Information":"ENERGIES Volume: 10 Issue: 3 Article Number: 406 DOI: 10.3390/en10030406 Published: MAR 2017","Abstract":"This paper documents the condition-based maintenance (CBM) of power transformers, the analysis of which relies on two basic data groups: structured (e.g., numeric and categorical) and unstructured (e.g., natural language text narratives) which accounts for 80% of data required. However, unstructured data comprised of malfunction inspection reports, as recorded by operation and maintenance of the power grid, constitutes an abundant untapped source of power insights. This paper proposes a method for malfunction inspection report processing by deep learning, which combines the text data mining-oriented recurrent neural networks (RNN) with long short-term memory (LSTM). In this paper, the effectiveness of the RNN-LSTM network for modeling inspection data is established with a straightforward training strategy in which we replicate targets at each sequence step. Then, the corresponding fault labels are given in datasets, in order to calculate the accuracy of fault classification by comparison with the original data labels and output samples. Experimental results can reflect how key parameters may be selected in the configuration of the key variables to achieve optimal results. The accuracy of the fault recognition demonstrates that the method we proposed can provide a more effective way for grid inspection personnel to deal with unstructured data.","Authors":"Wei, DQ (Wei, Daqian) ; Wang, B (Wang, Bo) ; Lin, G (Lin, Gang) ; Liu, DC (Liu, Dichen) ; Dong, ZY (Dong, Zhaoyang) ; Liu, HS (Liu, Hesen) ; Liu, YL (Liu, Yilu)","Title":"Research on Unstructured Text Data Mining and Fault Classification Based on RNN-LSTM with Malfunction Inspection Report"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398975200014 PubMed ID: 28344914 ISSN: 2190-7188 eISSN: 2190-7196","Keywords":"Automatic classification; Text mining; Decision Trees; Biobank","Categories":"Medical Informatics Web of Science Categories:Medical Informatics","Journal Information":"HEALTH AND TECHNOLOGY Volume: 7 Issue: 1 Pages: 81-88 Special Issue: SI DOI: 10.1007/s12553-016-0169-8 Published: MAR 2017","Abstract":"In this paper an automatic classification system for pathological findings is presented. The starting point in our undertaking was a pathologic tissue collection with about 1.4 million tissue samples described by free text records over 23 years. Exploring knowledge out of this \"big data\" pool is a challenging task, especially when dealing with unstructured data spanning over many years. The classification is based on an ontology-based term extraction and decision tree build with a manually curated classification system. The information extracting system is based on regular expressions and a text substitution system. We describe the generation of the decision trees by medical experts using a visual editor. Also the evaluation of the classification process with a reference data set is described. We achieved an F-Score of 89,7% for ICD-10 and an F-Score of 94,7% for ICD-O classification. For the information extraction of the tumor staging and receptors we achieved am F-Score ranging from 81,8 to 96,8%.","Authors":"Reihs, R (Reihs, Robert) ; Mueller, H (Mueller, Heimo) ; Sauer, S (Sauer, Stefan) ; Zatloukal, K (Zatloukal, Kurt)","Title":"Automatic classification of histopathological diagnoses for building a large scale tissue catalogue"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398908700005 ISSN: 0219-6492 eISSN: 1793-6926","Keywords":"Bug severity; cross project prediction; text mining; ensemble approach KeyWords Plus:PREDICTION","Categories":"Information Science & Library Science Web of Science Categories:Information Science & Library Science","Journal Information":"JOURNAL OF INFORMATION & KNOWLEDGE MANAGEMENT Volume: 16 Issue: 1 Article Number: 1750005 DOI: 10.1142/S0219649217500058 Published: MAR 2017","Abstract":"The automatic bug severity prediction will be useful in prioritising the development efforts, allocating resources and bug fixer. It needs historical data on which classifiers can be trained. In the absence of such historical data cross project prediction provides a good solution. In this paper, our objective is to automate the bug severity prediction by using a bug metric summary and to identify best training candidates in cross project context. The text mining technique has been used to extract the summary terms and trained the classifiers using these terms. About 63 training candidates have been designed by combining seven datasets of Eclipse projects to develop the severity prediction models. To deal with the imbalance bug data problem, we employed two approaches of ensemble by using two operators available in RapidMiner: Vote and Bagging. Results show that k-Nearest Neighbour (k-NN) performance is better than the Support Vector Machine (SVM) performance. Naive Bayes f-measure performance is poor, i.e. below 34.25%. In case of k-NN, developing training candidates by combining more than one training datasets helps in improving the performances (f-measure and accuracy). The two ensemble approaches have improved the f-measure performance up to 5% and 10% respectively for the severity levels having less number of bug reports in comparison of major severity level. We have further motivated the paper with a cross project bug severity prediction between Eclipse and Mozilla products. Results show that Mozilla products can be used to build reliable prediction models for Eclipse products and vice versa in case of SVM and k-NN classifiers.","Authors":"Singh, VB (Singh, V. B.) ; Misra, S (Misra, Sanjay) ; Sharma, M (Sharma, Meera)","Title":"Bug Severity Assessment in Cross Project Context and Identifying Training Candidates"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397855900001 PubMed ID: 27163413 ISSN: 0006-341X eISSN: 1541-0420","Keywords":"Clustering; Convex optimization; Fused lasso; Gene expression; Reproducible research; Structured sparsity KeyWords Plus:SINGULAR-VALUE DECOMPOSITION; HIGH-DIMENSIONAL DATA; GENE-EXPRESSION DATA; PRINCIPAL COMPONENTS; MICROARRAY DATA; LASSO; ALGORITHMS; REGRESSION; OPTIMIZATION; SELECTION","Categories":"Life Sciences & Biomedicine - Other Topics; Mathematical & Computational Biology; Mathematics Web of Science Categories:Biology; Mathematical & Computational Biology; Statistics & Probability","Journal Information":"BIOMETRICS Volume: 73 Issue: 1 Pages: 10-19 DOI: 10.1111/biom.12540 Published: MAR 2017","Abstract":"In the biclustering problem, we seek to simultaneously group observations and features. While biclustering has applications in a wide array of domains, ranging from text mining to collaborative filtering, the problem of identifying structure in high-dimensional genomic data motivates this work. In this context, biclustering enables us to identify subsets of genes that are co-expressed only within a subset of experimental conditions. We present a convex formulation of the biclustering problem that possesses a unique global minimizer and an iterative algorithm, COBRA, that is guaranteed to identify it. Our approach generates an entire solution path of possible biclusters as a single tuning parameter is varied. We also show how to reduce the problem of selecting this tuning parameter to solving a trivial modification of the convex biclustering problem. The key contributions of our work are its simplicity, interpretability, and algorithmic guarantees-features that arguably are lacking in the current alternative algorithms. We demonstrate the advantages of our approach, which includes stably and reproducibly identifying biclusterings, on simulated and real microarray data.","Authors":"Chi, EC (Chi, Eric C.) ; Allen, GI (Allen, Genevera I.) ; Baraniuk, RG (Baraniuk, Richard G.)","Title":"Convex Biclustering"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398040600006 ISSN: 0282-423X","Keywords":"Automated coding; Machine learning; ISCO-88; ALLBUS","Categories":"Mathematical Methods In Social Sciences; Mathematics Web of Science Categories:Social Sciences, Mathematical Methods; Statistics & Probability","Journal Information":"JOURNAL OF OFFICIAL STATISTICS Volume: 33 Issue: 1 Pages: 101-122 DOI: 10.1515/JOS-2017-0006 Published: MAR 2017","Abstract":"Occupation coding, an important task in official statistics, refers to coding a respondent's text answer into one of many hundreds of occupation codes. To date, occupation coding is still at least partially conducted manually, at great expense. We propose three methods for automatic coding: combining separate models for the detailed occupation codes and for aggregate occupation codes, a hybrid method that combines a duplicate-based approach with a statistical learning algorithm, and a modified nearest neighbor approach. Using data from the German General Social Survey (ALLBUS), we show that the proposed methods improve on both the coding accuracy of the underlying statistical learning algorithm and the coding accuracy of duplicates where duplicates exist. Further, we find defining duplicates based on ngram variables (a concept from text mining) is preferable to one based on exact string matches.","Authors":"Gweon, H (Gweon, Hyukjun) ; Schonlau, M (Schonlau, Matthias) ; Kaczmirek, L (Kaczmirek, Lars) ; Blohm, M (Blohm, Michael) ; Steiner, S (Steiner, Stefan)","Title":"Three Methods for Occupation Coding Based on Statistical Learning"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394496800006 PubMed ID: 24721977 ISSN: 1549-8417","Keywords":"electronic health records; patient safety; medical errors; iatrogenic disease; artificial intelligence KeyWords Plus:STATISTICAL TEXT CLASSIFICATION; CLINICAL INCIDENT REPORTS; INFORMATION-TECHNOLOGY; MALPRACTICE CLAIMS","Categories":"Health Care Sciences & Services Web of Science Categories:Health Care Sciences & Services; Health Policy & Services","Journal Information":"JOURNAL OF PATIENT SAFETY Volume: 13 Issue: 1 Pages: 31-36 Published: MAR 2017","Abstract":"Introduction: The objective of this study was to develop a semiautomated approach to screening cases that describe hazards associated with the electronic health record (EHR) from a mandatory, populationbased patient safety reporting system. Methods: Potentially relevant cases were identified through a query of the Pennsylvania Patient Safety Reporting System. A random sample of cases were manually screened for relevance and divided into training, testing, and validation data sets to develop a machine learning model. This model was used to automate screening of remaining potentially relevant cases. Results: Of the 4 algorithms tested, a naive Bayes kernel performed best, with an area under the receiver operating characteristic curve of 0.927 +/- 0.023, accuracy of 0.855 +/- 0.033, and F score of 0.877 +/- 0.027. Discussion: The machine learning model and text mining approach described here are useful tools for identifying and analyzing adverse event and near-miss reports. Although reporting systems are beginning to incorporate structured fields on health information technology and the EHR, these methods can identify related events that reporters classify in other ways. These methods can facilitate analysis of legacy safety reports by retrieving health information technology-related and EHRrelated events from databases without fields and controlled values focused on this subject and distinguishing them from reports in which the EHR is mentioned only in passing. Conclusions: Machine learning and text mining are useful additions to the patient safety toolkit and can be used to semiautomate screening and analysis of unstructured text in safety reports from frontline staff.","Authors":"Marella, WM (Marella, William M.) ; Sparnon, E (Sparnon, Erin); Finley, E (Finley, Edward)","Title":"Screening Electronic Health Record-Related Patient Safety Reports Using Machine Learning"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395842300015 ISSN: 0040-1625 eISSN: 1873-5509","Keywords":"Technical intelligence; Mergers and acquisitions; Patent analysis; Text mining KeyWords Plus:M-AND-A; EXTERNAL TECHNOLOGY ACQUISITION; SENSITIZED SOLAR-CELLS; INNOVATION PERFORMANCE; FIRM; MERGERS; DETERMINANTS; INTEGRATION; EXPERIENCE; PATHWAYS","Categories":"Business & Economics; Public Administration Web of Science Categories:Business; Planning & Development","Journal Information":"TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE Volume: 116 Pages: 162-180 DOI: 10.1016/j.techfore.2016.10.061 Published: MAR 2017","Abstract":"Technology strategy plays an increasingly important role in today's Mergers and Acquisitions (M&A) activities. Informing that strategy with empirical intelligence offers great potential value to R&D managers and technology policy makers. This paper proposes a methodology, based on patent analysis, to extract technical intelligence to identify M&A target technologies and evaluate relevant target companies to facilitate M&A target selection. We apply the term clumping process and a trend analysis together with policy and market information to profile present R&D status and capture future development signals and trends in order to grasp a range of significant domain-based technologies. Furthermore, a comparison between a selected acquirer and leading players is used to identify significant technologies and sub-technologies for specific strategy-oriented technology M&A activities. Finally, aiming to recommend appropriate M&A target companies, we set up an index-based system to evaluate the acquired target candidates from both firms-side perspective and target firm-side perspective and differentially weigh for specific M&A situations. We provide an empirical study in the field of computer numerical control machine tools (CNCMT) in China to identify technology M&A targets for an emerging Chinese CNCMT company - Estun Automation under different M&A strategies. (C) 2016 Elsevier Inc. All rights reserved.,","Authors":"Ma, TT (Ma, Tingting) ; Zhang, Y (Zhang, Yi) ; Huang, L (Huang, Lu) ; Shang, LN (Shang, Lining) ; Wang, KR (Wang, Kangrui) ; Yu, HZ (Yu, Huizhu) ; Zhu, DH (Zhu, Donghua)","Title":"Text mining to gain technical intelligence for acquired target selection: A case study for China's computer numerical control machine tools industry"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395842300018 ISSN: 0040-1625 eISSN: 1873-5509","Keywords":"Foresight; Text mining; Data analysis; Roadmapping; Scenario development; Big data KeyWords Plus:POLICY-MAKING; PATENT INFORMATION; TECHNOLOGY; INNOVATION; IDENTIFICATION; TRENDS; IMPACT; TRIZ","Categories":"Business & Economics; Public Administration Web of Science Categories:Business; Planning & Development","Journal Information":"TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE Volume: 116 Pages: 208-215 DOI: 10.1016/j.techfore.2016.10.017 Published: MAR 2017","Abstract":"While the volume of data from heterogeneous sources grows considerably, foresight and its methods rarely benefit from such available data. This work concentrates on textual data and considers its use in foresight to address new research questions and integrate other stakeholders. This textual data can be accessed and systematically examined through text mining which structures and aggregates data in a largely automated manner. By exploiting new data sources (e.g. Twitter, web mining), more actors and views are integrated, and more emphasis is laid on the analysis of social changes. The objective of this article is to explore the potential of text mining for foresight by considering different data sources, text mining approaches, and foresight methods. After clarifying the potential of combining text mining and foresight, examples are outlined for roadmapping and scenario development. As the results show, text mining facilitates the detection and examination of emerging topics and technologies by extending the knowledge base of foresight. Hence, new foresight applications can be designed. In particular, text mining provides a solid base for reflecting on possible futures. (C) 2016 Elsevier Inc. All rights reserved.","Authors":"Kayser, V (Kayser, Victoria) ; Blind, K (Blind, Knut)","Title":"Extending the knowledge base of foresight: The contribution of text mining"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397461000015 ISSN: 2211-9264","Keywords":"Cyanobacteria; Protein structure; Text mining; Methylotrophy; Bioremediation; C1 compounds; Database; Homology models KeyWords Plus:ALDEHYDES; PREDICTION; CONVERSION; OXYGENASE; FORMATE; BIOLOGY; METHANE; SYSTEMS","Categories":"Biotechnology & Applied Microbiology Web of Science Categories:Biotechnology & Applied Microbiology","Journal Information":"ALGAL RESEARCH-BIOMASS BIOFUELS AND BIOPRODUCTS Volume: 22 Pages: 135-139 DOI: 10.1016/j.algal.2016.12.005 Published: MAR 2017","Abstract":"Cyanobacteria are free-living photoautotrophic organisms that are able to degrade aliphatic and aromatic hydrocarbons in anoxic environments. Structural and biochemical information of a complete set of proteome for cyanobacterial C1 metabolism is not yet available in the public domain databases. Hence, we developed a database \"Cyanobacterial Protein Structure Information Resource for C1 metabolism(CPSIR-CM)\" with detailed structural and metabolic information of cyanobacterial proteins involved in C1 assimilation systems. A text mining approach was employed to identify the cyanobacterial proteins, which are responsible in mediating C1 metabolism. Standard computational prediction programs were used for accurately annotating the structural characteristics of proteins. This database structure was organized for 13 major metabolic pathways of C1 utilization systems. We incorporated structural information of 317 proteins showing significant modeling score and proper query coverage in our database. Home page of this database displays the lists of cyanobacterial C1 metabolism with a detailed summary. The first page describes the enzymes present in individual metabolism of different cyanobacterial genomes. Structural features, functional and metabolic information on each protein entry is available on the second page. A search engine on our database can access search forms as NCBI identifier and enzyme name. A user-friendly visualization tool is inbuilt to analyze three-dimensional structure of our homologymodels integrated in this database. This database record provides a support to decipher the structural and functional roles of cyanobacterial proteins in C1 metabolism. It also affords guidance for experimental setups to exploit the cyanobacteria in bioremediation applications. This resource can be accessible in online through the URL: http://www.pchellapandi.com/CPSIR/home.pl. (C) 2016 Elsevier B. V. All rights reserved.","Authors":"Chellapandi, P (Chellapandi, P.) ; Hussain, MMK (Hussain, M. Mohamed Khaja) ; Prathiviraj, R (Prathiviraj, R.)","Title":"CPSIR-CM: A database for structural properties of proteins identified in cyanobacterial C1 metabolism"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397351700013 ISSN: 1022-4653 eISSN: 2075-5597","Keywords":"Sparse controllable projection (SCP); Sparse singular value decomposition (SSVD); Sparse low rank matrix approximation (SLRMA) KeyWords Plus:CLIPPED ABSOLUTE DEVIATION; MATRIX DECOMPOSITION; ORACLE PROPERTIES; ADAPTIVE LASSO; SELECTION","Categories":"Engineering Web of Science Categories:Engineering, Electrical & Electronic","Journal Information":"CHINESE JOURNAL OF ELECTRONICS Volume: 26 Issue: 2 Pages: 306-312 DOI: 10.1049/cje.2017.01.025 Published: MAR 2017","Abstract":"Singular value decomposition (SVD) is a tool widely used in data denoising, matrix approximation, recommendation system, text mining and computer vision. A majority of applications prefer sparse singular vectors to capture inherent structures and patterns of the input data so that the results are interpretable. We present a novel penalty for SVD to achieve sparsity. Comparing with the traditional penalties, the proposed penalty is scale, dimensional insensitive and bounded between 0 and 1, which are in favor of controlling sparsity. Regulated by the penalty, we provide an efficient algorithm to project a vector onto a given sparse level in O(n) expected time. The efficient projection algorithm serve as a drudge for sparse SVD (SSVD). In experiments, SSVD is efficient and could capture the latent structures and patterns of the input data.","Authors":"Wang, CH (Wang Caihua) ; Liu, J (Liu Juan) ; Min, WW (Min Wenwen) ; Qu, AP (Qu Aiping)","Title":"A Novel Sparse Penalty for Singular Value Decomposition"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397590600001 ISSN: 1687-1499","Keywords":"Transfer learning; Short text mining; Latent semantic analysis KeyWords Plus:REGRESSION; ALGORITHM; THINGS","Categories":"Engineering; Telecommunications Web of Science Categories:Engineering, Electrical & Electronic; Telecommunications","Journal Information":"EURASIP JOURNAL ON WIRELESS COMMUNICATIONS AND NETWORKING Article Number: 42 DOI: 10.1186/s13638-017-0815-5 Published: MAR 1 2017","Abstract":"As a new emerging technique, transfer learning enjoys the advantage of integrating the well-learnt knowledge from another related work to facilitate an improved learning result of one task. Most of the existing transfer learning methods are designed for long texts and short texts. However, the latter one distinguishes from the former one in terms of its sparse nature, noise words, syntactical structure, and colloquial terminologies used. A transfer learning algorithm called automatic transfer learning (AutoTL) is proposed for short text mining. By transferring knowledge automatically learnt from theonline information, the proposed method enables training data to be selected automatically. Furthermore, it does not make any a priori assumption about probability distribution. Our experimental results on 20Newsgroups, Simulated Real Auto Aviation, and Reuter-21578 validate the higher performance of the proposed AutoTL over several state-of-of-the-art methods.","Authors":"Yang, L (Yang, Lei) ; Zhang, JP (Zhang, Jianpei)","Title":"Automatic transfer learning for short text mining"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395112600003 ISSN: 0963-1690 eISSN: 1467-8691","Categories":"Business & Economics Web of Science Categories:Management","Journal Information":"CREATIVITY AND INNOVATION MANAGEMENT Volume: 26 Issue: 1 Pages: 17-30 DOI: 10.1111/caim.12202 Published: MAR 2017","Abstract":"Online communities are attractive sources of ideas relevant for new product development and innovation. However, making sense of the big data' in these communities is a complex analytical task. A systematic way of dealing with these data is needed to exploit their potential for boosting companies' innovation performance. We propose a method for analysing online community data with a special focus on identifying ideas. We employ a research design where two human raters classified 3,000 texts extracted from an online community, according to whether the text contained an idea. Among the 3,000, 137 idea texts and 2,666 non-idea texts were identified. The human raters could not agree on the remaining 197 texts. These texts were omitted from the analysis. The remaining 2,803 texts were processed by using text mining techniques and used to train a classification model. We describe how to tune the model and which text mining steps to perform. We conclude that machine learning and text mining can be useful for detecting ideas in online communities. The method can help researchers and firms identify ideas hidden in large amounts of texts. Also, it is interesting in its own right that machine learning can be used to detect ideas.","Authors":"Christensen, K (Christensen, Kasper) ; Norskov, S (Norskov, Sladjana) ; Frederiksen, L (Frederiksen, Lars) ; Scholderer, J (Scholderer, Joachim)","Title":"In Search of New Product Ideas: Identifying Ideas in Online Communities by Machine Learning and Text Mining"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395663700004 PubMed ID: 28118920 ISSN: 1386-5056 eISSN: 1872-8243","Categories":"Computer Science; Health Care Sciences & Services; Medical Informatics Web of Science Categories:Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics","Journal Information":"INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS Volume: 99 Pages: 37-44 DOI: 10.1016/j.ijmedinf.2016.12.007 Published: MAR 2017","Abstract":"Background: Worldwide, patients have posted millions of online reviews for their doctors. The rich textual information in the online reviews holds the potential to generate insights into how patients' experience with their doctors differ across nations and how should we use them to improve our health service. Objective: We apply customized text mining techniques to compare online doctor reviews from China and the United States, in order to measure the systematic differences in patient reviews between the two countries, and assess the potential insights that can be derived from this large volume of online text data. Methods: We compare the textual reviews of obstetrics and gynecology (OBGYN) doctors from the two most popular online doctor rating websites in the U.S. and China, respectively: RateMDs.com and Haodf.com. We apply a customized text mining technique, Latent Dirichlet Allocation (LDA) topic modeling to identify the major topics in positive and negative reviews of those two countries. We then compare their similarities and differences. Results: Among the positive reviews, both Chinese and American patients talked about medical treatment, bedside manner, and appreciation/recommendation, but Chinese patients commented more about medical treatment while American patients focused more on recommendation. Also, reviews about bedside manner from Chinese patients were more related to doctors while on the American side, they were more about staff. This reflects the difference between the two countries' health systems. Further, among the negative reviews, both countries' patients talked about medical treatment, bedside manner, and logistics. However, Chinese patients focus more on the registration process, while American patients are more related to the staff, wait time, and insurance, which further shows the differences between the two nations' health systems. Conclusions: Online doctor reviews contain valuable information that can generate insights on the similarities and differences of patient experience across nations. They are useful assets to assist healthcare consumers, providers, and administrators in moving toward a patient-centered care. In this age of big data, online doctor reviews can be a valuable source for international perspectives on healthcare systems.","Authors":"Hao, HJ (Hao, Haijing) ; Zhang, KP (Zhang, Kunpeng) ; Wang, WG (Wang, Weiguang) ; Gao, G (Gao, Gordon)","Title":"A tale of two countries: International comparison of online doctor reviews between China and the United States"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394959700002 PubMed ID: 26358713 ISSN: 1073-1911 eISSN: 1552-3489","Keywords":"posttraumatic stress disorder; text mining; self-narratives; natural language processing; screening; assessment KeyWords Plus:WRITTEN EMOTIONAL EXPRESSION; ROC CURVE; PTSD; SCALE; AREA; CLASSIFICATION; SYMPTOMS; INTERNET; TRAUMA; HEALTH","Categories":"Psychology Web of Science Categories:Psychology, Clinical","Journal Information":"ASSESSMENT Volume: 24 Issue: 2 Pages: 157-172 DOI: 10.1177/1073191115602551 Published: MAR 2017","Abstract":"Patients' narratives about traumatic experiences and symptoms are useful in clinical screening and diagnostic procedures. In this study, we presented an automated assessment system to screen patients for posttraumatic stress disorder via a natural language processing and text-mining approach. Four machine-learning algorithms-including decision tree, naive Bayes, support vector machine, and an alternative classification approach called the product score model-were used in combination with n-gram representation models to identify patterns between verbal features in self-narratives and psychiatric diagnoses. With our sample, the product score model with unigrams attained the highest prediction accuracy when compared with practitioners' diagnoses. The addition of multigrams contributed most to balancing the metrics of sensitivity and specificity. This article also demonstrates that text mining is a promising approach for analyzing patients' self-expression behavior, thus helping clinicians identify potential patients from an early stage.","Authors":"He, QW (He, Qiwei) ; Veldkamp, BP (Veldkamp, Bernard P.) ; Glas, CAW (Glas, Cees A. W.) ; de Vries, T (de Vries, Theo)","Title":"Automated Assessment of Patients' Self-Narratives for Posttraumatic Stress Disorder Screening Using Natural Language Processing and Text Mining"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395225000004 ISSN: 0167-4048 eISSN: 1872-6208","Keywords":"Identity theft; Text mining; News stories; PII attributes; Named entity recognition KeyWords Plus:ROUTINE ACTIVITY THEORY; CRIME","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"COMPUTERS & SECURITY Volume: 65 Pages: 50-63 DOI: 10.1016/j.cose.2016.11.002 Published: MAR 2017","Abstract":"Identity theft, fraud, and abuse are problems affecting the entire society. Identity theft is often a \"gateway\" crime, as criminals use stolen or fraudulent identities to steal money, claim eligibility for services, hack into networks without authorization, and so on. The available data describing identity crimes and their aftermath are often in the form of recorded stories and reports by the news press, fraud examiners, and law enforcement. All of these sources are unstructured. In order to analyze identity theft data, this research proposes an approach which involves the novel collection of online news stories and reports on the topic of identity theft. Our approach pre-processes the raw text and extracts semi-structured information automatically, using text mining techniques. This paper presents statistical analysis of behavioral patterns and resources used by thieves and fraudsters to commit identity theft, including the identity attributes commonly linked to identity crimes, resources thieves employ to conduct identity crimes, and temporal patterns of criminal behavior. Furthermore, the automatically extracted information is validated against manually investigated news stories. Analyses of these results increase empirical understanding of identity threat behaviors, offer early warning signs of identity theft, and thwart future identity theft crimes. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Zaeem, RN (Zaeem, Razieh Nokhbeh) ; Manoharan, M (Manoharan, Monisha) ; Yang, YP (Yang, Yongpeng) ; Barber, KS (Barber, K. Suzanne)","Title":"Modeling and analysis of identity threat behaviors through text mining of identity theft stories"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394974900010 PubMed ID: 26597192 ISSN: 0163-2116 eISSN: 1573-2568","Keywords":"Hepatotoxicity; Drug-induced liver injury; Data mining; Electronic medical record KeyWords Plus:CAUSALITY ASSESSMENT METHOD; GENERAL-POPULATION; CLINICAL-FEATURES; NETWORK DILIN; RELIABILITY; DIAGNOSIS; OUTCOMES; EVENTS","Categories":"Gastroenterology & Hepatology Web of Science Categories:Gastroenterology & Hepatology","Journal Information":"DIGESTIVE DISEASES AND SCIENCES Volume: 62 Issue: 3 Pages: 615-625 DOI: 10.1007/s10620-015-3970-8 Published: MAR 2017","Abstract":"Idiosyncratic drug-induced liver injury (DILI) is an uncommon but important cause of liver disease that is challenging to diagnose and identify in the electronic medical record (EMR). To develop an accurate, reliable, and efficient method of identifying patients with bonafide DILI in an EMR system. In total, 527,000 outpatient and ER encounters in an EPIC-based EMR were searched for potential DILI cases attributed to eight drugs. A searching algorithm that extracted 200 characters of text around 14 liver injury terms in the EMR were extracted and collated. Physician investigators reviewed the data outputs and used standardized causality assessment methods to adjudicate the potential DILI cases. A total of 101 DILI cases were identified from the 2564 potential DILI cases that included 62 probable DILI cases, 25 possible DILI cases, nine historical DILI cases, and five allergy-only cases. Elimination of the term \"liver disease\" from the search strategy improved the search recall from 4 to 19 %, while inclusion of the four highest yield liver injury terms further improved the positive predictive value to 64 % but reduced the overall case detection rate by 47 %. RUCAM scores of the 57 probable DILI cases were generally high and concordant with expert opinion causality assessment scores. A novel text searching tool was developed that identified a large number of DILI cases from a widely used EMR system. A computerized extraction of dictated text followed by the manual review of text snippets can rapidly identify bona fide cases of idiosyncratic DILI.","Authors":"Heidemann, L (Heidemann, Lauren) ; Law, J (Law, James) ; Fontana, RJ (Fontana, Robert J.)","Title":"A Text Searching Tool to Identify Patients with Idiosyncratic Drug-Induced Liver Injury"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394633500019 ISSN: 2161-9549 eISSN: 2161-9565","Keywords":"conceptual models; evidence; environmental assessment; evidence synthesis; literature-based; mountaintop; removal mining. KeyWords Plus:KNOWLEDGE MAPS; ECOLOGICAL RISK; USA; DISPLAYS; TEXT; OHIO","Categories":"Environmental Sciences & Ecology; Marine & Freshwater Biology Web of Science Categories:Ecology; Marine & Freshwater Biology","Journal Information":"FRESHWATER SCIENCE Volume: 36 Issue: 1 Pages: 231-239 DOI: 10.1086/690296 Published: MAR 2017","Abstract":"Sound environmental management relies on scientific evidence to indicate whether action is warranted and, if so, which actions will be most effective. We discuss conceptual model diagrams that schematically describe how sources or human activities lead to specific stressors and ultimately to biotic effects. They are useful for describing how undesirable effects are produced and identifying where management actions may be most effective in preventing unwanted effects or improving existing conditions. We illustrate the use of conceptual model diagrams in a literature -based assessment of the impacts of mountaintop removal mining on downstream aquatic systems. The diagram-development process combined extraction and evaluation of research results with iterative refinement of diagrams depicting source-to-stressor-to-effect causal pathways. Conceptual -model diagrams provided a useful scaffold for organizing and synthesizing multiple individual pieces of evidence extracted from different studies and an effective way to summarize and present the evidentiary foundation of the assessment's conclusions. Key words: conceptual models, evidence, environmental assessment, evidence synthesis, literature -based, mountaintop removal mining.","Authors":"Norton, SB (Norton, Susan B.) ; Schofield, KA (Schofield, Kate A.)","Title":"Conceptual model diagrams as evidence scaffolds for environmental assessment and management"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395359500012 ISSN: 0164-1212 eISSN: 1873-1228","Keywords":"Invalid defect; Classification; Text mining; Server development; Project management; BIOS KeyWords Plus:PATTERNS; SOFTWARE; RISK","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering; Computer Science, Theory & Methods","Journal Information":"JOURNAL OF SYSTEMS AND SOFTWARE Volume: 125 Pages: 197-206 DOI: 10.1016/j.jss.2016.12.005 Published: MAR 2017","Abstract":"Invalid defects, which are often overlooked, reduce development productivity and efficiency. This study used exploratory study and text mining to answer three research questions related to invalid defects in two research stages. In the first stage, we filtered 231 invalid BIOS (basic input/output system) defects from the 3347 defects of three server projects. These defects were from numerous function areas owned by virtual teams located in Taiwan, China, and the United States. Results indicated that BIOS firmware demonstrates the maximum number of defects and invalid defects. This firmware accounted for 43.3% defects and 33% invalid defects in server development. Results determined that invalid defect classification that includes four types, namely, working as designed (WAD), user error, duplicate, and others. All of these types can be grouped under the term WUDO. WAD accounts for the maximum of 45% of invalid defects in the WUDO classification. In the second stage, this study determined a stable classification algorithm, namely, decision tree C4.5, to classify the invalid defect types. This study helps project teams for information technology products to classify the different invalid defect types that developers and testers face. Results can improve project team productivity and mitigate project risks in project management. (C) 2016 Elsevier Inc. All rights reserved.","Authors":"Su, Y (Su, Yihsiung) ; Luarn, P (Luarn, Pin) ; Lee, YS (Lee, Yue-Shi) ; Yen, SJ (Yen, Show-Jane)","Title":"Creating an invalid defect classification model using text mining on server development"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395496100001 ISSN: 1067-6341 eISSN: 1086-3184","Categories":"History; Religion Web of Science Categories:History; Religion","Journal Information":"JOURNAL OF EARLY CHRISTIAN STUDIES Volume: 25 Issue: 1 Pages: 1-28 Published: SPR 2017","Abstract":"Even though Salvian of Marseilles wrote in the relative security of Southern Gaul, his treatise On the Governance of God, composed between 440 and 450 C.E., reverberates with the shock-waves caused by Gaiseric's capture of Carthage and the devastation of the Western Roman Empire during the preceding decades. Salvian's treatise is a sustained criticism of the way in which the Christian Roman elites had failed and thus brought on God's immediate judgement themselves. As such, the text has been mined by social historians for information of the state of the later Roman Empire, but it has rarely been analyzed for its own sake. Reading On the Governance of God and its narrative of the progress of the barbarian invaders under the perspective of travel writing, it becomes evident that Salvian considers Carthage the true heart (anima) of the (Catholic) Christian Roman Empire, now captured by the Vandals, the new Romans, as the just successors of a failed Rome, even though that Rome remains the caput and could be saved if all were to heed Salvian's admonitions to embrace a true (Catholic) Christian life.","Authors":"Elm, S (Elm, Susanna)","Title":"2016 NAPS Presidential Address New Romans: Salvian of Marseilles On the Governance of God"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000394360400002 ISSN: 1389-5753 eISSN: 1572-9362","Keywords":"Online review; Recommendation systems; Collaborative filtering; User preference; Opinion mining KeyWords Plus:SYSTEMS","Categories":"Business & Economics Web of Science Categories:Business; Management","Journal Information":"ELECTRONIC COMMERCE RESEARCH Volume: 17 Issue: 1 Pages: 3-29 Special Issue: SI DOI: 10.1007/s10660-016-9240-9 Published: MAR 2017","Abstract":"Along with the growth of Internet and electronic commerce, online consumer reviews have become a prevalent and rich source of information for both consumers and merchants. Numerous reviews record massive consumers' opinions on products or services, which offer valuable information about users' preferences for various aspects of different entities. This paper proposes a novel approach to finding the user preferences from free-text online reviews, where a user-preference-based collaborative filtering approach, namely UPCF, is developed to discover important aspects to users, as well as to reflect users' individual needs for different aspects for recommendation. Extensive experiments are conducted on the data from a real-world online review platform, with the results showing that the proposed approach outperforms other approaches in effectively predicting the overall ratings of entities to target users for personalized recommendations. It also demonstrates that the approach has an advantage in dealing with sparse data, and can provide the recommendation results with desirable understandability.","Authors":"Ma, Y (Ma, Yue) ; Chen, GQ (Chen, Guoqing) ; Wei, Q (Wei, Qiang)","Title":"Finding users preferences from large-scale online reviews for personalized recommendation"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394360400004 ISSN: 1389-5753 eISSN: 1572-9362","Keywords":"Social spam; Spam detection; Topic modeling; Incremental learning; Machine learning; Big data KeyWords Plus:DIRICHLET ALLOCATION; TEXT CATEGORIZATION; CLASSIFICATION; ALGORITHMS; SELECTION; MODEL","Categories":"Business & Economics Web of Science Categories:Business; Management","Journal Information":"ELECTRONIC COMMERCE RESEARCH Volume: 17 Issue: 1 Pages: 51-81 Special Issue: SI DOI: 10.1007/s10660-016-9244-5 Published: MAR 2017","Abstract":"With the rise of social web, there has also been a great concern about the quality of user-generated content on social media sites (SMSs). Deceptive comments harm users' trust in online social media and cause financial loss to firms. Previous studies use various features and classification algorithms to detect and filter social spam on several social media platforms. However, to the best of our knowledge, previous studies have not exploited both probabilistic topic modeling and incremental learning to detect social spam on SMSs. Thus, the main contribution of this paper is design of a novel detection methodology that combines topic- and user-based features to improve the effectiveness of social spam detection. The proposed methodology exploits a probabilistic generative model, namely the labeled latent Dirichlet allocation (L-LDA), for mining the latent semantics from user-generated comments, and an incremental learning approach for tackling the changing feature space. An experiment based on a large dataset extracted from YouTube demonstrates the effectiveness of our proposed methodology, which achieves an average accuracy of 91.17 % in social spam detection. Our statistical analysis reveals that topic-based features significantly improve social spam detection, which has significant implications for business practice.","Authors":"Song, L (Song, Long) ; Lau, RYK (Lau, Raymond Yiu Keung) ; Kwok, RCW (Kwok, Ron Chi-Wai) ; Mirkovski, K (Mirkovski, Kristijan) ; Dou, WY (Dou, Wenyu)","Title":"Who are the spoilers in social media marketing? Incremental learning of latent semantics for social spam detection"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394341300007 ISSN: 1384-5810 eISSN: 1573-756X","Keywords":"Decision boundaries; Naive Bayes; Feature weighting; High-dimensional massive data; Class dispersion KeyWords Plus:TEXT CATEGORIZATION; RANDOM FORESTS; ASSUMPTION; LIKELIHOOD","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"DATA MINING AND KNOWLEDGE DISCOVERY Volume: 31 Issue: 2 Pages: 465-501 DOI: 10.1007/s10618-016-0481-y Published: MAR 2017","Abstract":"The presence of complex distributions of samples concealed in high-dimensional, massive sample-size data challenges all of the current classification methods for data mining. Samples within a class usually do not uniformly fill a certain (sub)space but are individually concentrated in certain regions of diverse feature subspaces, revealing the class dispersion. Current classifiers applied to such complex data inherently suffer from either high complexity or weak classification ability, due to the imbalance between flexibility and generalization ability of the discriminant functions used by these classifiers. To address this concern, we propose a novel representation of discriminant functions in Bayesian inference, which allows multiple Bayesian decision boundaries per class, each in its individual subspace. For this purpose, we design a learning algorithm that incorporates the naive Bayes and feature weighting approaches into structural risk minimization to learn multiple Bayesian discriminant functions for each class, thus combining the simplicity and effectiveness of naive Bayes and the benefits of feature weighting in handling high-dimensional data. The proposed learning scheme affords a recursive algorithm for exploring class density distribution for Bayesian estimation, and an automated approach for selecting powerful discriminant functions while keeping the complexity of the classifier low. Experimental results on real-world data characterized by millions of samples and features demonstrate the promising performance of our approach.","Authors":"Zhang, JF (Zhang, Jianfei) ; Wang, SR (Wang, Shengrui) ; Chen, LF (Chen, Lifei) ; Gallinari, P (Gallinari, Patrick)","Title":"Multiple Bayesian discriminant functions for high-dimensional massive data classification"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394341300008 ISSN: 1384-5810 eISSN: 1573-756X","Keywords":"Information needs; User modeling; Clustering; Web browsing KeyWords Plus:SEARCH; PERSONALIZATION; CLASSIFICATION; DESIGN","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"DATA MINING AND KNOWLEDGE DISCOVERY Volume: 31 Issue: 2 Pages: 502-547 DOI: 10.1007/s10618-016-0482-x Published: MAR 2017","Abstract":"Browsing sessions are rich in elements useful to build profiles of user interests, but at the same time HTML pages include noisy data such as advertisements, navigation menus and privacy notes. Moreover, some pages cover several different topics making it difficult to identify the most relevant to the user. For these reasons, they are often ignored by personalized search and recommender systems. We propose a novel approach for recognizing valuable text descriptions of current user information needs-namely cues-based on the data mined from browsing interactions over the web. The approach combines page clustering techniques based on Document Object Model-based representations for acquiring evidence about relevant correlations between text contents. This evidence is exploited for better filtering out irrelevant information and facilitating the construction of interest profiles. A comparative framework proves the accuracy of the extracted cues in the personalize search task, where results are re-ranked according to the last browsed resources.","Authors":"Gasparetti, F (Gasparetti, Fabio)","Title":"Modeling user interests from web browsing activities"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395563900003 ISSN: 1041-4347 eISSN: 1558-2191","Keywords":"Short text understanding; text segmentation; type detection; concept labeling; semantic knowledge","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING Volume: 29 Issue: 3 Pages: 499-512 DOI: 10.1109/TKDE.2016.2571687 Published: MAR 1 2017","Abstract":"Understanding short texts is crucial to many applications, but challenges abound. First, short texts do not always observe the syntax of a written language. As a result, traditional natural language processing tools, ranging from part-of-speech tagging to dependency parsing, cannot be easily applied. Second, short texts usually do not contain sufficient statistical signals to support many state-of-the-art approaches for text mining such as topic modeling. Third, short texts are more ambiguous and noisy, and are generated in an enormous volume, which further increases the difficulty to handle them. We argue that semantic knowledge is required in order to better understand short texts. In this work, we build a prototype system for short text understanding which exploits semantic knowledge provided by a well-known knowledge ase and automatically harvested from a web corpus. Our knowledge-intensive approaches disrupt traditional methods for tasks such as text segmentation, part-of-speech tagging, and concept labeling, in the sense that we focus on semantics in all these tasks. We conduct a comprehensive performance evaluation on real-life data. The results show that semantic knowledge is indispensable for short text understanding, and our knowledge-intensive approaches are both effective and efficient in discovering semantics of short texts.","Authors":"Hua, W (Hua, Wen) ; Wang, ZY (Wang, Zhongyuan) ; Wang, HX (Wang, Haixun) ; Zheng, K (Zheng, Kai) ; Zhou, XF (Zhou, Xiaofang)","Title":"Understand Short Texts by Harvesting and Analyzing Semantic Knowledge"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396085600003 ISSN: 0018-9529 eISSN: 1558-1721","Keywords":"Computer security; machine learning; software metrics; text mining KeyWords Plus:VALIDATION","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Engineering, Electrical & Electronic","Journal Information":"IEEE TRANSACTIONS ON RELIABILITY Volume: 66 Issue: 1 Pages: 17-37 DOI: 10.1109/TR.2016.2630503 Published: MAR 2017","Abstract":"Statistical prediction models can be an effective technique to identify vulnerable components in large software projects. Two aspects of vulnerability prediction models have a profound impact on their performance: 1) the features (i.e., the characteristics of the software) that are used as predictors and 2) the way those features are used in the setup of the statistical learning machinery. In a previous work, we compared models based on two different types of features: software metrics and term frequencies (text mining features). In this paper, we broaden the set of models we compare by investigating an array of techniques for the manipulation of said features. These techniques fall under the umbrella of dimensionality reduction and have the potential to improve the ability of a prediction model to localize vulnerabilities. We explore the role of dimensionality reduction through a series of cross-validation and cross-project prediction experiments. Our results show that in the case of software metrics, a dimensionality reduction technique based on confirmatory factor analysis provided an advantage when performing cross-project prediction, yielding the best F-measure for the predictions in five out of six cases. In the case of text mining, feature selection can make the prediction computationally faster, but no dimensionality reduction technique provided any other notable advantage.","Authors":"Stuckman, J (Stuckman, Jeffrey) ; Walden, J (Walden, James) ; Scandariato, R (Scandariato, Riccardo)","Title":"The Effect of Dimensionality Reduction on Software Vulnerability Prediction Models"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394339500005 ISSN: 0138-9130 eISSN: 1588-2861","Keywords":"Agroenergy; Scientific dimensions; Full text analysis; Public policies; Science management; Science Planning","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Interdisciplinary Applications; Information Science & Library Science","Journal Information":"SCIENTOMETRICS Volume: 110 Issue: 3 Pages: 1173-1189 DOI: 10.1007/s11192-016-2233-6 Published: MAR 2017","Abstract":"The disciplinary structure of research on complex problems related to human activities is supported by the fundaments of the social, life, and hard sciences. In this work, we looked at the development of scientific research in the field of biofuels, as a sustainable source of energy, searching for references regarding its scientific roots and social relevance. Scientific communications on biofuels published between 1998 and 2007 were analyzed using a combination of bibliometric methods and text mining techniques. This field of research was characterized as interdisciplinary, with marked social relevance. Our bibliometric analysis shows that, in this research subject, 132 different, interacting fields of knowledge overlap, with dominance of Chemistry, Engineering and Agricultural Sciences. Through the use of text mining techniques, this field was configured into three groups of Disciplinary Dimensions. The first and most influential group includes the Agricultural Sciences, Social Sciences, and Environmental Sciences. The second group, which gives the field its technological basis, includes Chemistry, Engineering, and Microbiology. The third group includes disciplines with emerging involvement in the field of biofuels: Biology and Biochemistry, Animal and Plant Sciences, Molecular Biology and Genetics, Economics, Material Sciences, Nanosciences and Nanotechnology, Geosciences, Physics, Humanities, Multidisciplinary Sciences, Mathematics, and Computer Sciences. This study suggests that the first group of Disciplinary Dimensions conforms to the elements that socially validate the progress of research in the field of biofuels. This study also proposes a metric that can be used to measure the interdisciplinarity and the social framing of any other research field.","Authors":"Gomes, J (Gomes, Janaina) ; Dewes, H (Dewes, Homero)","Title":"Disciplinary dimensions and social relevance in the scientific communications on biofuels"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393662500004 ISSN: 0219-1377 eISSN: 0219-3116","Keywords":"Variational inference; Bayesian nonparametrics; Classification; Von Mises-Fisher distribution KeyWords Plus:DIRICHLET PROCESS MIXTURES; SAMPLING METHODS; PRIORS","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"KNOWLEDGE AND INFORMATION SYSTEMS Volume: 50 Issue: 3 Pages: 763-793 DOI: 10.1007/s10115-016-0956-6 Published: MAR 2017","Abstract":"As the number of documents has been rapidly increasing in recent time, automatic text categorization is becoming a more important and fundamental task in information retrieval and text mining. Accuracy and interpretability are two important aspects of a text classifier. While the accuracy of a classifier measures the ability to correctly classify unseen data, interpretability is the ability of the classifier to be understood by humans and provide reasons why each data instance is assigned to a label. This paper proposes an interpretable classification method by exploiting the Dirichlet process mixture model of von Mises-Fisher distributions for directional data. By using the labeled information of the training data explicitly and determining automatically the number of topics for each class, the learned topics are coherent, relevant and discriminative. They help interpret as well as distinguish classes. Our experimental results showed the advantages of our approach in terms of separability, interpretability and effectiveness in classification task of datasets with high dimension and complex distribution. Our method is highly competitive with state-of-the-art approaches.","Authors":"Linh, NV (Ngo Van Linh) ; Anh, NK (Nguyen Kim Anh) ; Than, K (Khoat Than) ; Dang, CN (Chien Nguyen Dang)","Title":"An effective and interpretable method for document classification"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393244100016 PubMed ID: 27913255 ISSN: 0166-4328 eISSN: 1872-7549","Keywords":"Mouth diseases; Mental disorders; Text mining; Gene expression profiling KeyWords Plus:CELL-ADHESION MOLECULE; LITERATURE-BASED DISCOVERY; NERVOUS-SYSTEM; DISEASE; ANXIETY; NCAM; CONNECTIONS; PLASTICITY; KNOWLEDGE; DISORDER","Categories":"Behavioral Sciences; Neurosciences & Neurology Web of Science Categories:Behavioral Sciences; Neurosciences","Journal Information":"BEHAVIOURAL BRAIN RESEARCH Volume: 320 Pages: 136-142 DOI: 10.1016/j.bbr.2016.11.047 Published: MAR 1 2017","Abstract":"Exacerbations of oral lichen planus (OLP) have been linked to the periods of psychological stress, anxiety and depression. The specific mechanism of the interaction is unclear. The aim of this study was to explore the candidate genes or molecules that play important roles in the interaction between OLP and depression. The BITOLA system was used to search all intermediate concepts relevant to the \"Gene or Gene Product\" for OLP and depression, and the gene expression data and tissue-specific gene data along with manual checking were then employed to filter the intermediate concepts. Finally, two genes (NCAM1, neural cell adhesion molecule 1; CD4, CD4 molecule) passed the follow-up inspection. By using the text mining can formulate a new hypothesis: NCAM1 and CD4 were identified as involved or potentially involved in the interaction between OLP and depression. These results offer a new clue for the experimenters and hold promise for developing innovative therapeutic strategies for these two diseases. (c) 2016 Elsevier B.V. All rights reserved.","Authors":"Zhan, YB (Zhan, Yuanbo) ; Zhou, S (Zhou, Shuang) ; Li, Y (Li, Ying) ; Mu, S (Mu, Sen) ; Zhang, RJ (Zhang, Ruijie) ; Song, XJ (Song, Xuejing) ; Lin, F (Lin, Feng) ; Zhang, RM (Zhang, Ruimin) ; Zhang, B (Zhang, Bin)","Title":"Using the BITOLA system to identify candidate molecules in the interaction between oral lichen planus and depression"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393241500001 ISSN: 0306-4573 eISSN: 1873-5371","Keywords":"Information extraction; Sampling; Deep web; Text mining; Scalability KeyWords Plus:TEXT DATABASES; HIDDEN-WEB; SYSTEM","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"INFORMATION PROCESSING & MANAGEMENT Volume: 53 Issue: 2 Pages: 309-331 DOI: 10.1016/j.ipm.2016.11.006 Published: MAR 2017","Abstract":"Information extraction systems discover structured information in natural language text. Having information in structured form enables much richer querying and data mining than possible over the natural language text. However, information extraction is a computationally expensive task, and hence improving the efficiency of the extraction process over large text collections is of critical interest. In this paper, we focus on an especially valuable family of text collections, namely, the so-called deep-web text collections, whose contents are not crawlable and are only available via querying. Important steps for efficient information extraction over deep-web text collections (e.g., selecting the collections on which to focus the extraction effort, based on their contents; or learning which documents within these collections and in which order to process, based on their words and phrases) require having a representative document sample from each collection. These document samples have to be collected by querying the deep-web text collections, an expensive process that renders impractical the existing sampling approaches developed for other data scenarios. In this paper, we systematically study the space of query-based document sampling techniques for information extraction over the deep web. Specifically, we consider (i) alternative query execution schedules, which vary on how they account for the query effectiveness, and (ii) alternative document retrieval and processing schedules, which vary on how they distribute the extraction effort over documents. We report the results of the first large-scale experimental evaluation of sampling techniques for information extraction over the deep web. Our results show the merits and limitations of the alternative query execution and document retrieval and processing strategies, and provide a roadmap for addressing this critically important building block for efficient, scalable information extraction. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Barrio, P (Barrio, Pablo) ; Gravano, L (Gravano, Luis) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Barrio, Pablo  http://orcid.org/0000-0002-4410-0682","Title":"Sampling strategies for information extraction over the deep web"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000393241500008 ISSN: 0306-4573 eISSN: 1873-5371","Keywords":"Online hotel review; Multi-text summarization; Sentiment analysis; Sentence clustering; k-medoids KeyWords Plus:WORD-OF-MOUTH; USER-GENERATED CONTENT; INFORMATION SEARCH; SERVICES; HOSPITALITY; BEHAVIOR; SYSTEMS; IMPACT","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"INFORMATION PROCESSING & MANAGEMENT Volume: 53 Issue: 2 Pages: 436-449 DOI: 10.1016/j.ipm.2016.12.002 Published: MAR 2017","Abstract":"Online travel forums and social networks have become the most popular platform for sharing travel information, with enormous numbers of reviews posted daily. Automatically generated hotel summaries could aid travelers in selecting hotels. This study proposes a novel multi-text summarization technique for identifying the top-k most informative sentences of hotel reviews. Previous studies on review summarization have primarily examined content analysis, which disregards critical factors like author credibility and conflicting opinions. We considered such factors and developed a new sentence importance metric. Both the content and sentiment similarities were used to determine the similarity of two sentences. To identify the top-k sentences, the k-medoids clustering algorithm was used to partition sentences into k groups. The medoids from these groups were then selected as the final summarization results. To evaluate the performance of the proposed method, we collected two sets of reviews for the two hotels posted on TripAdvisor.com. A total of 20 subjects were invited to review the text summarization results from the proposed approach and two conventional approaches for the two hotels. The results indicate that the proposed approach outperforms the other two, and most of the subjects believed that the proposed approach can provide more comprehensive hotel information. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Hu, YH (Hu, Ya-Han) ; Chen, YL (Chen, Yen-Liang) ; Chou, HL (Chou, Hui-Ling)","Title":"Opinion mining from online hotel reviews - A text summarization approach"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000391900000022 ISSN: 0306-4379 eISSN: 1873-6076","Keywords":"Smog disaster; Health hazard; Social media; Urban data; Forecasting; Data mining KeyWords Plus:NEURAL-NETWORKS; AIR-POLLUTION; CHINA","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION SYSTEMS Volume: 64 Pages: 281-291 DOI: 10.1016/j.is.2016.03.011 Published: MAR 2017","Abstract":"Smog disasters are becoming more and more frequent and may cause severe consequences on the environment and public health, especially in urban areas. Social media as a real-time urban data source has become an increasingly effective channel to observe people's reactions on smog-related health hazard. It can be used to capture possible smog related public health disasters in its early stage. We then propose a predictive analytic approach that utilizes both social media and physical sensor data to forecast the next day smog-related health hazard. First, we model smog-related health hazards and smog severity through mining raw microblogging text and network information diffusion data. Second, we developed an artificial neural network (ANN)-based model to forecast smog related health hazard with the current health hazard and smog severity observations. We evaluate the performance of the approach with other alternative machine learning methods. To the best of our knowledge, we are the first to integrate social media and physical sensor data for smog-related health hazard forecasting. The empirical findings can help researchers to better understand the non-linear relationships between the current smog observations and the next day health hazard. In addition, this forecasting approach can provide decision support for smog-related health hazard management through functions like early warning. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Chen, JY (Chen, Jiaoyan) ; Chen, HJ (Chen, Huajun) ; Wu, ZH (Wu, Zhaohui) ; Hu, DN (Hu, Daning) ; Pan, JZ (Pan, Jeff Z.)","Title":"Forecasting smog-related health hazard based on social media and physical sensor"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000389111000005 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Outlier pair detection; Complex network; Link structure; Semantic relationship; K-step index KeyWords Plus:ANOMALY DETECTION","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 69 Pages: 40-49 DOI: 10.1016/j.eswa.2016.10.026 Published: MAR 1 2017","Abstract":"In this paper, we propose an outlier pair detection method, called LSOutPair, which discovers the vast differences between link structure and semantic relationship. LSOutPair addresses three important challenges: (1) how can we measure the target object's link similarity among multi-typed objects and multi-typed relations? (2) how can we measure the semantic similarity using the short texts? (3) how can we find the objects' maximum differences between link structure and semantic relationship? To tackle these challenges, LSOutPair applies three main techniques: (1) two matrices are used to store link similarity and semantic similarity, (2) a k-step index algorithm, which calculates the term weighting for each object, (3) applying the linear transformation of Frobenius norm to matrices can obtain the top-K outlier pairs. LSOutPair considers link and semantics in complex network simultaneously, which is a new attempt in data mining. Substantial experiments show that LSOutPair is very effective for outlier pair detection. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Liu, L (Liu, L.) ; Zuo, WL (Zuo, W. L.) ; Peng, T (Peng, T.)","Title":"Detecting outlier pairs in complex network based on link structure and semantic relationship"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000389111000019 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Multilingual sentiment analysis; Text analysis; Machine learning; Vector representation; Hybrid vectorization; Online user reviews KeyWords Plus:LEXICON; TWITTER","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 69 Pages: 214-224 DOI: 10.1016/j.eswa.2016.10.043 Published: MAR 1 2017","Abstract":"Sentiment analysis and opinion mining are valuable for extraction of useful subjective information out of text documents. These tasks have become of great importance, especially for business and marketing professionals, since online posted products and services reviews impact markets and consumers shifts. This work is motivated by the fact that automating retrieval and detection of sentiments expressed for certain products and services embeds complex processes and pose research challenges, due to the textual phenomena and the language specific expression variations. This paper proposes a fast, flexible, generic methodology for sentiment detection out of textual snippets which express people's opinions in different languages. The proposed methodology adopts a machine learning approach with which textual documents are represented by vectors and are used for training a polarity classification model. Several documents' vector representation approaches have been studied, including lexicon-based, word embedding based and hybrid vectorizations. The competence of these feature representations for the sentiment classification task is assessed through experiments on four datasets containing online user reviews in both Greek and English languages, in order to represent high and weak inflection language groups. The proposed methodology requires minimal computational resources, thus, it might have impact in real world scenarios where limited resources is the case. (C) 2016 Elsevier Ltd. All rights reserved.","Authors":"Giatsoglou, M (Giatsoglou, Maria) ; Vozalis, MG (Vozalis, Manolis G.) ; Diamantaras, K (Diamantaras, Konstantinos) ; Vakali, A (Vakali, Athena) ; Sarigiannidis, G (Sarigiannidis, George) ; Chatzisavvas, KC (Chatzisavvas, Konstantinos Ch.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Diamantaras, Konstantinos  http://orcid.org/0000-0003-1373-4022","Title":"Sentiment analysis leveraging emotions and word embeddings"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397528800001 ISSN: 1758-0463","Categories":"Mathematical & Computational Biology Web of Science Categories:Mathematical & Computational Biology","Journal Information":"DATABASE-THE JOURNAL OF BIOLOGICAL DATABASES AND CURATION Article Number: baw156 DOI: 10.1093/database/baw156 Published: FEB 26 2017","Abstract":"Extracting meaningful relationships with semantic significance from biomedical literature is often a challenging task. BioCreative V track4 challenge for the first time has organized a comprehensive shared task to test the robustness of the text-mining algorithms in extracting semantically meaningful assertions from the evidence statement in biomedical text. In this work, we tested the ability of a rule-based semantic parser to extract Biological Expression Language (BEL) statements from evidence sentences culled out of biomedical literature as part of BioCreative V Track4 challenge. The system achieved an overall best F-measure of 21.29% in extracting the complete BEL statement. For relation extraction, the system achieved an F-measure of 65.13% on test data set. Our system achieved the best performance in five of the six criteria that was adopted for evaluation by the task organizers. Lack of ability to derive semantic inferences, limitation in the rule sets to map the textual extractions to BEL function were some of the reasons for low performance in extracting the complete BEL statement. Post shared task we also evaluated the impact of differential NER components on the ability to extract BEL statements on the test data sets besides making a single change in the rule sets that translate relation extractions into a BEL statement. There is a marked improvement by over 20% in the overall performance of the BELMiner's capability to extract BEL statement on the test set.","Authors":"Ravikumar, KE (Ravikumar, K. E.) ; Rastegar-Mojarad, M (Rastegar-Mojarad, Majid) ; Liu, HF (Liu, Hongfang)","Title":"BELMiner: adapting a rule-based relation extraction system to extract biological expression language statements from bio-medical literature evidence sentences"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000386738300020 ISSN: 0377-2217 eISSN: 1872-6860","Keywords":"Finance; Risk prediction; Text mining; Sentiment analysis KeyWords Plus:TIME-SERIES; TEXTUAL ANALYSIS; MANAGEMENT; VOLATILITY; SENTIMENT; RETURNS; MODEL","Categories":"Business & Economics; Operations Research & Management Science Web of Science Categories:Management; Operations Research & Management Science","Journal Information":"EUROPEAN JOURNAL OF OPERATIONAL RESEARCH Volume: 257 Issue: 1 Pages: 243-250 DOI: 10.1016/j.ejor.2016.06.069 Published: FEB 16 2017","Abstract":"We attempt in this paper to utilize soft information in financial reports to analyze financial risk among companies. Specifically, on the basis of the text information in financial reports, which is the so-called soft information, we apply analytical techniques to study relations between texts and financial risk. Furthermore, we conduct a study on financial sentiment analysis by using a finance-specific sentiment lexicon to examine the relations between financial sentiment words and financial risk. A large collection of financial reports published annually by publicly-traded companies is employed to conduct our experiments; moreover, two analytical techniques - regression and ranking methods - are applied to conduct these analyses. The experimental results show that, based on a bag-of-words model, using only financial sentiment words results in performance comparable to using the whole texts; this confirms the importance of financial sentiment words with respect to risk prediction. In addition to this performance comparison, via the learned models, we draw attention to some strong and interesting correlations between texts and financial risk. These valuable findings yield greater insight and understanding into the usefulness of soft information in financial reports and can be applied to a broad range of financial and accounting applications. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Tsai, MF (Tsai, Ming-Feng) ; Wang, CJ (Wang, Chuan-Ju) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Wang, Chuan-Ju  http://orcid.org/0000-0002-5281-2962","Title":"On the risk prediction and analysis of soft information in finance reports"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393009800010 ISSN: 0950-7051 eISSN: 1872-7409","Keywords":"Comments summarization; Social media; Swarm intelligence; Ant colony optimization; Text mining","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"KNOWLEDGE-BASED SYSTEMS Volume: 118 Pages: 105-114 DOI: 10.1016/j.knosys.2016.11.009 Published: FEB 15 2017","Abstract":"User-contributed comments (UCC) are one of the signs of the social media. Due to the high popularity of social media, it becomes already exceedingly difficult to find the most relevant, interactive information for the users. The motivation behind this work is the fact that users may interest to get an efficacious brief understanding of comments without reading the entire comments. This paper opens up an unconventional field of comment's summarization predicated on Ant colony optimization mixed with Jensen Shannon divergence (ACO-JSD). ACO-JSD is a proposed novel technique concerning the extraction the most interactive comments from the huge amount of concise comment's perspectives. This problem is unfastened utilizing ACO to generate the optimal solution. Moreover, the JSD model is employed to ensure a summary could capture the essence of the original comments. First, an acyclic semi-graph has been constructed under two constraints: (1) the longest comments will be isolated from the graph, (2) The more similarity between two comments, the greater the chance that mutual connectivity is eliminated. Next, a feasible solution is constructed to select the high-quality summarization. Finally, the proposed algorithm has been evaluated over a collection of Facebook posts with their associated comments and an excellent performance in comparison with traditional document summarization algorithms was obtained. Accordingly, the computational results show the efficiency of the proposed algorithm, as well as its ability to find a good summary that is guaranteed to be near-optimal. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Mosa, MA (Mosa, Mohamed Atef) ; Hamouda, A (Hamouda, Alaa) ; Marei, M (Marei, Mahmoud)","Title":"Ant colony heuristic for user-contributed comments summarization"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000398053400011 ISSN: 1094-3501","Keywords":"Collaborative Learning; Writing; Digital Literacies; Research Methods KeyWords Plus:LANGUAGE; WIKIS; LEARNERS; STUDENTS; TECHNOLOGY; FACILITATE","Categories":"Education & Educational Research; Linguistics Web of Science Categories:Education & Educational Research; Linguistics","Journal Information":"LANGUAGE LEARNING & TECHNOLOGY Volume: 21 Issue: 1 Pages: 146-165 Special Issue: SI Published: FEB 2017","Abstract":"The increasingly widespread use of social software (e.g., Wikis, Google Docs) in second language (L2) settings has brought a renewed attention to collaborative writing. Although the current methodological approaches to examining collaborative writing are valuable to understand L2 students' interactional patterns or perceived experiences, they can be insufficient to capture the quantity and quality of writing in networked online environments. Recently, the evolution of techniques for analyzing big data has transformed many areas of life, from information search to marketing. However, the use of data and text mining for understanding writing processes in language learning contexts is largely underexplored. In this article, we synthesize the current methodological approaches to researching collaborative writing and discuss how new text mining tools can enhance research capacity. These advanced methods can help researchers to elucidate collaboration processes by analyzing user behaviors (e. g., amount of editing, participation equality) and their link to writing outcomes across large numbers of exemplars. We introduce key research examples to illustrate this potential and discuss the implications of integrating the tools for L2 collaborative writing research and pedagogy.","Authors":"Yim, S (Yim, Soobin) ; Warschauer, M (Warschauer, Mark)","Title":"WEB-BASED COLLABORATIVE WRITING IN L2 CONTEXTS: METHODOLOGICAL INSIGHTS FROM TEXT MINING"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000397311100005 ISSN: 1019-6781 eISSN: 1422-8890","Keywords":"Media industry; Media business; Broadcasting; Social media; Print industry; Information technology KeyWords Plus:QUALITY","Categories":"Business & Economics Web of Science Categories:Business; Management","Journal Information":"ELECTRONIC MARKETS Volume: 27 Issue: 1 Pages: 33-47 DOI: 10.1007/s12525-016-0239-9 Published: FEB 2017","Abstract":"Global media reports clearly show a tremendous increase in spending on Information Technology (IT) and Information Systems (IS) in the media sector. Two main trends are currently visible. First, as stated in McKinsey & Company's Global Media Report, consumers continuously shift from spending on traditional media products towards rapidly-increasing spending on digital services and media products-consumer patterns have rapidly changed. Second, as stated in Gartner's reports about the media industry, spending on IT services in the media industry increases gradually, and as a whole, themedia industry is the third-largest spender on IT, after banking/ finance and manufacturing. Third, as reported by both authors in their works, several facets of the media industry have undergone extreme changes, including business models, declining revenue, content models, management, economics and public funding. The aim of this study is to investigate research work related to IS in the media industry, in particular in the management and economic areas. To conduct this study, we investigated a large corpus of studies that have been contributed to IS research within the Association for Information Systems (AIS) within the past decades. We utilised advanced text mining methods to identify contributions and thematic areas. Our results clearly indicate that there is a significant downward trend of research works dealing with media industry aspects. This trend was a surprise to us, as it contradicts the emergence of new digital technologies which became key drivers in the media industry after 2009. We conclude this article by giving research directions, illustrating the opportunities and importance of investigating media industries within the context of IS, and introducing the research field of Information Systems in the eMedia Industry.","Authors":"Lugmayr, A (Lugmayr, Artur) ; Grueblbauer, J (Grueblbauer, Johanna)","Title":"Review of information systems research for media industry-recent advances, challenges, and introduction of information systems research in the media industry"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395080200007 ISSN: 1387-3326 eISSN: 1572-9419","Keywords":"Data mining; Text mining; Information systems; Politics; Truthfulness; Association rules KeyWords Plus:TOPIC DETECTION; GOVERNMENT; DISCOVERY; CITIZENS","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"INFORMATION SYSTEMS FRONTIERS Volume: 19 Issue: 1 Pages: 109-127 DOI: 10.1007/s10796-015-9596-8 Published: FEB 2017","Abstract":"In modern information societies, there are information systems that track and log parts of the ongoing political discourse. Due to the sheer volume of the accumulated data, automated tools are required in order to enable citizens to better interpret political statements and promises, as well as evaluate their truthfulness. We propose an approach to use the established machine learning and data mining techniques for analyzing annotated political statements and promises available via the Serbian Truth-o-meter (Istinomer) system in order to extract and interpret the hidden patterns of truthfulness and deceit. We perform standard textual processing and topic extraction and associate topical truthfulness profiles with the promise makers, for pattern discovery and prediction. Prevailing trends in Serbian political discourse emerge as strong association rules where truthfulness is set as the target variable. The evaluated set of standard content-based prediction models exhibit a bias towards the negative outcomes, due to an overall low truthfulness rate in the data. Our results demonstrate that it is possible to use data mining within political information systems for generating insights into the workings of governments.","Authors":"Tomasev, N (Tomasev, Nenad)","Title":"Extracting the patterns of truthfulness from political information systems in Serbia"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397411100001 ISSN: 2158-107X eISSN: 2156-5570","Keywords":"Opinion mining; Stock market; Twitter; Saudi Arabia; Association text rules; Data mining; Text Visualization KeyWords Plus:SCHEME","Categories":"Computer Science Web of Science Categories:Computer Science, Theory & Methods","Journal Information":"INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS Volume: 8 Issue: 2 Pages: 1-7 Published: FEB 2017","Abstract":"Text mining methods involve various techniques, such as text categorization, summarisation, information retrieval, document clustering, topic detection, and concept extraction. In addition, because of the difficulties involved in text mining, visualisation techniques can play a paramount role in the analysis and pre-processing of textual data. This paper will present two novel frameworks for the classification and extraction of the association rules and the visualisation of financial Arabic text in order to realize both the general structure and the sentiment within an accumulated corpus. However, mining unstructured data with natural language processing (NLP) and machine learning techniques can be arduous, especially where the Arabic language is concerned, because of limited research in this area. The results show that our frameworks can readily classify Arabic tweets. Furthermore, they can handle many antecedent text association rules for the positive class and the negative class.","Authors":"AL-Rubaiee, H (AL-Rubaiee, Hamed) ; Qiu, RX (Qiu, Renxi) ; Li, DY (Li, Dayou)","Title":"Visualising Arabic Sentiments and Association Rules in Financial Text"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397411100037 ISSN: 2158-107X eISSN: 2156-5570","Keywords":"Informal Arabic; Sentiment analysis; Opinion Mining (OM); Twitter; YouTube KeyWords Plus:SUBJECTIVITY","Categories":"Computer Science Web of Science Categories:Computer Science, Theory & Methods","Journal Information":"INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS Volume: 8 Issue: 2 Pages: 278-284 Published: FEB 2017","Abstract":"Recently, there are wide numbers of users that use the social network like Twitter, Facebook, MySpace to share various kinds of resources, express their opinions, thoughts, messages in real time. Thus, increase the amount of electronic content that generated by users. Sentiment analysis becomes a very interesting topic in research community. Thereby, we need to give more attention to Arabic sentiment analysis. This paper discusses the challenges and obstacles when analyze the sentiment analysis of informal Arabic, the social media. The most of recent research sentiment analysis conduct for English text. Also, when the research works in Arabic sentiment analysis, they focus in formal Arabic. However, most of social media network use the informal Arabic (colloquial) such as Twitter and YouTube website. This paper investigates the problems and the challenges to identify sentiment in informal Arabic language which is mostly used when users express their opinions and feelings in context of twitter and YouTube Arabic content.","Authors":"AlOtaibi, S (AlOtaibi, Salihah) ; Khan, MB (Khan, Muhammad Badruddin)","Title":"Sentiment Analysis Challenges of Informal Arabic Language"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395371400003 ISSN: 0218-4885 eISSN: 1793-6411","Keywords":"Microblogging; micro-message; clustering; similarity upper approximation; primitive interest; rough set KeyWords Plus:ROUGH SET MODEL; SEQUENTIAL INFORMATION; SOCIAL MEDIA","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"INTERNATIONAL JOURNAL OF UNCERTAINTY FUZZINESS AND KNOWLEDGE-BASED SYSTEMS Volume: 25 Issue: 1 Pages: 53-79 DOI: 10.1142/S0218488517500039 Published: FEB 2017","Abstract":"Microblogging platforms like Twitter, Tumblr and Plurk have radically changed our lives. The presence of millions of people has made these platforms a preferred channel for communication. A large amount of User Generated Content, on these platforms, has attracted researchers and practitioners to mine and extract information nuggets. For information extraction, clustering is an important and widely used mining operation. This paper addresses the issue of clustering of micro-messages and corresponding users based on the text content of micro-messages that reflect their primitive interest. In this paper, we performed modification of the Similarity Upper Approximation based clustering algorithm for clustering of micro-messages. We compared the performance of the modified Similarity Upper Approximation based clustering algorithm with state-of-the-art clustering algorithms such as Partition Around Medoids, Hierarchical Agglomerative Clustering, Affinity Propagation Clustering and DBSCAN. Experiments were performed on micro-messages collected from Twitter. Experimental results show the effectiveness of the proposed algorithm.","Authors":"Gupta, M (Gupta, Mukul) ; Kumar, P (Kumar, Pradeep) ; Bhasker, B (Bhasker, Bharat)","Title":"Clustering of Micro-Messages Using Similarity Upper Approximation"}, {"Document Information":"Document Type:Software Review Language:English Accession Number: WOS:000394793900004 ISSN: 1076-9986 eISSN: 1935-1054","Keywords":"software; modeling; data management; text mining; data analysis; big data; data cleaning KeyWords Plus:COH-METRIX; TEXT; TASK","Categories":"Education & Educational Research; Mathematical Methods In Social Sciences; Psychology Web of Science Categories:Education & Educational Research; Social Sciences, Mathematical Methods; Psychology, Mathematical","Journal Information":"JOURNAL OF EDUCATIONAL AND BEHAVIORAL STATISTICS Volume: 42 Issue: 1 Pages: 85-106 DOI: 10.3102/1076998616666808 Published: FEB 2017","Abstract":"In recent years, a wide array of tools have emerged for the purposes of conducting educational data mining (EDM) and/or learning analytics (LA) research. In this article, we hope to highlight some of the most widely used, most accessible, and most powerful tools available for the researcher interested in conducting EDM/LA research. We will highlight the utility that these tools have with respect to common data preprocessing and analysis steps in a typical research project as well as more descriptive information such as price point and user-friendliness. We will also highlight niche tools in the field, such as those used for Bayesian knowledge tracing (BKT), data visualization, text analysis, and social network analysis. Finally, we will discuss the importance of familiarizing oneself with multiple toolsa data analysis toolboxfor the practice of EDM/LA research.","Authors":"Slater, S (Slater, Stefan) ; Joksimovic, S (Joksimovic, Srecko) ; Kovanovic, V (Kovanovic, Vitomir) ; Baker, RS (Baker, Ryan S.) ; Gasevic, D (Gasevic, Dragan) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Kovanovic, Vitomir  F-5862-2017 http://orcid.org/0000-0001-9694-6033","Title":"Tools for Educational Data Mining: A Review"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394671000003 ISSN: 0165-5515 eISSN: 1741-6485","Keywords":"Feature selection; rank aggregation; sentiment classification KeyWords Plus:TRAVELING SALESMAN PROBLEM; ALGORITHMS","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF INFORMATION SCIENCE Volume: 43 Issue: 1 Pages: 25-38 DOI: 10.1177/0165551515613226 Published: FEB 2017","Abstract":"Sentiment analysis is an important research direction of natural language processing, text mining and web mining which aims to extract subjective information in source materials. The main challenge encountered in machine learning method-based sentiment classification is the abundant amount of data available. This amount makes it difficult to train the learning algorithms in a feasible time and degrades the classification accuracy of the built model. Hence, feature selection becomes an essential task in developing robust and efficient classification models whilst reducing the training time. In text mining applications, individual filter-based feature selection methods have been widely utilized owing to their simplicity and relatively high performance. This paper presents an ensemble approach for feature selection, which aggregates the several individual feature lists obtained by the different feature selection methods so that a more robust and efficient feature subset can be obtained. In order to aggregate the individual feature lists, a genetic algorithm has been utilized. Experimental evaluations indicated that the proposed aggregation model is an efficient method and it outperforms individual filter-based feature selection methods on sentiment classification.","Authors":"Onan, A (Onan, Aytug) ; Korukoglu, S (Korukoglu, Serdar)","Title":"A feature selection model based on genetic rank aggregation for text sentiment classification"}, {"Keywords":"Text classification; Transductive learning; Graph-based learning; Text mining; Label propagation; Bipartite graphs KeyWords Plus:NETWORKS; MODEL","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"PATTERN RECOGNITION LETTERS Volume: 87 Pages: 127-138 Special Issue: SI DOI: 10.1016/j.patrec.2016.04.006 Published: FEB 1 2017","Abstract":"Transductive classification is an useful way to classify a collection of unlabeled textual documents when only a small fraction of this collection can be manually labeled. Graph-based algorithms have aroused considerable interests in recent years to perform transductive classification since the graph-based representation facilitates label propagation through the graph edges. In a bipartite graph representation, nodes represent objects of two types, here documents and terms, and the edges between documents and terms represent the occurrences of the terms in the documents. In this context, the label propagation is performed from documents to terms and then from terms to documents iteratively. In this paper we propose a new graph-based transductive algorithm that use the bipartite graph structure to associate the available class information of labeled documents and then propagate these class information to assign labels for unlabeled documents. By associating the class information to edges linking documents to terms we guarantee that a single term can propagate different class information to its distinct neighbors. We also demonstrated that the proposed method surpasses the algorithms for transductive classification based on vector space model or graphs when only a small number of labeled documents is available. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Faleiros, TD (Faleiros, Thiago de Paulo) ; Rossi, RG (Rossi, Rafael Geraldeli) ; Lopes, AD (Lopes, Alneu de Andrade)","Title":"Optimizing the class information divergence for transductive classification of texts using propagation in bipartite graphs"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396969200017 ISSN: 1004-4132","Keywords":"feature selection; Markov blanket; particle swarm optimization; information metric KeyWords Plus:FEATURE SUBSET-SELECTION; ANT COLONY OPTIMIZATION; ROUGH SETS; ALGORITHM; CLASSIFICATION","Categories":"Automation & Control Systems; Engineering; Operations Research & Management Science Web of Science Categories:Automation & Control Systems; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"JOURNAL OF SYSTEMS ENGINEERING AND ELECTRONICS Volume: 28 Issue: 1 Pages: 151-161 DOI: 10.21629/JSEE.2017.01.17 Published: FEB 2017","Abstract":"Feature selection plays an important role in data mining and recognition, especially in the large scale text, image and biological data. Specifically, the class label information is unavailable to guide the selection of minimal feature subset in unsupervised feature selection, which is challenging and interesting. An unsupervised feature selection based on Markov blanket and particle swarm optimization is proposed named as UFSMB-PSO. The proposed method seeks to find the high-quality feature subset through multi-particles' cooperation of particle swarm optimization without using any learning algorithms. Moreover, the features' relevance will be computed based on an information metric of relevance gain, which provides an information theoretical foundation for finding the minimization of the redundancy between features. Our results on several benchmark datasets demonstrate that UFSMB-PSO can achieve significant improvement over state of the art unsupervised methods.","Authors":"Wang, YT (Wang, Yintong) ; Wang, JD (Wang, Jiandong) ; Liao, H (Liao, Hao) ; Chen, HY (Chen, Haiyan)","Title":"Unsupervised feature selection based on Markov blanket and particle swarm optimization"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394377100011 PubMed ID: 28118024 ISSN: 2152-2715 eISSN: 2152-2723","Keywords":"electronic cigarettes; physician; twitter; text analytics KeyWords Plus:FOR-DISEASE-CONTROL; LIVE TWITTER CHAT; HEALTH COMMUNICATION; US ADULTS; AWARENESS; FUTURE","Categories":"Psychology Web of Science Categories:Psychology, Social","Journal Information":"CYBERPSYCHOLOGY BEHAVIOR AND SOCIAL NETWORKING Volume: 20 Issue: 2 Pages: 133-137 DOI: 10.1089/cyber.2016.0409 Published: FEB 2017","Abstract":"Medical professionals are now relying on social media platforms like Twitter to express their recommendations for the use or avoidance of products like electronic cigarettes (e-cigs), which may have long-term health consequences for users. The goal of this study is to compare how physicians from the United States and the United Kingdom talk about e-cigs on Twitter and identify the topics that these groups perceive as salient. Comparing tweets from the U.S. and U.K. will allow for a better understanding of how medical professionals from these countries differ in their attitudes toward e-cigs. This information can be also used to inform policies designed to regulate the use of e-cigs. Using a text-mining program, we analyzed approximately 3,800 original tweets sent by physicians from the U.S. and the U.K. within a 1-year time span (June 2015 through June 2016). The program clustered the tweets by topics, which allowed us to categorize the topics by importance. Both sets of tweets contained debates about the degree to which e-cigs pose a threat to health, but the U.S. tweets emphasized the dangers of e-cig use for teens, while the U.K. tweets focused more on the potential that e-cigs have to be used as a smoking cessation aid. Doctors are using Twitter to share timely information about the potential risks, benefits, and regulations associated with e-cigs. Evaluating these tweets allows researchers to collect information about topics that doctors find important and make comparisons about how medical professionals from the U.S. and the U.K. regard e-cigs.","Authors":"Glowacki, EM (Glowacki, Elizabeth M.) ; Lazard, AJ (Lazard, Allison J.) ; Wilcox, GB (Wilcox, Gary B.)","Title":"E-Cigarette Topics Shared by Medical Professionals: A Comparison of Tweets from the United States and United Kingdom"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000394352100004 ISSN: 0948-3349 eISSN: 1614-7502","Keywords":"Environmental impact; Life cycle assessment; Methodology; Prioritization; Text mining; Topic model; Weighting KeyWords Plus:IMPACT; LCA; SCIENCE; POLICY","Categories":"Engineering; Environmental Sciences & Ecology Web of Science Categories:Engineering, Environmental; Environmental Sciences","Journal Information":"INTERNATIONAL JOURNAL OF LIFE CYCLE ASSESSMENT Volume: 22 Issue: 2 Pages: 148-158 DOI: 10.1007/s11367-016-1153-2 Published: FEB 2017","Abstract":"Purpose Life cycle assessment aims to evaluate multiple kinds of environmental impact associated with a product or process across its life cycle. Objective evaluation is a common goal, though the community recognizes that implicit valuations of diverse impacts resulting from analytical choices and choice of subject matter are present. This research evaluates whether these implicit valuations lead to detectable priority shifts in the published English language academic LCA literature over time. Methods A near-comprehensive investigation of the LCA literature is undertaken by applying a text mining technique known as topic modeling to over 8200 environment-related LCA journal article titles and abstracts published between 1995 and 2014. Results and discussion Topic modeling using MALLET software and manual validation shows that over time, the LCA literature reflects a dramatic proportional increase in attention to climate change and a corresponding decline in attention to human and ecosystem health impacts, accentuated by rapid growth of the LCA literature. This result indicates an implicit prioritization of climate over other impact categories, a field-scale trend that appears to originate mostly in the broader environmental community rather than the LCA methodological community. Reasons for proportionally increasing publication of climate-related LCA might include the relative robustness of greenhouse gas emissions as an environmental impact indicator, a correlation with funding priorities, researcher interest in supporting active policy debates, or a revealed priority on climate versus other environmental impacts in the scholarly community. Conclusions As LCA becomes more widespread, recognizing and addressing the fact that analyses are not objective becomes correspondingly more important. Given the emergence of implicit prioritizations in the LCA literature, such as the impact prioritization of climate identified here with the use of computational tools, this work recommends the development and use of techniques that make impact prioritization explicit and enable consistent analysis of result sensitivity to value judgments. Explicit prioritization can improve transparency while enabling more systematic investigation of the effects of value choices on how LCA results are used.","Authors":"Grubert, E (Grubert, Emily) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Grubert, Emily  http://orcid.org/0000-0003-2196-7571","Title":"Implicit prioritization in life cycle assessment: text mining and detecting metapatterns in the literature"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396051200004 ISSN: 1380-7501 eISSN: 1573-7721","Keywords":"Compromised accounts; Authorship verification; Online social networks KeyWords Plus:SENTIMENT ANALYSIS; RECOMMENDATION; ATTRIBUTION; CLASSIFICATION; INFORMATION; MICROBLOGS; TWITTER; TWEETS; TEXT","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"MULTIMEDIA TOOLS AND APPLICATIONS Volume: 76 Issue: 3 Pages: 3213-3233 DOI: 10.1007/s11042-016-3899-8 Published: FEB 2017","Abstract":"Compromising legitimate accounts has been the most used strategy to spread malicious content on OSN (Online Social Network). To address this problem, we propose a pure text mining approach to check if an account has been compromised based on its posts content. In the first step, the proposed approach extracts the writing style from the user account. The second step comprehends the k-Nearest Neighbors algorithm (k-NN) to evaluate the post content and identify the user. Finally, Baseline Updating (third step) consists of a continuous updating of the user baseline to support the current trends and seasonality issues of user's posts. Experiments were carried out using a dataset from Twitter composed by tweets of 1000 users. All the three steps were individually evaluated, and the results show that the developed method is stable and can detect the compromised accounts. An important observation is the Baseline Updating contribution, which leads to an enhancement of accuracy superior of 60 %. Regarding average accuracy, the developed method achieved results over 93 %.","Authors":"Barbon, S (Barbon, Sylvio, Jr.) ; Igawa, RA (Igawa, Rodrigo Augusto) ; Zarpelao, BB (Zarpelao, Bruno Bogaz)","Title":"Authorship verification applied to detection of compromised accounts on online social networks A continuous approach"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396231100007 ISSN: 2168-2216","Keywords":"Detecting patterns; interaction contexts; loopy belief propagation (LBP); mining relationships; social manufacturing network KeyWords Plus:NETWORK; PROPAGATION; ALGORITHM; DISCOVERY; MODELS; SYSTEM","Categories":"Automation & Control Systems; Computer Science Web of Science Categories:Automation & Control Systems; Computer Science, Cybernetics","Journal Information":"IEEE TRANSACTIONS ON SYSTEMS MAN CYBERNETICS-SYSTEMS Volume: 47 Issue: 2 Pages: 276-288 DOI: 10.1109/TSMC.2016.2623630 Published: FEB 2017","Abstract":"There is an increasing use of social interaction contexts in the cross-enterprise manufacturing problem solving. To transform these massive and unstructured data into decision-support information for cross-enterprise manufacturing demand-capability matching, we present automated solutions to two phases: 1) extracting relationships based on a semi-supervised learning approach to derive formalized heterogeneous manufacturing network from the unstructured text-based context that contains high levels of noise and irrelevant information and 2) matching group-level relationships among the entities in the established manufacturing network. The extracting phase formulates network data using multiattributed graph that can encode various entities and relationships. The matching phase is based on probabilistic multiattributed graph matching, and implemented using distributed message passing algorithm. We developed a prototype system to verify the proposed model, which is also flexible to new domains of contexts and scale to large datasets. The ultimate goal of this paper is to facilitate knowledge transferring and sharing in the context of cross-enterprise social interaction, thereby supporting the integration of the resources and capabilities among different enterprise.","Authors":"Leng, JW (Leng, Jiewu) ; Jiang, PY (Jiang, Pingyu) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Leng, Jiewu  http://orcid.org/0000-0003-4068-3910","Title":"Mining and Matching Relationships From Interaction Contexts in a Social Manufacturing Paradigm"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394158300006 ISSN: 1617-9846 eISSN: 1617-9854","Keywords":"Text mining; Twitter; Natural language processing; Gender classification; Knowledge discovery; Supervised learning; Artificial intelligence; Business intelligence KeyWords Plus:FEATURE-SELECTION; CATEGORIZATION","Categories":"Business & Economics Web of Science Categories:Business; Management","Journal Information":"INFORMATION SYSTEMS AND E-BUSINESS MANAGEMENT Volume: 15 Issue: 1 Pages: 117-138 DOI: 10.1007/s10257-016-0312-0 Published: FEB 2017","Abstract":"Gender profiling of unstructured text data has several applications in areas such as marketing, advertising, legal investigation, and recommender systems. The automatic detection of gender in microblogs, like twitter, is a difficult task. It requires a system that can use knowledge to interpret the linguistic styles being used by the genders. In this paper, we try to provide this knowledge for such a system by considering different sets of features, which are relatively independent of the text, such as function words and part of speech n-grams. We test a range of different feature sets using two different classifiers; namely Na < ve Bayes and maximum entropy algorithms. Our results show that the gender detection task benefits from the inclusion of features that capture the authorial style of the microblog authors. We achieve an accuracy of approximately 71 %, which outperforms the classification accuracy of commercially available gender detection software like Gender Genie and Gender Guesser.","Authors":"Mukherjee, S (Mukherjee, Shubhadeep) ; Bala, PK (Bala, Pradip Kumar)","Title":"Gender classification of microblog text based on authorial style"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394148300013 ISSN: 0138-9130 eISSN: 1588-2861","Keywords":"Research priority; Research gap; Text mining; Environment studies; Researchers' behavior analysis KeyWords Plus:LOG FILES; TRENDS; PREDICTION; MANAGEMENT; RETRIEVAL; FEEDBACK","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Interdisciplinary Applications; Information Science & Library Science","Journal Information":"SCIENTOMETRICS Volume: 110 Issue: 2 Pages: 815-842 DOI: 10.1007/s11192-016-2195-8 Published: FEB 2017","Abstract":"This study aims to observe the researchers' behavior in Iranian scientific databases to determine the research gaps and priorities in their field of research. Text mining and natural language processing techniques were used to identify what researchers are looking for and to analyze existing research works. In this paper, the information about the behavior of researchers who work in the field of environmental science and existing research works in the Iranian scientific database are processed. The search trends in all areas are evaluated by analyzing the users' search data. The trend analysis indicates that in the period of February 2013 to July 2015, the growth of the researchers' requests in some domains of the environment such as Industry, Training, Assessment, Material, Water and Pollution was 1.5 up to 2 times more than the overall requests. A Combination of the trend analysis and clustering of queries led to shaping four priority zones. Then, the research priorities for each environmental research area were determined. The results show that Training, Pollution, Rangeland, Management and Law are those domains in the environmental research which have the most research gaps in Iran, but there are enough research in Forest, Soil and Industry domains. At the end, we describe the steps for the implementation of a decision support system in environmental research management. Researchers, managers and policy makers can use this proposed \"research demand and supply monitoring'' system or RDSM to make appropriate decisions and allocate their resources more efficiently.","Authors":"Rabiei, M (Rabiei, Mohammad) ; Hosseini-Motlagh, SM (Hosseini-Motlagh, Seyyed-Mahdi) ; Haeri, A (Haeri, Abdorrahman)","Title":"Using text mining techniques for identifying research gaps and priorities: a case study of the environmental science in Iran"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393759100005 ISSN: 0942-4962 eISSN: 1432-1882","Keywords":"Web image clustering; Ranking; Diversity; Visibility; Graph model KeyWords Plus:CROSS-MEDIA RETRIEVAL; RECOGNITION; ADAPTATION; KNOWLEDGE","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"MULTIMEDIA SYSTEMS Volume: 23 Issue: 1 Pages: 41-52 Special Issue: SI DOI: 10.1007/s00530-014-0419-4 Published: FEB 2017","Abstract":"In this paper, we consider the problem of clustering and re-ranking web image search results so as to improve diversity at high ranks. We propose a novel ranking framework, namely cluster-constrained conditional Markov random walk (CCCMRW), which has two key steps: first, cluster images into topics, and then perform Markov random walk in an image graph conditioned on constraints of image cluster information. In order to cluster the retrieval results of web images, a novel graph clustering model is proposed in this paper. We explore the surrounding text to mine the correlations between words and images and therefore the correlations are used to improve clustering results. Two kinds of correlations, namely word to image and word to word correlations, are mainly considered. As a standard text process technique, tf-idf method cannot measure the correlation of word to image directly. Therefore, we propose to combine tf-idf method with a novel feature of word, namely visibility, to infer the word-to-image correlation. By latent Dirichlet allocation model, we define a topic relevance function to compute the weights of word-to-word correlations. Taking word to image correlations as heterogeneous links and word-to-word correlations as homogeneous links, graph clustering algorithms, such as complex graph clustering and spectral co-clustering, are respectively used to cluster images into topics in this paper. In order to perform CCCMRW, a two-layer image graph is constructed with image cluster nodes as upper layer added to a base image graph. Conditioned on the image cluster information from upper layer, Markov random walk is constrained to incline to walk across different image clusters, so as to give high rank scores to images of different topics and therefore gain the diversity. Encouraging clustering and re-ranking outputs on Google image search results are reported in this paper.","Authors":"Yan, Y (Yan, Yan) ; Liu, GW (Liu, Gaowen) ; Wang, S (Wang, Sen) ; Zhang, J (Zhang, Jian) ; Zheng, K (Zheng, Kai)","Title":"Graph-based clustering and ranking for diversified image search"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393631500007 ISSN: 0167-9236 eISSN: 1873-5797","Keywords":"Sentiment analysis; Opinion mining; Sentiment lexicon; Lexicon expansion; Social media KeyWords Plus:STOCK-MARKET; BUSINESS INTELLIGENCE; CLASSIFICATION; FIRM; MICROBLOGS; BEHAVIOR; TWITTER; IMPACT; WEB","Categories":"Computer Science; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science","Journal Information":"DECISION SUPPORT SYSTEMS Volume: 94 Pages: 65-76 DOI: 10.1016/j.dss.2016.11.001 Published: FEB 2017","Abstract":"Social media has become the largest data source of public opinion. The application of sentiment analysis to social media texts has great potential, but faces great challenges because of domain heterogeneity. Sentiment orientation of words varies by content domain, but learning context-specific sentiment in social media domains continues to be a major challenge. The language domain poses another challenge since the language used in social media today differs significantly from that used in traditional media. To address these challenges, we propose a method to adapt existing sentiment lexicons for domain-specific sentiment classification using an unannotated corpus and a dictionary. We evaluate our method using two large developing corpora, containing 743,069 tweets related to the stock market and one million tweets related to political topics, respectively, and five existing sentiment lexicons as seeds and baselines. The results demonstrate the usefulness of our method, showing significant improvement in sentiment classification performance. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Deng, SY (Deng, Shuyuan) ; Sinha, AP (Sinha, Atish P.) ; Zhao, HM (Zhao, Huimin)","Title":"Adapting sentiment lexicons to domain-specific social media texts"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393631500009 ISSN: 0167-9236 eISSN: 1873-5797","Keywords":"Decision support; Online review; Review quality; Web personalization; Text mining; Web 2.0 KeyWords Plus:WORD-OF-MOUTH; ONLINE REVIEWS; INFORMATION-SYSTEMS; CURRENT STATE; E-COMMERCE; SEARCH; RECOMMENDATION; ALGORITHM; HELPFULNESS; QUALITY","Categories":"Computer Science; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science","Journal Information":"DECISION SUPPORT SYSTEMS Volume: 94 Pages: 85-96 DOI: 10.1016/j.dss.2016.11.003 Published: FEB 2017","Abstract":"In recent years there has been increased consumer use of the vast array of online reviews. Given the increasingly high volume of such reviews, automatic analyses of their quality have become imperative. Not surprisingly, this situation has attracted the interest of researchers. However, prior approaches are insufficient to address the consumers' need for non-burdensome sense making of online reviews. This research attempts to close this gap by proposing novel design science artifacts (i.e. construct, architecture, algorithms and prototype) to address the consumers' need. We evaluate these artifacts using a set of experiments and hypothesis tests. The results validate the effectiveness and efficiency of the proposed artifacts. We demonstrate their practical utility and relevance using real world pilot experiments. This paper contributes theoretical knowledge to the review quality literature and, what we believe is the first exemplifier for adequately validating the solutions of review quality research. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Flory, L (Flory, Long) ; Osei-Bryson, KM (Osei-Bryson, Kweku-Muata) ; Thomas, M (Thomas, Manoj)","Title":"A new web personalization decision-support artifact for utility-sensitive customer review analysis"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393309600015 ISSN: 1868-8071 eISSN: 1868-808X","Keywords":"Data mining; Information extraction; Big data; Entity extraction; Data science; Hidden Markov models; Learning algorithms","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS Volume: 8 Issue: 1 Pages: 171-178 Special Issue: SI DOI: 10.1007/s13042-016-0514-2 Published: FEB 2017","Abstract":"One of the applications of the Formal concept analysis (FCA) is the ability to extract structured information from textual documents. Typically, one can define a set of attributes that will characterize the objects. Consequently, these defined objects will be extracted by standard FCA algorithms. In this paper, we describe how FCA identifies and extracts personal names as units of thought similar to the decoding of text sequences by Viterbi algorithm as used with Hidden Markov Models. We further exhibit how FCA mimics the thought process that goes into a rule-based information extraction system. We then observe that the formal approach of FCA combined with already established computational techniques such as bottom up intersection algorithm avoids the difficulties associated with hand coding and maintenance of rule-based systems.","Authors":"Taghva, K (Taghva, Kazem)","Title":"Name identification and extraction with formal concept analysis"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393309600019 ISSN: 1868-8071 eISSN: 1868-808X","Keywords":"News clustering; k-means; W-kmeans; Cluster labeling; Partitional clustering; Collaborative filtering KeyWords Plus:SYSTEMS; ALGORITHM","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS Volume: 8 Issue: 1 Pages: 223-237 Special Issue: SI DOI: 10.1007/s13042-014-0316-3 Published: FEB 2017","Abstract":"Although commonly only item clustering is suggested by Web mining techniques for news articles recommendation systems, one of the various tasks of personalized recommendation is categorization of Web users. With the rapid explosion of online news articles, predicting user-browsing behavior using collaborative filtering (CF) techniques has gained much attention in the web personalization area. However common CF techniques suffer from problems like low accuracy and performance. This research proposes a new personalized recommendation approach that integrates both user and text clustering based on our developed algorithm, W-kmeans, with other information retrieval (IR) techniques, like text categorization and summarization in order to provide users with the articles that match their profiles. Our system can easily adapt over time to divertive user preferences. Furthermore, experimental results show that by aggregating item and user clustering with multiple IR techniques like categorization and summarization, our recommender generates results that outperform the cases where each or both of them are used, but clustering is not applied.","Authors":"Bouras, C (Bouras, Christos) ; Tsogkas, V (Tsogkas, Vassilis)","Title":"Improving news articles recommendations via user clustering"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393347100018 ISSN: 0040-1625 eISSN: 1873-5509","Keywords":"Patent lanes; Patent analysis; Cluster analysis; Similarity measurement; Visualization; Citation networks; Technological trajectories KeyWords Plus:SCIENCE-AND-TECHNOLOGY; CLASSIFICATION; CITATION; SIMILARITY; CENTRALITY; NETWORKS; PROGRESS; SYSTEM","Categories":"Business & Economics; Public Administration Web of Science Categories:Business; Planning & Development","Journal Information":"TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE Volume: 115 Pages: 210-220 DOI: 10.1016/j.techfore.2016.10.004 Published: FEB 2017","Abstract":"Understanding the evolution of a technological field in the course of time is a key task in technology analysis. Analysts in research institutions as well as in companies need to know which topics are relevant for the respective technological field, which are the emerging topics, which traditional topics have been deepened in the course of time and which have been abandoned. For this purpose we suggest a patent lane analysis. Patent lanes can be seen as the deployment of patent clusters in the course of time. We use a method based on semantic similarities to develop patent lanes. A case study focuses on the application of carbon fibers in bicycle technology; it is used to demonstrate our method, i.e. to establish patent lanes in this case and characterize them by multiple use of a Tf idf measure. Despite some limitations, patent lanes enable deep insights into the development of patent-friendly technological fields. (C) 2016 Elsevier Inc. All rights reserved.","Authors":"Niemann, H (Niemann, Helen) ; Moehrle, MG (Moehrle, Martin G.) ; Frischkom, J (Frischkom, Jonas)","Title":"Use of a new patent text-mining and visualization method for identifying patenting patterns over time: Concept, method and test application"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393347100030 ISSN: 0040-1625 eISSN: 1873-5509","Keywords":"Innovation system; Text mining; Foresight; Media analysis; Publications analysis; Future technology analysis KeyWords Plus:EMERGING TECHNOLOGIES; SENTIMENT ANALYSIS; FORESIGHT; IDENTIFICATION; FUTURES; ENERGY","Categories":"Business & Economics; Public Administration Web of Science Categories:Business; Planning & Development","Journal Information":"TECHNOLOGICAL FORECASTING AND SOCIAL CHANGE Volume: 115 Pages: 348-357 DOI: 10.1016/j.techfore.2016.08.005 Published: FEB 2017","Abstract":"Innovation as a systemic process is not only driven by science and technology but has diverse sources. While there are (numeric) indicators to map S&T developments such as patents, publications or standards, new indicators are required to map other areas of the innovation system. In this regard, one option is the examination of news reporting. News is a recognized channel for innovation diffusion and plays an important role in informing society. To contrast changes and developments in science and society, specifically the link between both is addressed in this article by comparing the content of news articles and scientific publications. Thus, the aim of this article is to first argue the benefit of integrating the media in the innovation system debate because of its recognized role in innovation diffusion and to develop a methodology to automatically compare scientific and media discourses. To process the volume of textual data according to a common analytical scheme, a text mining framework has been developed. The results offer valuable input for examining the present state of themes and technologies and, thereby, support future planning activities. (C) 2016 Elsevier Inc. All rights reserved.","Authors":"Kayser, V (Kayser, Victoria)","Title":"Comparing public and scientific discourse in the context of innovation systems"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000392684200001 ISSN: 0952-1976 eISSN: 1873-6769","Keywords":"Content pipeline; Relevance of text classification; Machine learning of syntactic parse trees; Personalized recommendation KeyWords Plus:GRAPHS; SEARCH","Categories":"Automation & Control Systems; Computer Science; Engineering Web of Science Categories:Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic","Journal Information":"ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE Volume: 58 Pages: 1-26 DOI: 10.1016/j.engappai.2016.11.001 Published: FEB 2017","Abstract":"This is a report from the field on a linguistic-based relevance technology based on learning of parse trees for processing, classification and delivery of a stream of texts. We describe the content pipeline for eBay entertainment domain which employs this technology, and show that text processing relevance is the main bottleneck for its performance. A number of components of the content pipeline such as content mining, aggregation, deduplication, opinion mining, integrity enforcing need to rely on domain-independent efficient text classification, entity extraction and relevance assessment operations. Text relevance assessment is based on the operation of syntactic generalization (SG) which finds a maximum common sub-tree for a pair of parse trees for sentences. Relevance of two portions of texts is then defined as a cardinality of this sub-tree. SG is intended to substitute keyword-based analysis for more accurate assessment of relevance which takes phrase-level and sentence-level information into account. In the partial case where short expression are commonly used terms such as Facebook likes, SG ascends to the level of categories and a reasoning technique is required to map these categories in the course of relevance assessment. A number of content pipeline components employ web mining which needs SG to compare web search results. We describe how SG works in a number of components in the content pipeline including personalization and recommendation, and provide the evaluation results for eBay deployment. Content pipeline support is implemented as an open source contribution OpenNLP.Similarity and is available at https://github.com/ bgalitsky/relevance-based-on-pars-trees.","Authors":"Galitsky, B (Galitsky, Boris)","Title":"Improving relevance in a content pipeline via syntactic generalization"}]