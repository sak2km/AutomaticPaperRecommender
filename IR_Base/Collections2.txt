Title: 
A hash-based co-clustering algorithm for categorical data
Abstract:
Cluster analysis, or clustering, refers to the analysis of the structural organization of a data set. This analysis is performed by grouping together objects of the data that are more similar among themselves than to objects of different groups. The sampled data may be described by numerical features or by a symbolic representation, known as categorical features. These features often require a transformation into numerical data in order to be properly handled by clustering algorithms. The transformation usually assigns a weight for each feature calculated by a measure of importance (i.e., frequency, mutual information). A problem with the weight assignment is that the values are calculated with respect to the whole set of objects and features. This may pose as a problem when a subset of the features have a higher degree of importance to a subset of objects but a lower degree with another subset. One way to deal with such problem is to measure the importance of each subset of features only with respect to a subset of objects. This is known as co-clustering that, similarly to clustering, is the task of finding a subset of objects and features that presents a higher similarity among themselves than to other subsets of objects and features. As one might notice, this task has a higher complexity than the traditional clustering and, if not properly dealt with, may present an scalability issue. In this paper we propose a novel co-clustering technique, called HBLCoClust, with the objective of extracting a set of co-clusters from a categorical data set, without the guarantees of an enumerative algorithm, but with the compromise of scalability. This is done by using a probabilistic clustering algorithm, named Locality Sensitive Hashing, together with the enumerative algorithm named InClose. The experimental results are competitive when applied to labeled categorical data sets and text corpora. Additionally, it is shown that the extracted co-clusters can be of practical use to expert systems such as Recommender Systems and Topic Extraction. (C) 2016 Elsevier Ltd. All rights reserved.

Title: 
CoTO: A novel approach for fuzzy aggregation of semantic similarity measures
Abstract:
Semantic similarity measurement aims to determine the likeness between two text expressions that use different lexicographies for representing the same real object or idea. There are a lot of semantic similarity measures for addressing this problem. However, the best results have been achieved when aggregating a number of simple similarity measures. This means that after the various similarity values have been calculated, the overall similarity for a pair of text expressions is computed using an aggregation function of these individual semantic similarity values. This aggregation is often computed by means of statistical functions. In this work, we present CoTO (Consensus or Trade-Off) a solution based on fuzzy logic that is able to outperform these traditional approaches. (C) 2016 Elsevier B.V. All rights reserved.

Title: 
Comparison of sentiment lexicon development techniques for event prediction
Abstract:
What started as a social utility for sharing short bursts of 'inconsequential information' has become a powerful information network capable of both tracking and shaping current events. From orchestrating government insurgencies to tracking epidemics, the majority of information shared via Twitter contains semantic relevance to contemporary topic(s), according to recent statistics. And, in consequence, Twitter is considered by researchers as an ideal platform for sentiment analysis. Compared to other online arenas such as forum discussions, blogs, and Facebook postings, Twitter frequently yields a higher degree of sentiment analysis accuracy due to the shortness of each post (140 character limit per Tweet). Various natural language processing techniques have been used to successfully perform sentiment classification on a group of Tweets. However, these techniques analyze text using both English-specific grammar rules and lexicons. Since there are fewer resources or tools in other languages, researchers often attempt to first use machine translation to translate the text into English. Often, translation errors introduce noise that obfuscates the results. In this study, we are analyzing the accuracy of sentiment analysis using an ad hoc and a translated sentiment lexicon in terms of capability of predicting the results of a future occurrence. We collected some 22,000 tweets using Twitter Search and Streaming APIs regarding a highly popular TV Show called "O Ses Turkiye" to predict the winner (Turkish version of globally known voice contest "The Voice of America"). We first performed a frequency-based statistical classification using an English sentiment lexicon translated into Turkish as well as a small ad hoc Turkish sentiment lexicon generated specifically for this study. We also use a k-means clustering technique using the two sentiment lexicons to evaluate the accuracies. Our study concludes that although using a translated sentiment lexicon (or training data for that matter) can also give a rough estimate for the result of a future event successfully, a language-specific ad hoc lexicon yields better granularity with higher discriminative power between negative, positive and neutral tweets. We also show the effect of automatic spell check and stemming in tweets on the predictive and discriminative power of auto-translated sentiment lexicon on a target language.

Title: 
Mining half a billion topical experts across multiple social networks
Abstract:
Mining topical experts on social media is a problem that has gained significant attention due to its wide-ranging applications. Here we present the first study that combines data from four major social networks-Twitter, Facebook, Google+ and LinkedIn-along with the Wikipedia graph and Internet webpage text and metadata, to rank topical experts across the global population of users. We perform an in-depth analysis of 37 features derived from various data sources such as message text, user lists, webpages, social graphs and Wikipedia. This large-scale study includes more than 12 billion messages over a 90-day sliding window and 58 billion social graph edges. Comparison reveals that features derived from Twitter Lists, Wikipedia, Internet webpages and Twitter Followers are especially good indicators of expertise. We train an expertise ranking model using these features on a large ground-truth dataset containing almost 90,000 labels. This model is applied within a production system that ranks over 650 million experts in more than 9000 topical domains on a daily basis. We provide results and examples on the effectiveness of our expert ranking system, along with empirical validation. Finally, we make the topical expertise data available through open REST APIs for wider use.

Title: 
eSAP: A decision support framework for enhanced sentiment analysis and polarity classification
Abstract:
Sentiment analysis or opinion mining is an imperative research area of natural language processing. It is used to determine the writer's attitude or speaker's opinion towards a particular person, product or topic. Polarity or subjectivity classification is the process of categorizing a piece of text into positive or negative classes. In recent years, various supervised and unsupervised methods have been presented to accomplish sentiment polarity detection. SentiWordNet (SWN) has been extensively used as a lexical resource for opinion mining. This research incorporates SWN as the labeled training corpus where the sentiment scores are extracted based on the part of speech information. A vocabulary SWN-V with revised sentiment scores, generated from SWN, is then used for Support Vector Machines model learning and classification process. Based on this vocabulary, a framework named "Enhanced Sentiment Analysis and Polarity Classification (eSAP)" is proposed. Training, testing and evaluation of the proposed eSAP are conducted on seven benchmark datasets from various domains. 10-fold cross validated accuracy, precision, recall, and f-measure results averaged over seven datasets for the proposed framework are 80.82%, 80.83%, 80.94% and 80.81% respectively. A notable performance improvement of 13.4% in accuracy, 14.2% in precision, 6.9% in recall and 11.1% in f-measure is observed on average by evaluating the proposed eSAP against the baseline SWN classifier. State of the art performance comparison is conducted which also verifies the superiority of the proposed eSAP framework. (C) 2016 Elsevier Inc. All rights reserved.

Title: 
Learning to extract adverse drug reaction events from electronic health records in Spanish
Abstract:
Objective: To tackle the extraction of adverse drug reaction events in electronic health records. The challenge stands in inferring a robust prediction model from highly unbalanced data. According to our manually annotated corpus, only 6% of the drug-disease entity pairs trigger a positive adverse drug reaction event and this low ratio makes machine learning tough. Method: We present a hybrid system utilising a self-developed morpho-syntactic and semantic analyser for medical texts in Spanish. It performs named entity recognition of drugs and diseases and adverse drug reaction event extraction. The event extraction stage operates using rule-based and machine learning techniques. Results: We assess both the base classifiers, namely a knowledge-based model and an inferred classifier, and also the resulting hybrid system. Moreover, for the machine learning approach, an analysis of each particular bio-cause triggering the adverse drug reaction is carried out. Conclusions: One of the contributions of the machine learning based system is its ability to deal with both intra-sentence and inter-sentence events in a highly skewed classification environment Moreover, the knowledge-based and the inferred model are complementary in terms of precision and recall. While the former provides high precision and low recall, the latter is the other way around. As a result, an appropriate hybrid approach seems to be able to benefit from both approaches and also improve them. This is the underlying motivation for selecting the hybrid approach. In addition, this is the first system dealing with real electronic health records in Spanish. (C) 2016 Elsevier Ltd. All rights reserved.

Title: 
Identification of category associations using a multilabel classifier
Abstract:
Description of the data using categories allows one to describe it on a higher abstraction level. In this way, we can operate on aggregated groups of the information, allowing one to see relationships that do not appear explicit when we analyze the individual objects separately. In this paper we present automatic identification of the associations between categories used for organization of the textual data. As experimental data we used a network of English Wikipedia articles and their associated categories, that have been preprocessed by a dedicated filtering method for noise reduction. The main contribution of the paper is the introduction of the method based on supervised machine learning for mining relations between these categories. We describe existing in the literature category proximity metrics as well as introduce three new ones, based on observing the properties of a multilabel Support Vector Machine classifier. The first metric uses classifier predictions, the second uses its errors, and the third is based on its model. Comparison to the existing state-of-the-art methods, and to manual assessments, confirm that the proposed methods are useful and are more flexible than typical approaches. We show how different metrics allow us to introduce new significant relations between categories. Aggregated results of mining categories' associations have been used to build a semantic network that shows a practical application of the research. The proposed method for finding associations can be extended with using other approaches than SVM classification, and can find (other than presented in the paper) applications for mining categories in text repositories. Eg.: it can be used for extending the prediction of the rating in recommender systems or as a method of missing data imputation. (C) 2016 Elsevier Ltd. All rights reserved.

Title: 
Investigating biofuels through network analysis
Abstract:
Biofuel policies are motivated by a plethora of political concerns related to energy security, environmental damages, and support of the agricultural sector. In response to this, much scientific work has chiefly focussed on analysing the biofuel domain and on giving policy advice and recommendations. Although innovation has been acknowledged as one of the key factors in sustainable and cost-effective biofuel development, there is an urgent need to investigate technological trajectories in the biofuel sector by starting from consistent data and appropriate methodological tools. To do so, this work proposes a procedure to select patent data unequivocally related to the investigated sector, it uses co-occurrence of technological terms to compute patent similarity and highlights content and interdependencies of biofuels technological trajectories by revealing hidden topics from unstructured patent text fields. The analysis suggests that there is a breaking trend towards modern generation biofuels and that innovators seem to focus increasingly on the ability of alternative energy sources to adapt to the transport/industrial sector. (C) 2016 Elsevier Ltd. All rights reserved.

Title: 
Comparative effect of company-driven SNS activity vs. consumer-driven SNS activity on firm value: Evidence from facebook
Abstract:
As mobile technology and social media have advanced, companies have become more and more motivated to make use of social network services (SNS) such as Facebook to increase future firm performance. Perusing the literature on the association between SNS and firm performance, we found very few empirical studies of the comparative effect of company-driven activity (e.g. posting) and consumer-driven activity (e.g. liking, commenting, sharing) on firm performance. Moreover, specific SNS activities affecting firm performance in the present, future, or both have not been explicitly identified. Hence, we developed an empirical model to identify and find differences between the effects of SNS activities on firm performance in the present (as measured by returns on investment) or future (as measured by Tobin's q) to improve our understanding of the impact of corporate SNS as a marketing channel. Text mining techniques are applied in this study to identify SNS activities from SNS data. The results suggest that SNS contributes significantly to future firm performance, as evidenced by increases in Tobin's q. Moreover, company-driven activities affect future value, while consumer-driven activities affect present value. Implications from these results are discussed. (C) 2016 Elsevier B.V. All rights reserved.

Title: 
Extracting and evaluating topics by region
Abstract:
Analyzing streaming data that contains regional information can derive the interest trends of a region and the differences from those of other regions. The results of analyzing regional differences can be used for making important decisions in areas such as regional marketing and national policy establishment. In this paper, we propose a method to extract topics that represent regional interests from news articles collected by region. The proposed method consists of a novel word-weighting step to extract regional keywords and a word-clustering step to extract regional topics based on the associations between the extracted keywords. The validity of the extracted regional topics is evaluated through a comparison with a ground-truth topic set. Since each topic is represented by a set of words, and a regional topic set is represented by a family of sets, we propose a new clustering validity index for families of sets for a given set of regions. Using the proposed clustering validity index, the optimal parameters for the collected data are presented through experiments.

Title: 
Analysis of effectiveness of tsunami evacuation principles in the 2011 Great East Japan tsunami by using text mining
Abstract:
Evacuation of the 2011 Great East Japan Earthquake and Tsunami was a large-scale evacuation of over thousands of people escaping from the earthquake-induced tsunami. The survivors' evacuation experiences provided valuable insights into the factors that helped with survival and some very important practical issues regarding tsunami evacuation. Therefore, this article analyzes an effectiveness of tsunami evacuation principles from descriptive comments from the survivors and the non-survivors in the 2011 disaster using text mining method. As a result using the Na < ve Bayesian classifier, it identifies some of the evacuation behaviors differences taken by the survivors or by the non-survivors under the disaster as an effectiveness of the evacuation principles, and attempts to understand how to provide more practical instructions. Therefore, these results give effective recommendations for evacuation preparation against catastrophic earthquake and tsunami disasters in the future.

Title: 
Challenges facing European agriculture and possible biotechnological solutions
Abstract:
Agriculture faces many challenges to maximize yields while it is required to operate in an environmentally sustainable manner. In the present study, we analyze the major agricultural challenges identified by European farmers (primarily related to biotic stresses) in 13 countries, namely Belgium, Bulgaria, the Czech Republic, France, Germany, Hungary, Italy, Portugal, Romania, Spain, Sweden, UK and Turkey, for nine major crops (barley, beet, grapevine, maize, oilseed rape, olive, potato, sunflower and wheat). Most biotic stresses (BSs) are related to fungi or insects, but viral diseases, bacterial diseases and even parasitic plants have an important impact on yield and harvest quality. We examine how these challenges have been addressed by public and private research sectors, using either conventional breeding, marker-assisted selection, transgenesis, cisgenesis, RNAi technology or mutagenesis. Both national surveys and scientific literature analysis followed by text mining were employed to evaluate genetic engineering (GE) and non-GE approaches. This is the first report of text mining of the scientific literature on plant breeding and agricultural biotechnology research. For the nine major crops in Europe, 128 BS challenges were identified with 40% of these addressed neither in the scientific literature nor in recent European public research programs. We found evidence that the private sector was addressing only a few of these neglected challenges. Consequently, there are considerable gaps between farmer's needs and current breeding and biotechnology research. We also provide evidence that the current political situation in certain European countries is an impediment to GE research in order to address these agricultural challenges in the future. This study should also contribute to the decision-making process on future pertinent international consortia to fill the identified research gaps.

Title: 
Unsupervised method for sentiment analysis in online texts
Abstract:
In recent years, the explosive growth of online media, such as blogs and social networking sites, has enabled individuals and organizations to write about their personal experiences and express opinions. Classifying these documents using a polarity metric is an arduous task. We propose a novel approach to predicting sentiment in online textual messages such as tweets and reviews, based on an unsupervised dependency parsing-based text classification method that leverages a variety of natural language processing techniques and sentiment features primarily derived from sentiment lexicons. These lexicons were created by means of a semiautomatic polarity expansion algorithm in order to improve accuracy in specific application domains. The results obtained for the Cornell Movie Review, Obama-McCain Debate and SemEval-2015 datasets confirm the competitive performance and the robustness of the system. (C) 2016 Elsevier Ltd. All rights reserved.

Title: 
Secure principal component analysis in multiple distributed nodes
Abstract:
Privacy preservation becomes an important issue in recent big data analysis, and many secure multiparty computations have been proposed for the purpose of privacy preservation in the environment of distributed nodes. As a secure multiparty computations of principal component analysis (PCA), in this paper, we propose S-PCA, which compute PCA securely among the distributed nodes. PCA is widely used in many applications including time-series analysis, text mining, and image compression. In general, we compute PCA after concentrating all data in a single server, but this approach discloses data privacy of each node. In contrast, the proposed S-PCA computes PCA without disclosing the sensitive data of individual nodes. In S-PCA, the nodes share non-sensitive mean vectors first and compute covariance matrices and PCA securely using the shared mean vectors. In this paper, we formally prove the correctness and secureness of S-PCA and apply it to an application of secure similar document detection. Experimental results show that the performance of S-PCA is slightly worse than that of PCA due to guarantee of secureness, but it significantly improves the performance of secure similar document detection by up to two orders of magnitudes. Copyright (c) 2016 John Wiley & Sons, Ltd.

Title: 
Trigger word mining for relation extraction based on activation force
Abstract:
In this paper, relation extraction is characterized as structured feature learning, and activation force (AF) is employed to extract and construct structured features. Trigger word is a low-level feature, and it is very crucial in relation extraction. We define the trigger word as a word that is most likely to form a structure corresponding to a special relation. To extract trigger words, firstly, posteriori probability weighted frequency AF model, in which AF is regarded as posteriori probability weighted frequency, is presented. Secondly, a generative AF is introduced. Then, a higher level structured feature, named trigger-word dependency pair (TWDP), is extracted by a reduced AF model. Based on the trigger words and TWDPs, the most advanced patterns, the shortest dependency paths (SDPs), are optimized. The evaluation corpus of Knowledge Base Population in Text Analysis Conference is adopted to test our methods. Experiments show that 87.30% of Stanford manual trigger words appearing in the training sentences can be found by G-AF. The experimental results also verified that the modified SDP patterns are superior to original SDP patterns. Copyright (c) 2014 John Wiley & Sons, Ltd.

Title: 
The environment ontology in 2016: bridging domains with increased scope, semantic density, and interoperation
Abstract:
Background: The Environment Ontology (ENVO; http://www.environmentontology.org/), first described in 2013, is a resource and research target for the semantically controlled description of environmental entities. The ontology's initial aim was the representation of the biomes, environmental features, and environmental materials pertinent to genomic and microbiome-related investigations. However, the need for environmental semantics is common to a multitude of fields, and ENVO's use has steadily grown since its initial description. We have thus expanded, enhanced, and generalised the ontology to support its increasingly diverse applications. Methods: We have updated our development suite to promote expressivity, consistency, and speed: we now develop ENVO in the Web Ontology Language (OWL) and employ templating methods to accelerate class creation. We have also taken steps to better align ENVO with the Open Biological and Biomedical Ontologies (OBO) Foundry principles and interoperate with existing OBO ontologies. Further, we applied text-mining approaches to extract habitat information from the Encyclopedia of Life and automatically create experimental habitat classes within ENVO. Results: Relative to its state in 2013, ENVO's content, scope, and implementation have been enhanced and much of its existing content revised for improved semantic representation. ENVO now offers representations of habitats, environmental processes, anthropogenic environments, and entities relevant to environmental health initiatives and the global Sustainable Development Agenda for 2030. Several branches of ENVO have been used to incubate and seed new ontologies in previously unrepresented domains such as food and agronomy. The current release version of the ontology, in OWL format, is available at http://purl.obolibrary.org/obo/envo.owl. Conclusions: ENVO has been shaped into an ontology which bridges multiple domains including biomedicine, natural and anthropogenic ecology, 'omics, and socioeconomic development. Through continued interactions with our users and partners, particularly those performing data archiving and sythesis, we anticipate that ENVO's growth will accelerate in 2017. As always, we invite further contributions and collaboration to advance the semantic representation of the environment, ranging from geographic features and environmental materials, across habitats and ecosystems, to everyday objects in household settings.

Title: 
A corpus for plant-chemical relationships in the biomedical domain
Abstract:
Background: Plants are natural products that humans consume in various ways including food and medicine. They have a long empirical history of treating diseases with relatively few side effects. Based on these strengths, many studies have been performed to verify the effectiveness of plants in treating diseases. It is crucial to understand the chemicals contained in plants because these chemicals can regulate activities of proteins that are key factors in causing diseases. With the accumulation of a large volume of biomedical literature in various databases such as PubMed, it is possible to automatically extract relationships between plants and chemicals in a large-scale way if we apply a text mining approach. A cornerstone of achieving this task is a corpus of relationships between plants and chemicals. Results: In this study, we first constructed a corpus for plant and chemical entities and for the relationships between them. The corpus contains 267 plant entities, 475 chemical entities, and 1,007 plant-chemical relationships (550 and 457 positive and negative relationships, respectively), which are drawn from 377 sentences in 245 PubMed abstracts. Inter-annotator agreement scores for the corpus among three annotators were measured. The simple percent agreement scores for entities and trigger words for the relationships were 99.6 and 94.8 %, respectively, and the overall kappa score for the classification of positive and negative relationships was 79.8 %. We also developed a rule- based model to automatically extract such plant-chemical relationships. When we evaluated the rule- based model using the corpus and randomly selected biomedical articles, overall F-scores of 68.0 and 61.8 % were achieved, respectively. Conclusion: We expect that the corpus for plant-chemical relationships will be a useful resource for enhancing plant research. The corpus is available at http://combio.gist.ac.kr/plantchemicalcorpus.

Title: 
A text feature-based approach for literature mining of lncRNA-protein interactions
Abstract:
Long non-coding RNAs (lncRNAs) play important roles in regulating transcriptional and post transcriptional levels. Currently, Knowledge of lncRNA and protein interactions (LPIs) is crucial for biomedical researches that are related to lncRNA. Many freshly discovered LPIs are stored in biomedical literature. With over one million new biomedical journal articles published every year, just keeping up with the novel finding requires automatically extracting information by text mining. To address this issue, we apply a text feature-based text mining approach to efficiently extract LPIs from biomedical literatures. Our approach consists of four steps. By employ natural language processing (NLP) technologies, this approach extracts text features from sentences that can precisely reflect the real LPIs. Our approach involves four steps including data collection, text pre-processing, structured representation, features extraction and training model and classification. The F-score performance of our approach achieves 79.5%, and the results indicate that the proposed approach can efficiently extract LPIs from biomedical literature. (C) 2016 Elsevier B.V. All rights reserved.

Title: 
Aspect extraction for opinion mining with a deep convolutional neural network
Abstract:
In this paper, we present the first deep learning approach to aspect extraction in opinion mining. Aspect extraction is a subtask of sentiment analysis that consists in identifying opinion targets in opinionated text, i.e., in detecting the specific aspects of a product or service the opinion holder is either praising or complaining about. We used a 7-layer deep convolutional neural network to tag each word in opinionated sentences as either aspect or non-aspect word. We also developed a set of linguistic patterns for the same purpose and combined them with the neural network. The resulting ensemble classifier, coupled with a word-embedding model for sentiment analysis, allowed our approach to obtain significantly better accuracy than state-of-the-art methods. (C) 2016 Elsevier B.V. All rights reserved.

Title: 
Contextual sentiment analysis for social media genres
Abstract:
The lexicon-based approaches to opinion mining involve the extraction of term polarities from sentiment lexicons and the aggregation of such scores to predict the overall sentiment of a piece of text. It is typically preferred where sentiment labelled data is difficult to obtain or algorithm robustness across different domains is essential. A major challenge for this approach is accounting for the semantic gap between prior polarities of terms captured by a lexicon and the terms' polarities in a specific context (contextual polarity). This is further exacerbated by the fact that a term's contextual polarity also depends on domains or genres in which it appears. In this paper, we introduce SmARTSA, a lexicon-based sentiment classification system for social media genres which integrates strategies to capture contextual polarity from two perspectives: the interaction of terms with their textual neighbourhood (local context) and text genre (global context). We introduce an approach to hybridise a general purpose lexicon, SentiWordNet, with genre-specific vocabulary and sentiment. Evaluation results from diverse social media show that our strategies to account for local and global contexts significantly improve sentiment classification, and are complementary in combination. Our system also performed significantly better, than a state-of-the-art sentiment classification system for social media, SENTISTRENGTH. (C) 2016 Elsevier B.V. All rights reserved.

Title: 
Back to the roots: A quantitative survey of herbal drugs in Dioscorides' De Materia Medica (ex Matthioli, 1568)
Abstract:
Background: De Materia Medica written by Pedanios Dioscorides (1 century CE) has shaped European and Mediterranean herbal medicine to a large extent. Despite its fundamental importance for modern medico-botanical traditions the content of this work has never been systematically assessed. Purpose: We present a quantitative survey of the botanical drugs described in De Materia Medica (ex Matthioli, 1568) and identify overall therapeutic, diachronic and botanical patterns. The extracted data may serve as a baseline and help to better contextualize research on herbal drugs and phytotherapy. Methods: Therapeutic uses of herbal drugs were extracted through line-by-line reading of a digitized version of the treatise. For each plant usage mentioned in the text we recorded (I) the chapter number, (II) the putative botanical identity, (III) the plant part, (IV) the symptoms or disease, (V) the mode of administration, (VI) our biomedical interpretation of the ancient ailment or disease description as well as (VII) the organ-and symptom-defined category under which the use was filed. Sections: An introduction to Dioscorides' De Materia Medica and Matthioli's Renaissance commentary is followed by a description of the employed methodology. The results and discussion section introduces the generated database comprising 5314 unique therapeutic uses of 536 plant taxa and 924 herbal drugs. Separate subsections address salient patterns such as the frequent recommendation of Fabaceae seeds for dermatology, Apiaceae seeds as antidotes and Apiaceae exudates for neurology and psychosomatic disorders as well as the heavy reliance on subterranean parts as drugs. Conclusions: The therapeutic knowledge described in De Materia Medica (ex Matthioli, 1568) offers unique insights into classical Mediterranean epidemiology and herbal medicine. Drugs that lost importance over time as well as remedies used for diseases now controlled by preventive medicine and industrially produced drugs may be interesting starting points for research on herbal medicine and drug discovery. Apart from promoting future data mining, the study may also help to prove the tradition of use, which is required for the regulatory approval of certain herbal products. (C) 2016 Elsevier GmbH. All rights reserved.

Title: 
Ensemble of keyword extraction methods and classifiers in text classification
Abstract:
Automatic keyword extraction is an important research direction in text mining, natural language processing and information retrieval. Keyword extraction enables us to represent text documents in a condensed way. The compact representation of documents can be helpful in several applications, such as automatic indexing, automatic summarization, automatic classification, clustering and filtering. For instance, text classification is a domain with high dimensional feature space challenge. Hence, extracting the most important/relevant words about the content of the document and using these keywords as the features can be extremely useful. In this regard, this study examines the predictive performance of five statistical keyword extraction methods (most frequent measure based keyword extraction, term frequency-inverse sentence frequency based keyword extraction, co-occurrence statistical information based keyword extraction, eccentricity-based keyword extraction and TextRank algorithm) on classification algorithms and ensemble methods for scientific text document classification (categorization). In the study, a comprehensive study of comparing base learning algorithms (Naive Bayes, support vector machines, logistic regression and Random Forest) with five widely utilized ensemble methods (AdaBoost, Bagging, Dagging, Random Subspace and Majority Voting) is conducted. To the best of our knowledge, this is the first empirical analysis, which evaluates the effectiveness of statistical keyword extraction methods in conjunction with ensemble learning algorithms. The classification schemes are compared in terms of classification accuracy, F-measure and area under curve values. To validate the empirical analysis, two-way ANOVA test is employed. The experimental analysis indicates that Bagging ensemble of Random Forest with the most-frequent based keyword extraction method yields promising results for text classification. For ACM document collection, the highest average predictive performance (93.80%) is obtained with the utilization of the most frequent based keyword extraction method with Bagging ensemble of Random Forest algorithm. In general, Bagging and Random Subspace ensembles of Random Forest yield promising results. The empirical analysis indicates that the utilization of keyword-based representation of text documents in conjunction with ensemble learning can enhance the predictive performance and scalability of text classification schemes, which is of practical importance in the application fields of text classification. (C) 2016 Elsevier Ltd. All rights reserved.

Title: 
Futuristic data-driven scenario building: Incorporating text mining and fuzzy association rule mining into fuzzy cognitive map
Abstract:
Fuzzy cognitive maps (FCMs) are one of the representative techniques in developing scenarios that include future concepts and issues, as well as their causal relationships. The technique, initially dependent on deductive modeling of expert knowledge, suffered from inherent limitations of scope and subjectivity; though this lack has been partially addressed by the recent emergence of inductive modeling, the fact that inductive modeling uses a retrospective, historical data that often misses trend-breaking developments. Addressing this issue, the paper suggests the utilization of futuristic data, a collection of future-oriented opinions extracted from online communities of large participation, in scenario building. Because futuristic data is both large in scope and prospective in nature, we believe a methodology based on this particular data set addresses problems of subjectivity and myopia suffered by the previous modeling techniques. To this end, text mining (TM) and latent semantic analysis (LSA) algorithm are applied to extract scenario concepts from futuristic data in textual documents; and fuzzy association rule mining (FARM) technique is utilized to identify their causal weights based on if-then rules. To illustrate the utility of proposed approach, a case of electric vehicle is conducted. The suggested approach can improve the effectiveness and efficiency of scanning knowledge for scenario development. (C) 2016 Elsevier Ltd. All rights reserved.

Title: 
Question-driven topic-based extraction of Protein-Protein Interaction Methods from biomedical literature
Abstract:
This paper proposes a novel topic-based model for identifying experimental mentions of Protein-Protein Interaction Method (PPIM) in the biomedical literature. The model combines topic-based classification models and some basic question-answering extraction techniques aiming at effectively detecting and identifying PPIM mentions on Protein-Protein Interactions. Unlike other state-of-the-art approaches, the approach captures underlying relationships within both input and output concept spaces by assuming the extraction task to be strongly driven by context provided by experts, usually in the form of a question to guide the search. Results indicate our topic-based question-driven approach obtained better results than other unsupervised learning probabilistic latent space models for detecting correct answers (PPIM mentions). (C) 2016 Elsevier Inc. All rights reserved.

Title: 
Gene Ontology synonym generation rules lead to increased performance in biomedical concept recognition
Abstract:
Background: Gene Ontology (GO) terms represent the standard for annotation and representation of molecular functions, biological processes and cellular compartments, but a large gap exists between the way concepts are represented in the ontology and how they are expressed in natural language text. The construction of highly specific GO terms is formulaic, consisting of parts and pieces from more simple terms. Results: We present two different types of manually generated rules to help capture the variation of how GO terms can appear in natural language text. The first set of rules takes into account the compositional nature of GO and recursively decomposes the terms into their smallest constituent parts. The second set of rules generates derivational variations of these smaller terms and compositionally combines all generated variants to form the original term. By applying both types of rules, new synonyms are generated for two-thirds of all GO terms and an increase in F-measure performance for recognition of GO on the CRAFT corpus from 0.498 to 0.636 is observed. Additionally, we evaluated the combination of both types of rules over one million full text documents from Elsevier; manual validation and error analysis show we are able to recognize GO concepts with reasonable accuracy (88 %) based on random sampling of annotations. Conclusions: In this work we present a set of simple synonym generation rules that utilize the highly compositional and formulaic nature of the Gene Ontology concepts. We illustrate how the generated synonyms aid in improving recognition of GO concepts on two different biomedical corpora. We discuss other applications of our rules for GO ontology quality assurance, explore the issue of overgeneration, and provide examples of how similar methodologies could be applied to other biomedical terminologies. Additionally, we provide all generated synonyms for use by the text-mining community.

Title: 
Automatic classification of communication logs into implementation stages via text analysis
Abstract:
Background: To improve the quality, quantity, and speed of implementation, careful monitoring of the implementation process is required. However, some health organizations have such limited capacity to collect, organize, and synthesize information relevant to its decision to implement an evidence-based program, the preparation steps necessary for successful program adoption, the fidelity of program delivery, and the sustainment of this program over time. When a large health system implements an evidence-based program across multiple sites, a trained intermediary or broker may provide such monitoring and feedback, but this task is labor intensive and not easily scaled up for large numbers of sites. We present a novel approach to producing an automated system of monitoring implementation stage entrances and exits based on a computational analysis of communication log notes generated by implementation brokers. Potentially discriminating keywords are identified using the definitions of the stages and experts' coding of a portion of the log notes. A machine learning algorithm produces a decision rule to classify remaining, unclassified log notes. Results: We applied this procedure to log notes in the implementation trial of multidimensional treatment foster care in the California 40-county implementation trial (CAL-40) project, using the stages of implementation completion (SIC) measure. We found that a semi-supervised non-negative matrix factorization method accurately identified most stage transitions. Another computational model was built for determining the start and the end of each stage. Conclusions: This automated system demonstrated feasibility in this proof of concept challenge. We provide suggestions on how such a system can be used to improve the speed, quality, quantity, and sustainment of implementation. The innovative methods presented here are not intended to replace the expertise and judgement of an expert rater already in place. Rather, these can be used when human monitoring and feedback is too expensive to use or maintain. These methods rely on digitized text that already exists or can be collected with minimal to no intrusiveness and can signal when additional attention or remediation is required during implementation. Thus, resources can be allocated according to need rather than universally applied, or worse, not applied at all due to their cost.

Title: 
BioCreative V BioC track overview: collaborative biocurator assistant task for BioGRID
Abstract:
BioC is a simple XML format for text, annotations and relations, and was developed to achieve interoperability for biomedical text processing. Following the success of BioC in BioCreative IV, the BioCreative V BioC track addressed a collaborative task to build an assistant system for BioGRID curation. In this paper, we describe the framework of the collaborative BioC task and discuss our findings based on the user survey. This track consisted of eight subtasks including gene/protein/organism named entity recognition, protein-protein/genetic interaction passage identification and annotation visualization. Using BioC as their data-sharing and communication medium, nine teams, world-wide, participated and contributed either new methods or improvements of existing tools to address different subtasks of the BioC track. Results from different teams were shared in BioC and made available to other teams as they addressed different subtasks of the track. In the end, all submitted runs were merged using a machine learning classifier to produce an optimized output. The biocurator assistant system was evaluated by four BioGRID curators in terms of practical usability. The curators' feedback was overall positive and highlighted the user-friendly design and the convenient gene/protein curation tool based on text mining.

Title: 
Overview of the interactive task in BioCreative V
Abstract:
Fully automated text mining (TM) systems promote efficient literature searching, retrieval, and review but are not sufficient to produce ready-to-consume curated documents. These systems are not meant to replace biocurators, but instead to assist them in one or more literature curation steps. To do so, the user interface is an important aspect that needs to be considered for tool adoption. The BioCreative Interactive task (IAT) is a track designed for exploring user-system interactions, promoting development of useful TM tools, and providing a communication channel between the biocuration and the TM communities. In BioCreative V, the IAT track followed a format similar to previous interactive tracks, where the utility and usability of TM tools, as well as the generation of use cases, have been the focal points. The proposed curation tasks are user-centric and formally evaluated by biocurators. In BioCreative V IAT, seven TM systems and 43 biocurators participated. Two levels of user participation were offered to broaden curator involvement and obtain more feedback on usability aspects. The full level participation involved training on the system, curation of a set of documents with and without TM assistance, tracking of time-on-task, and completion of a user survey. The partial level participation was designed to focus on usability aspects of the interface and not the performance per se. In this case, biocurators navigated the system by performing pre-designed tasks and then were asked whether they were able to achieve the task and the level of difficulty in completing the task. In this manuscript, we describe the development of the interactive task, from planning to execution and discuss major findings for the systems tested.

Title: 
Extracting information from the text of electronic medical records to improve case detection: a systematic review
Abstract:
Background Electronic medical records (EMRs) are revolutionizing health-related research. One key issue for study quality is the accurate identification of patients with the condition of interest. Information in EMRs can be entered as structured codes or unstructured free text. The majority of research studies have used only coded parts of EMRs for case-detection, which may bias findings, miss cases, and reduce study quality. This review examines whether incorporating information from text into case-detection algorithms can improve research quality. Methods A systematic search returned 9659 papers, 67 of which reported on the extraction of information from free text of EMRs with the stated purpose of detecting cases of a named clinical condition. Methods for extracting information from text and the technical accuracy of case-detection algorithms were reviewed. Results Studies mainly used US hospital-based EMRs, and extracted information from text for 41 conditions using keyword searches, rule-based algorithms, and machine learning methods. There was no clear difference in case-detection algorithm accuracy between rule-based and machine learning methods of extraction. Inclusion of information from text resulted in a significant improvement in algorithm sensitivity and area under the receiver operating characteristic in comparison to codes alone (median sensitivity 78% (codes + text) vs 62% (codes), P = .03; median area under the receiver operating characteristic 95% (codes + text) vs 88% (codes), P = .025). Conclusions Text in EMRs is accessible, especially with open source information extraction algorithms, and significantly improves case detection when combined with codes. More harmonization of reporting within EMR studies is needed, particularly standardized reporting of algorithm accuracy metrics like positive predictive value (precision) and sensitivity (recall).

Title: 
Optimization Methods in Emotion Recognition System
Abstract:
Emotions play big role in our everyday communication and contain important information. This work describes a novel method of automatic emotion recognition from textual data. The method is based on well-known data mining techniques, novel approach based on parallel run of SVM (Support Vector Machine) classifiers, text preprocessing and 3 optimization methods: sequential elimination of attributes, parameter optimization based on token groups, and method of extending train data sets during practical testing and production release final tuning. We outperformed current state of the art methods and the results were validated on bigger data sets (3346 manually labelled samples) which is less prone to overfitting when compared to related works. The accuracy achieved in this work is 86.89 % for recognition of 5 emotional classes. The experiments were performed in the real world helpdesk environment, was processing Czech language but the proposed methodology is general and can be applied to many different languages.

Title: 
C-BiLDA extracting cross-lingual topics from non-parallel texts by distinguishing shared from unshared content
Abstract:
Conference Conference: European Conference on Machine Learning and Principles and Practice of Knowledge Discovery Location: Riva del Garda, ITALY Date: SEP 19-23, 2016

Title: 
Understanding the evolving academic landscape of library and information science through faculty hiring data
Abstract:
Using a 40-year (from 1975 to 2015) hiring dataset of 642 library and Information science (LIS) faculty members from 44 US universities, this research reveals the disciplinary characteristics of LIS through several key aspects including gender, rank, country, university, major, and research area. Results show that genders and ranks among LIS faculty members are evenly distributed; geographically, more than 90 % of LIS faculty members received doctoral degrees in the US; meanwhile, 60 % of LIS faculty received Ph.D. in LIS, followed by Computer Science and Education; in regards to research interests, Human-Computer interaction, Digital Librarianship, Knowledge Organization and Management, and Information Behavior are the most popular research areas among LIS faculty members. Through a series of dynamic analyses, this study shows that the educational background of LIS faculty members is becoming increasingly diverse; in addition, research areas such as Human-Computer interaction, Social Network Analysis, Services for Children and Youth, Information Literacy, Information Ethics and Policy, and Data and Text Mining, Natural Language Processing, Machine Learning have received an increasing popularity. Predictive analyses are performed to discover trends on majors and research areas. Results show that the growth rate of LIS faculty members is linearly distributed. In addition, among faculty member's Ph.D. majors, the share of LIS is decreasing while that the share of Computer Science is growing; among faculty members' research areas, the share of Human-Computer interaction is on the rise.

Title: 
Hierarchical classification in text mining for sentiment analysis of online news
Abstract:
Conference Conference: 1st International Conference on Soft Computing and Machine Intelligence (ISCMI) Location: New Delhi, INDIA Date: 2014

Title: 
A comparison study of clustering algorithms for microblog posts
Abstract:
Clustering is a popular unsupervised learning approach for topic analysis in text mining. In this paper, we do a comparison study of clustering algorithms for microblog posts, including weighting and programming model. Our experimental data is crawled from Sina Weibo in China. They are the 74,662 microblogs of 14 topics about Internet Technology. First of all, we do preprocessing to these microblog posts. Then we propose a manual sampling based dynamic incremental clustering algorithm (MS-DICA) to extract the topic threads from the microblogs we crawled. We evaluate the proposed algorithm from four aspects. Moreover, experimental comparisons are done in terms of accuracy and efficiency with the traditional k-means algorithm. Our experimental results show that the proposed MS-DICA is effective in the topic thread extraction. Its accuracy is close to the traditional k-means algorithm, and the running speed improves more than five times. In addition, the MapReduce programming model in Hadoop distributed computation platform that can run paralleled the k-means algorithm for cluster speeding up.

Title: 
Building associated semantic representation model for the ultra-short microblog text jumping in big data
Abstract:
In the massive microblog texts, the ultra-short microblog text is difficult to be independently understood because of its special characteristics such as data sparseness, content fragmentation and so on. To solve this problem, this paper presents an associated semantic representation model for the ultra-short microblog text (ASRM-UMT) to help users understand it better. First, multi-layer associated semantic views of the ultra-short microblog text are built. The ICTCLAS system is adopted to extract the feature keywords from microblog texts. The mining algorithm of associated semantic on a dynamic time window is proposed to mine the associated semantic relations among the feature keywords. The mining process has deeply considered three aspects including context, comments and transmissions of microblog texts. Then, multi-layer associated semantic views of the ultra-short microblog text are optimized. The comparison of the clustering coefficients among several multi-layer associated semantic views is presented to select the optimal associated semantic view. Experimental results show that the proposed model can represent the ultra-short microblog text accurately and effectively.

Title: 
A multi-level text representation model within background knowledge based on human cognitive process for big data analysis
Abstract:
Text representation is part of the most fundamental work in text comprehension, processing, and search. Various kinds of work has been proposed to mine the semantics in texts and then to represent them. However, most of them only focus on how to mine semantics from the text itself, while few of them take the background knowledge into consideration, which is very important to text understanding. In this paper, on the basis of human cognitive process, we propose a multi-level text representation model within background knowledge, called TRMBK. It is composed of three levels, which are machine surface code, machine text base and machine situational model. All of them are able to be constructed automatically to acquire semantics both inside and outside of the texts. Simultaneously, we also propose a method to establish background knowledge automatically and offer supports for the current text comprehension. Finally, experiments and comparisons have been presented to show the better performance of TRMBK.

Title: 
The effects of leadership by types of soccer instruction on big data analysis
Abstract:
The purpose of the present study is to figure out football coaches' leadership styles. So far, numerous of coaches have coached South Korea's national team. Compared to other countries, the Korea Republic national team has changed coaches relatively often. In particular, owing to the result-centric Korean culture, if the national team had deplorable results in a specific match, the head coach would be fired right away. Of course, there were some successful and popular coaches. However, many other coaches ended up in a failure in the Korean national team. Therefore, there must be a difference in leadership styles between the successful and unsuccessful coaches. In this context, it would be critical to find out the traits of the successful coaches' leadership. Using text-mining techniques, the present study aims to establish different leadership type of football coaches. To this end, we analyzed the South Korean national football team coaches' leadership styles using text-mining techniques applied to the analysis of NAVER news. Our results suggest that successful leaders have important leadership elements, such as communication, trust, and belief.

Title: 
Highlighting Relationships of a Smartphone's Social Ecosystem in Potentially Large Investigations
Abstract:
Social media networks are becoming increasingly popular because they can satisfy diverse needs of individuals (both personal and professional). Modern mobile devices are empowered with increased capabilities, taking advantage of the technological progress that makes them smarter than their predecessors. Thus, a smartphone user is not only the phone owner, but also an entity that may have different facets and roles in various social media networks. We believe that these roles can be aggregated in a single social ecosystem, which can be derived by the smartphone. In this paper, we present our concept of the social ecosystem in contemporary devices and we attempt to distinguish the different communities that occur from the integration of social networking in our lives. In addition, we propose techniques to highlight major actors within the ecosystem. Moreover, we demonstrate our suggested visualization scheme, which illustrates the linking of entities that live in separate communities using data taken from the smartphone. Finally, we extend our concept to include various parallel ecosystems during potentially large investigations and we link influential entities in a vertical fashion. We particularly examine cases where data aggregation is performed by specific applications, producing volumes of textual data that can be analyzed with text mining methods. Our analysis demonstrates the risks of the rising "bring your own device" trend in enterprise environments.

Title: 
Helmholtz principle based supervised and unsupervised feature selection methods for text mining
Abstract:
One of the important problems in text classification is the high dimensionality of the feature space. Feature selection methods are used to reduce the dimensionality of the feature space by selecting the most valuable features for classification. Apart from reducing the dimensionality, feature selection methods have potential to improve text classifiers' performance both in terms of accuracy and time. Furthermore, it helps to build simpler and as a result more comprehensible models. In this study we propose new methods for feature selection from textual data, called Meaning Based Feature Selection (MBFS) which is based on the Helmholtz principle from the Gestalt theory of human perception which is used in image processing. The proposed approaches are extensively evaluated by their effect on the classification performance of two well-known classifiers on several datasets and compared with several feature selection algorithms commonly used in text mining. Our results demonstrate the value of the MBFS methods in terms of classification accuracy and execution time. (C) 2016 Elsevier Ltd. All rights reserved.

Title: 
Mining contentious documents
Abstract:
This work proposes an unsupervised method intended to enhance the quality of opinion mining in contentious text. It presents a Joint Topic Viewpoint (JTV) probabilistic model to analyze the underlying divergent arguing expressions that may be present in a collection of contentious documents. It extends the original Latent Dirichlet Allocation, which makes it domain and thesaurus independent, e.g., does not rely on WordNet coverage. The conceived JTV has the potential of automatically carrying the tasks of extracting associated terms denoting an arguing expression, according to the hidden topics it discusses and the embedded viewpoint it voices. Furthermore, JTV's structure enables the unsupervised grouping of obtained arguing expressions according to their viewpoints, using a constrained clustering approach. Experiments are conducted on three types of contentious documents: polls, online debates and editorials. The qualitative and quantitative analyses of the experimental results show the effectiveness of our model to handle six different contentious issues when compared to a state-of-the-art method. Moreover, the ability to automatically generate distinctive and informative patterns of arguing expressions is demonstrated. Furthermore, the coherence of these arguing expressions is proved to be of a high quality when evaluated on the basis of recently introduced automatic coherence measure.

Title: 
Combined new nonnegative matrix factorization algorithms with two-dimensional nonnegative matrix factorization for image processing
Abstract:
In recent years, nonnegative matrix factorization (NMF) has attracted significant amount of attentions in image processing, text mining, speech processing and related fields. Although NMF has been applied in several application successfully, its simple application on image processing has a few caveats. For example, NMF costs considerable computational resources when performing on large databases. In this paper, we propose two enhanced NMF algorithms for image processing to save the computational costs. One is modified rank-one residue iteration (MRRI) algorithm, the other is element-wisely residue iteration (ERI) algorithm. Here we combine CAPG (a NMF algorithm proposed by Lin), MRRI and ERI with two-dimensional nonnegative matrix factorization (2DNMF) for image processing. The main difference between NMF and 2DNMF is that the former first aligns images into one-dimensional (1D) vectors and then represents them with a set of 1D bases, while the latter regards images as 2D matrices and represents them with a set of 2D bases. The three combined algorithms are named CAPG-2DNMF, MRRI-2DNMF and ERI-2DNMF. The computational complexity and convergence analyses of proposed algorithms are also presented in this paper. Three public databases are used to test the three NMF algorithms and the three combinations, the results of which show the enhancement performance of our proposed algorithms (MRRI and ERI algorithms) over the CAPG algorithm. MRRI and ERI have similar performance. The three combined algorithms have better image reconstruction quality and less running time than their corresponding 1DNMF algorithms under the same compression ratio. We also do some experiments on a real-captured image database and get similar conclusions.

Title: 
Representation learning for very short texts using weighted word embedding aggregation
Abstract:
Short text messages such as tweets are very noisy and sparse in their use of vocabulary. Traditional textual representations, such as tf-idf, have difficulty grasping the semantic meaning of such texts, which is important in applications such as event detection, opinion mining, news recommendation, etc. We constructed a method based on semantic word embeddings and frequency information to arrive at low-dimensional representations for short texts designed to capture semantic similarity. For this purpose we designed a weight-based model and a learning procedure based on a novel median-based loss function. This paper discusses the details of our model and the optimization methods, together with the experimental results on both Wikipedia and Twitter data. We find that our method outperforms the baseline approaches in the experiments, and that it generalizes well on different word embeddings without retraining. Our method is therefore capable of retaining most of the semantic information in the text, and is applicable out-of-the-box. (C) 2016 Elsevier B.V. All rights reserved.

Title: 
Prevalence, survival analysis and multimorbidity of chronic diseases in the general veterinarian-attended horse population of the UK
Abstract:
The average age of the global human population is increasing, leading to increased interest in the effects of chronic disease and multimorbidity on health resources and patient welfare. It has been posited that the average age of the general veterinarian-attended horse population of the UK is also increasing, and therefore it could be assumed that chronic diseases and multimorbidity would pose an increasing risk here also. However, evidence for this trend in ageing is very limited, and the current prevalence of many chronic diseases, and of multimorbidity, is unknown. Using text mining of first-opinion electronic medical records from seven veterinary practices around the UK, Kaplan-Meier and Cox proportional hazard modelling, we were able to estimate the apparent prevalence among veterinarian-attended horses of nine chronic diseases, and to assess their relative effects on median life expectancy following diagnosis. With these methods we found evidence of increasing population age. Multimorbidity affected 1.2% of the study population, and had a significant effect upon survival times, with co-occurrence of two diseases, and three or more diseases, leading to 6.6 and 21.3 times the hazard ratio compared to no chronic disease, respectively. Laminitis was involved in 74% of cases of multimorbidity. The population of horses attended by UK veterinarians appears to be aging, and chronic diseases and their co-occurrence are common features, and as such warrant further investigation. (C) 2016 The Authors. Published by Elsevier B.V.

Title: 
Technology roadmapping for competitive technical intelligence
Abstract:
Understanding the evolution and emergence of technology domains remains a challenge, particularly so for potentially breakthrough technologies. Though it is well recognized that emergence of new fields is complex and uncertain, to make decisions amidst such uncertainty, one needs to mobilize various sources of intelligence to identify known-knowns and known-unknowns to be able to choose appropriate strategies and policies. This competitive technical intelligence cannot rely on simple trend analyses because breakthrough technologies have little past to inform such trends, and positing the directions of evolution is challenging. Neither do qualitative tools, embracing the complexities, provide all the solutions, since transparent and repeatable techniques need to be employed to create best practices and evaluate the intelligence that comes from such exercises. In this paper, we present a hybrid roadmapping technique that draws on a number of approaches and integrates them into a multi-level approach (individual activities, industry evolutions and broader global changes) that can be applied to breakthrough technologies. We describe this approach in deeper detail through a case study on dye-sensitized solar cells. Our contribution to this special issue is to showcase the technique as part of a family of approaches that are emerging around the world to inform strategy and policy. (C) 2015 Elsevier Inc. All rights reserved.

Title: 
AIDS as social construction: text mining of AIDS-related information in the Italian press
Abstract:
Given the relevance of AIDS as a public health problem in the Italian context and of the role of mass media in the social construction of the phenomenon, the aim of the present study is twofold: (1) to explore the main AIDS-related themes in the Italian popular press; (2) to analyse the temporal trends of AIDS representations over the last decades. For the research, we decided to consult Italian newspaper articles produced between 1985 and 1990 and between 2005 and 2010 using the archives of the main two national newspapers (La Repubblica and Corriere della Sera), resulting in an overall sample of 446 newspaper articles. A computer-aided content analysis allowed the detection of five different thematic domains (clusters), respectively focused on: Medical care (7.47%), Family support (37.03%), Science and religion debate (27%), Social exclusion (17.6%) and Healthcare policies (10.9%). These thematic domains are conceived along two main latent dimensions (factors) which explain 72.47% of the data variance which respectively deal with: (1) Attitudes towards people with AIDS (care versus avoidance) and (2) Social mandate on AIDS (powerlessness versus control). The study results also reveal the potential evolution of representations of people with AIDS over time: from stigmatised subjects who represent a risk for the entire society within a climate of social control to people progressively symbolised as frail subjects that need to be taken care of.

Title: 
The added value of auxiliary data in sentiment analysis of Facebook posts
Abstract:
The purpose of this study is to (1) assess the added value of information available before (i.e., leading) and after (i.e., lagging) the focal post's creation time in sentiment analysis of Facebook posts, (2) determine which predictors are most important, and (3) investigate the relationship between top predictors and sentiment. We build a sentiment prediction model, including leading information, lagging information, and traditional post variables. We benchmark Random Forest and Support Vector Machines using five times twofold cross validation. The results indicate that both leading and lagging information increase the model's predictive performance. The most important predictors include the number of uppercase letters, the number of likes and the number of negative comments. A higher number of uppercase letters and likes increases the likelihood of a positive post, while a higher number of comments increases the likelihood of a negative post. The main contribution of this study is that it is the first to assess the added value of leading and lagging information in the context of sentiment analysis. (C) 2016 Elsevier B.V. All rights reserved.

Title: 
An Evaluation Analysis on Three-Wheeled Personal Mobility Vehicles
Abstract:
Personal mobility vehicles are proposed as a new category of transportation device that offers several potential benefits to solve the current problems, such as mobility issues of the elderly, downtown area revitalization, and development of low-carbon transport. This paper aims to explore basic attitude of the general public to understand how people think about three-wheeled personal mobility vehicles. Using the surveys data on i-REAL conducted in Toyota, a discussion is made by employing Quantification Theory and Semantic Differential Method. Moreover, textual data derived from the survey are classified by applying Text Mining. Furthermore, conclusions are drawn and suggestions for further work are made. As a conclusion from the comparative analysis between the unexperienced and experienced groups, the experience brings people to make different evaluations so that the test rides are very important to know the true answers. The analysis on the experienced people shows that the elderly highly evaluated the hobby factors, the male highly evaluated the practice factors and the weather condition seems being a key factor for the current model.

Title: 
A Computational Protein Phenotype Prediction Approach to Analyze the Deleterious Mutations of Human MED12 Gene
Abstract:
Genetic mutations in MED12, a subunit of Mediator complex are seen in a broad spectrum of human diseases. However, the underlying basis of how these pathogenic mutations elicit protein phenotype changes in terms of 3D structure, stability and protein binding sites remains unknown. Therefore, we aimed to investigate the structural and functional impacts of MED12 mutations, using computational methods as an alternate to traditional in vivo and in vitro approaches. The MED12 gene mutations details and their corresponding clinical associations were collected from different databases and by text-mining. Initially, diverse computational approaches were applied to categorize the different classes of mutations based on their deleterious impact to MED12. Then, protein structures for wild and mutant types built by integrative modeling were analyzed for structural divergence, solvent accessibility, stability, and functional interaction deformities. Finally, this study was able to identify that genetic mutations mapped to exon-2 region, highly conserved LCEWAV and Catenin domains induce biochemically severe amino acid changes which alters the protein phenotype as well as the stability of MED12-CYCC interactions. To better understand the deleterious nature of FS-IDs and Indels, this study asserts the utility of computational screening based on their propensity towards non-sense mediated decay. Current study findings may help to narrow down the number of MED12 mutations to be screened for mediator complex dysfunction associated genetic diseases. This study supports computational methods as a primary filter to verify the plausible impact of pathogenic mutations based on the perspective of evolution, expression and phenotype of proteins. J. Cell. Biochem. 117: 2023-2035, 2016. (c) 2016 Wiley Periodicals, Inc.

Title: 
Using NLP Approach for Opinion Types Classifier
Abstract:
Information that are represented as text are either facts or opinions, whenever we need to make a decision, we often seek out the opinions of others which is one of the most influencing factors for our decisions. Traditionally, individuals can get opinions from friends and family while organizations use surveys, focus groups, opinion polls and consultants. Nowadays, opinions expressed through user generated content are considered as one of the important types of information which is available on the web, therefore, many resources have been emerged for expressing opinions including social media and others. This situation has revealed the necessity for robust, flexible Information Extraction (IE) systems, these systems have the availability to transform the web pages into program-friendly structures such as a relational database to reveal these opinions. In this paper, we propose an approach to classify the opinions of a document or a set of documents considering an object. The approach has been implemented and applied on a dataset of opinions. The proposed system discover the opinions provided for an object in a document or set of documents. The system discovers different types of opinionated statements, including the opinionated, comparative, superlative, and non-opinionated. The system has been applied on a set of 4000 sentences, and the results has been evaluated using the standard metrics, they are True positive, True negative, False positive, False negative, Precision, Recall, and F-score. We also provided a comparison of the presented work with previous work that has been presented in the same field.

Title: 
AutoQuery: automatic construction of dependency queries for code search
Abstract:
Many code search techniques have been proposed to return relevant code for a user query expressed as textual descriptions. However, source code is not mere text. It contains dependency relations among various program elements. To leverage these dependencies for more accurate code search results, techniques have been proposed to allow user queries to be expressed as control and data dependency relationships among program elements. Although such techniques have been shown to be effective for finding relevant code, it remains a question whether appropriate queries can be generated by average users. In this work, we address this concern by proposing a technique, AutoQuery, that can automatically construct dependency queries from a set of code snippets. We realize AutoQuery by the following major steps: firstly, code snippets (that are not necessarily compilable) are converted into program dependence graphs (PDGs); secondly, a new graph mining solution is built to return common structures in the PDGs; thirdly, the common structures are converted to dependency queries, which are used to retrieve results by using a dependence-based code search technique. We have evaluated AutoQuery on real systems with 47 different code search tasks. The results show that the automatically constructed dependency queries retrieve relevant code with a precision, recall, and F-measure of 68.4, 72.1, and 70.2 %, respectively. We have also performed a user study to compare the effectiveness of AutoQuery with that of human generated queries. The results show that queries constructed by AutoQuery on average help to retrieve code fragments with comparable F-measures to those retrieved by human constructed queries.

