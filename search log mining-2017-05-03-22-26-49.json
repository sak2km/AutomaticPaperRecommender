[{"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396178500001 PubMed ID: 28361034 ISSN: 2234-943X","Keywords":"prostate cancer; retinoic acid; prognosis; systems biology; The Cancer Genome Atlas; data mining KeyWords Plus:ALDH1 ISOENZYMES; SYSTEMS BIOLOGY; BREAST-CANCER; HETEROGENEITY; COMPLEXITY; PROGNOSIS; NETWORKS","Categories":"Oncology Web of Science Categories:Oncology","Journal Information":"FRONTIERS IN ONCOLOGY Volume: 7 Article Number: 30 DOI: 10.3389/fonc.2017.00030 Published: MAR 15 2017","Abstract":"Background: Quantitative high-throughput data deposited in consortia such as International Cancer Genome Consortium (ICGC) and The Cancer Genome Atlas (TCGA) present opportunities and challenges for computational analyses. Methods: We present a computational strategy to systematically rank and investigate a large number (210-220) of clinically testable gene sets, using combinatorial gene subset generation and disease-free survival (DFS) analyses. This approach integrates protein-protein interaction networks, gene expression, DNA methylation, and copy number data, in association with DFS profiles from patient clinical records. Results: As a case study, we applied this pipeline to systematically analyze the role of ALDH1A2 in prostate cancer (PCa). We have previously found this gene to have multiple roles in disease and homeostasis, and here we investigate the role of the associated ALDH1A2 gene/protein networks in PCa, using our methodology in combination with PCa patient clinical profiles from ICGC and TCGA databases. Relationships between gene signatures and relapse were analyzed using Kaplan-Meier (KM) log-rank analysis and multivariable Cox regression. Relative expression versus pooled mean from diploid population was used for z-statistics calculation. Gene/protein interaction network analyses generated 11 core genes associated with ALDH1A2; combinatorial ranking of the power set of these core genes identified two gene sets (out of 2(11)-1= 2,047 combinations) with significant correlation with disease relapse (KM log rank p < 0.05). For the more significant of these two sets, referred to as the optimal gene set (OGS), patients have median survival 62.7 months with OGS alterations compared to > 150 months without OGS alterations (p = 0.0248, hazard ratio = 2.213, 95% confidence interval = 1.1-4.098). Two genes comprising OGS (CYP26A1 and RDH10) are strongly associated with ALDH1A2 in the retinoic acid (RA) pathways, suggesting a major role of RA signaling in early PCa progression. Our pipeline complements human expertise in the search for prognostic biomarkers in large-scale datasets.","Authors":"Nim, HT (Nim, Hieu T.) ; Furtado, MB (Furtado, Milena B.) ; Ramialison, M (Ramialison, Mirana) ; Boyd, SE (Boyd, Sarah E.)","Title":"Combinatorial Ranking of Gene sets to Predict disease Relapse: the Retinoic Acid Pathway in early Prostate Cancer"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397835500014 ISSN: 1000-9000 eISSN: 1860-4749","Keywords":"incremental parallel FPGrowth; data mining; frequent itemset mining; MapReduce KeyWords Plus:ASSOCIATION RULES; DATABASES","Categories":"Computer Science Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Software Engineering","Journal Information":"JOURNAL OF COMPUTER SCIENCE AND TECHNOLOGY Volume: 32 Issue: 2 Pages: 368-385 DOI: 10.1007/s11390-017-1726-y Published: MAR 2017","Abstract":"Frequent itemset mining (FIM) is a popular data mining issue adopted in many fields, such as commodity recommendation in the retail industry, log analysis in web searching, and query recommendation (or related search). A large number of FIM algorithms have been proposed to obtain better performance, including parallelized algorithms for processing large data volumes. Besides, incremental FIM algorithms are also proposed to deal with incremental database updates. However, most of these incremental algorithms have low parallelism, causing low efficiency on huge databases. This paper presents two parallel incremental FIM algorithms called IncMiningPFP and IncBuildingPFP, implemented on the MapReduce framework. IncMiningPFP preserves the FP-tree mining results of the original pass, and utilizes them for incremental calculations. In particular, we propose a method to generate a partial FP-tree in the incremental pass, in order to avoid unnecessary mining work. Further, some of the incremental parallel tasks can be omitted when the inserted transactions include fewer items. IncbuildingPFP preserves the CanTrees built in the original pass, and then adds new transactions to them during the incremental passes. Our experimental results show that IncMiningPFP can achieve significant speedup over PFP (Parallel FPGrowth) and a sequential incremental algorithm (CanTree) in most cases of incremental input database, and in other cases IncBuildingPFP can achieve it.","Authors":"Song, YG (Song, Yu-Geng) ; Cui, HM (Cui, Hui-Min) ; Feng, XB (Feng, Xiao-Bing)","Title":"Parallel Incremental Frequent Itemset Mining for Large Data"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000397549600019 ISSN: 0920-4105 eISSN: 1873-4715","Keywords":"FL(Fuzzy Logic); K-means cluster analysis; SVM (Support Vector Machine); ANN (Artificial Neural Network); Source rock KeyWords Plus:WIRELINE LOGS; ABADAN PLAIN; SW IRAN; DENSITY; FIELD; IDENTIFICATION; HISTORY; SYSTEMS; CARBON; BELT","Categories":"Energy & Fuels; Engineering Web of Science Categories:Energy & Fuels; Engineering, Petroleum","Journal Information":"JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING Volume: 151 Pages: 224-234 DOI: 10.1016/j.petro1.2017.01.003 Published: MAR 2017","Abstract":"Determination of TOC is critical to the evaluation of every source rock unit. Methods which are dependent upon extensive laboratory testing are limited by the availability and integrity of the rock samples. Prediction of TOC (Total Organic Carbon) from well Log data being available for the majority of wells being drilled provides rapid evaluation of organic content, producing a continuous record while eliminating sampling issues. Therefore, the ideal method for determining the TOC fraction within source rock units would utilize common well log data. So a model was developed to formulate TOC values in the absence of laboratory TOC measurements from conventional well log data. Consequently, with the assistance of FL (Fuzzy Logic), TOC estimated from well log data with an overall prediction accuracy of 0.9425 for the test set. Following that TOC content of the Kazhdumi formation optimally has been divided into 4 zones using K-means cluster analysis, since searching for patterns is one of the main goals in data mining. There is a general increase in TOC from zone 1 to zone 4. The optimal number of zones has been detected by means of the knee method that finds the \"knee\" in a number of clusters vs. Compactness, Davies-Bouldin and Silhouette values. In the last step, using SVM (Support Vector Machine) and ANN (Artificial Neural Network) algorithms, two commonly used techniques, classification rules developed to predict the source rock class-membership (zones) from well log data. The proposed method is found effective in directly extracting patterns from well log data after defining classification rules. Quantitative comparisons of the results from ANN and SVM depicts that for classification problem of source rock zonation SVM with RBF (Radial Basis Function) kernel readily outperforms ANN in term of classification accuracy (0.9077 and 0.9369 for ANN and SVM, respectively), reduced computational time and highly 'repeatable results. ThiS method would enable a more elaborate assessment of Kazhdumi formation to be undertaken by providing a comprehensive quick look results derived directly from well log data while using conventional methods one can't define patterns within the data without grouping data manually.","Authors":"Bolandi, V (Bolandi, Vahid) ; Kadkhodaie, A (Kadkhodaie, Ali) ; Farzi, R (Farzi, Reza)","Title":"Analyzing organic richness of source rocks from well log data by using SVM and ANN classifiers: A case study from the Kazhdumi formation, the Persian Gulf basin, offshore Iran"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000394148300013 ISSN: 0138-9130 eISSN: 1588-2861","Keywords":"Research priority; Research gap; Text mining; Environment studies; Researchers' behavior analysis KeyWords Plus:LOG FILES; TRENDS; PREDICTION; MANAGEMENT; RETRIEVAL; FEEDBACK","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Interdisciplinary Applications; Information Science & Library Science","Journal Information":"SCIENTOMETRICS Volume: 110 Issue: 2 Pages: 815-842 DOI: 10.1007/s11192-016-2195-8 Published: FEB 2017","Abstract":"This study aims to observe the researchers' behavior in Iranian scientific databases to determine the research gaps and priorities in their field of research. Text mining and natural language processing techniques were used to identify what researchers are looking for and to analyze existing research works. In this paper, the information about the behavior of researchers who work in the field of environmental science and existing research works in the Iranian scientific database are processed. The search trends in all areas are evaluated by analyzing the users' search data. The trend analysis indicates that in the period of February 2013 to July 2015, the growth of the researchers' requests in some domains of the environment such as Industry, Training, Assessment, Material, Water and Pollution was 1.5 up to 2 times more than the overall requests. A Combination of the trend analysis and clustering of queries led to shaping four priority zones. Then, the research priorities for each environmental research area were determined. The results show that Training, Pollution, Rangeland, Management and Law are those domains in the environmental research which have the most research gaps in Iran, but there are enough research in Forest, Soil and Industry domains. At the end, we describe the steps for the implementation of a decision support system in environmental research management. Researchers, managers and policy makers can use this proposed \"research demand and supply monitoring'' system or RDSM to make appropriate decisions and allocate their resources more efficiently.","Authors":"Rabiei, M (Rabiei, Mohammad) ; Hosseini-Motlagh, SM (Hosseini-Motlagh, Seyyed-Mahdi) ; Haeri, A (Haeri, Abdorrahman)","Title":"Using text mining techniques for identifying research gaps and priorities: a case study of the environmental science in Iran"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000395591500013 ISSN: 1939-1374","Keywords":"Event logs; process models; alignment; process decomposition; trace segmentation; trace replaying KeyWords Plus:CONFORMANCE CHECKING; WORKFLOW; FRAMEWORK","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"IEEE TRANSACTIONS ON SERVICES COMPUTING Volume: 10 Issue: 1 Pages: 136-149 DOI: 10.1109/TSC.2016.2601094 Published: JAN-FEB 2017","Abstract":"The aligning of event logs with process models is of great significance for process mining to enable conformance checking, process enhancement, performance analysis, and trace repairing. Since process models are increasingly complex and event logs may deviate from process models by exhibiting redundant, missing, and dislocated events, it is challenging to determine the optimal alignment for each event sequence in the log, as this problem is NP-hard. Existing approaches utilize the cost-based A* algorithm to address this problem. However, scalability is often not considered, which is especially important when dealing with industrial-sized problems. In this paper, by taking advantage of the structural and behavioral features of process models, we present an efficient approach which leverages effective heuristics and trace replaying to significantly reduce the overall search space for seeking the optimal alignment. We employ real-world business processes and their traces to evaluate the proposed approach. Experimental results demonstrate that our approach works well in most cases, and that it outperforms the state-of-the-art approach by up to 5 orders of magnitude in runtime efficiency.","Authors":"Song, W (Song, Wei) ; Xia, XX (Xia, Xiaoxu) ; Jacobsen, HA (Jacobsen, Hans-Arno) ; Zhang, PC (Zhang, Pengcheng) ; Hu, H (Hu, Hao) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Song, Wei  http://orcid.org/0000-0002-4324-3382","Title":"Efficient Alignment Between Event Logs and Process Models"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000388053700046 ISSN: 0925-2312 eISSN: 1872-8286","Keywords":"Query recommendation; Query log analysis; Convex optimization; Incremental update method","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"NEUROCOMPUTING Volume: 218 Pages: 423-431 DOI: 10.1016/j.neucom.2016.09.003 Published: DEC 19 2016","Abstract":"Search engine query recommendation based on mining query logs has been considered as an important and useful method of facilitating users to retrieve information. However, the log data evolves quickly. Existing query recommendation approaches have to rebuild the models when new log data arrive. In this paper, we extend the query ranking model (QRM) proposed in our previous work (Wang et al., 2015) 111 to an adaptive model in which new coming log data is incrementally added, so that the recommendation model is kept up-to-date. The experimental results have demonstrated that the proposed incremental query ranking model (IQRM) is able to recommend queries more efficiently than re-building QRM on evolving log data without losing accuracy. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Wang, JG (Wang, JianGuo) ; Huang, JSZX (Huang, Joshua Zhexue) ; Wu, DM (Wu, Dingming) ; Guo, JF (Guo, Jiafeng) ; Lan, YY (Lan, Yanyan)","Title":"An incremental model on search engine query recommendation"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000385470400022 ISSN: 0020-0255 eISSN: 1872-6291","Keywords":"Duplicate tasks; Process discovery; Petri nets KeyWords Plus:MINING PROCESS MODELS; CONFORMANCE CHECKING; GENETIC ALGORITHM; EVENT LOGS","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION SCIENCES Volume: 373 Pages: 369-387 DOI: 10.1016/j.ins.2016.09.008 Published: DEC 10 2016","Abstract":"Including duplicate tasks in the mining process is a challenge that hinders the process discovery, as it is also necessary to find out which events of the log belong to which transitions. To face this problem, we propose SLAD (Splitting Labels After Discovery), an algorithm that uses the local information of the log to enhance an already mined model, by performing a local search over the tasks that have more probability to be duplicated in the log. This proposal has been validated with 54 different mined models from three process discovery algorithms, improving the final solution in 45 of the cases. Furthermore, SLAD has been tested in a real scenario. (C) 2016 Elsevier Inc. All rights reserved.","Authors":"Vazquez-Barreiros, B (Vazquez-Barreiros, Borja) ; Mucientes, M (Mucientes, Manuel) ; Lama, M (Lama, Manuel)","Title":"Enhancing discovered processes with duplicate tasks"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393184000008 ISSN: 1556-4681 eISSN: 1556-472X","Keywords":"Query intent; head and modifier; concept pattern; knowledge modeling","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA Volume: 11 Issue: 2 Article Number: 19 DOI: 10.1145/2988235 Published: DEC 2016","Abstract":"Interpreting the user intent in search queries is a key task in query understanding. Query intent classification has been widely studied. In this article, we go one step further to understand the query from the view of head-modifier analysis. For example, given the query \"popular iphone 5 smart cover,\" instead of using coarsegrained semantic classes (e.g., find electronic product), we interpret that \"smart cover\" is the head or the intent of the query and \"iphone 5\" is its modifier. Query head-modifier detection can help search engines to obtain particularly relevant content, which is also important for applications such as ads matching and query recommendation. We introduce an unsupervised semantic approach for query head-modifier detection. First, we mine a large number of instance level head-modifier pairs from search log. Then, we develop a conceptualization mechanism to generalize the instance level pairs to concept level. Finally, we derive weighted concept patterns that are concise, accurate, and have strong generalization power in head-modifier detection. The developed mechanism has been used in production for search relevance and ads matching. We use extensive experiment results to demonstrate the effectiveness of our approach.","Authors":"Wang, ZY (Wang, Zhongyuan) ; Wang, F (Wang, Fang) ; Wang, HX (Wang, Haixun) ; Hu, ZR (Hu, Zhirui) ; Yan, J (Yan, Jun) ; Li, FT (Li, Fangtao) ; Wen, JR (Wen, Ji-Rong) ; Li, ZJ (Li, Zhoujun)","Title":"Unsupervised Head-Modifier Detection in Search Queries"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393130300001 ISSN: 0022-1899 eISSN: 1537-6613","Keywords":"big data; infectious diseases; surveillance; disease models; transmission; social media; Internet search queries; electronic health records; mobility; adverse events; outbreaks","Categories":"Immunology; Infectious Diseases; Microbiology Web of Science Categories:Immunology; Infectious Diseases; Microbiology","Journal Information":"JOURNAL OF INFECTIOUS DISEASES Volume: 214 Pages: S375-S379 Supplement: 4 DOI: 10.1093/infdis/jiw400 Published: DEC 1 2016","Abstract":"We devote a special issue of the Journal of Infectious Diseases to review the recent advances of big data in strengthening disease surveillance, monitoring medical adverse events, informing transmission models, and tracking patient sentiments and mobility. We consider a broad definition of big data for public health, one encompassing patient information gathered from high-volume electronic health records and participatory surveillance systems, as well as mining of digital traces such as social media, Internet searches, and cell-phone logs. We introduce nine independent contributions to this special issue and highlight several cross-cutting areas that require further research, including representativeness, biases, volatility, and validation, and the need for robust statistical and hypotheses-driven analyses. Overall, we are optimistic that the big-data revolution will vastly improve the granularity and timeliness of available epidemiological information, with hybrid systems augmenting rather than supplanting traditional surveillance systems, and better prospects for accurate infectious diseases models and forecasts.","Authors":"Bansal, S (Bansal, Shweta) ; Chowell, G (Chowell, Gerardo) ; Simonsen, L (Simonsen, Lone) ; Vespignani, A (Vespignani, Alessandro) ; Viboud, C (Viboud, Cecile) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Bansal, Shweta  http://orcid.org/0000-0002-1740-5421","Title":"Big Data for Infectious Disease Surveillance and Modeling"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000388014900002 ISSN: 1386-4564 eISSN: 1573-7659","Keywords":"Mining similar queries; Query intent; Web search","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL JOURNAL Volume: 19 Issue: 6 Pages: 573-593 DOI: 10.1007/s10791-016-9288-0 Published: DEC 2016","Abstract":"Users often issue all kinds of queries to look for the same target due to the intrinsic ambiguity and flexibility of natural languages. Some previous work clusters queries based on co-clicks; however, the intents of queries in one cluster are not that similar but roughly related. It is desirable to conduct automatic mining of queries with equivalent intents from a large scale search logs. In this paper, we take account of similarities between query strings. There are two issues associated with such similarities: it is too costly to compare any pair of queries in large scale search logs, and two queries with a similar formulation, such as ''SVN'' (Apache Subversion) and support vector machine (SVM), are not necessarily similar in their intents. To address these issues, we propose using the similarities of query strings above the co-click based clustering results. Our method improves precision over the co-click based clustering method (lifting precision from 0.37 to 0.62), and outperforms a commercial search engine's query alteration (lifting F-1 measure from 0.42 to 0.56). As an application, we consider web document retrieval. We aggregate similar queries' click-throughs with the query's click-throughs and evaluate them on a large scale dataset. Experimental results indicate that our proposed method significantly outperforms the baseline method of using a query's own click-throughs in all metrics.","Authors":"Song, RH (Song, Ruihua) ; Wang, DQ (Wang, Dingquan) ; Nie, JY (Nie, Jian-Yun) ; Wen, JR (Wen, Ji-Rong) ; Yu, Y (Yu, Yong)","Title":"Enhancing web search with queries of equivalent intents"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000389174800015 ISSN: 1673-5447","Keywords":"component testing; security detection; monitor log; abnormal information; string-searching KeyWords Plus:CHEMICAL ABSTRACT MACHINE","Categories":"Telecommunications Web of Science Categories:Telecommunications","Journal Information":"China Communications Volume: 13 Issue: 11 Pages: 153-169 Published: NOV 2016","Abstract":"In the execution of method invocation sequences to test component security, abnormal or normal information is generated and recorded in a monitor log. By searching abnormal information from monitor log, the exceptions that the component has can be determined. To facilitate the searching process, string searching methods could be employed. However, current approaches are not effective enough to search long pattern string. In order to mine the specific information with less number of matches, we proposed an improved Sunday string searching algorithm in this paper. Unlike Sunday algorithm which does not make use of the already matched characters, the proposed approach presents two ideas utilizing and recycling these characters. We take advantage of all matched characters in main string, if they are still in the matchable interval compared with pattern string, to increase the distance that pattern string moves backwards. Experimental analysis shows that, compared to Sunday algorithm, our method could greatly reduce the matching times, if the scale of character set constituting both main string and pattern string is small, or if the length of pattern string is long. Also, the proposed approach can improve the search effectiveness for abnormal information in component security testing.","Authors":"Chen, JF (Chen, Jinfu) ; Zhu, LL (Zhu, Lili) ; Xie, ZB (Xie, Zhibin) ; Omari, M (Omari, Michael) ; Ackah-Arthur, H (Ackah-Arthur, Hilary) ; Cai, SH (Cai, Saihua) ; Huang, RB (Huang, Rubing)","Title":"An Effective Long String Searching Algorithm towards Component Security Testing"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000385190100009 ISSN: 0219-1377 eISSN: 0219-3116","Keywords":"Search engine; Web search","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"KNOWLEDGE AND INFORMATION SYSTEMS Volume: 49 Issue: 2 Pages: 661-685 DOI: 10.1007/s10115-015-0915-7 Published: NOV 2016","Abstract":"Mining the latent intents behind search queries is critical for contemporary search engines. Therefore, there has been lots of effort on studying how to infer the intents of search queries via search engine query log. However, the task of query log-based intent inference is not trivial, since it involves cross-disciplinary knowledge of data modeling and data mining. In this paper, we tackle the problem of query intent inference by integrating multiple information sources in a seamless manner. We first propose a comprehensive data model called Search Query Log Structure (SQLS) that represents the relation between search queries via the User dimension, the URL dimension, the Session dimension and the Term dimension. In order to explore the effective ways of using such multidimensional information modeled by SQLS, we survey and compare three frameworks, namely Result-Oriented Framework, Laplacian-Oriented Framework and Topic-Oriented Framework, to infer the intents of search queries. Experimental results show that the three frameworks significantly outperform the state-of-the-art approach and meet the diverse requirements arising from different application scenarios.","Authors":"Jiang, D (Jiang, Di) ; Yang, LX (Yang, Lingxiao)","Title":"Query intent inference via search engine log"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000388495800022 PubMed ID: 27655225 ISSN: 1438-8871","Keywords":"search behavior; geotagged search logs; health care utilization; utility; health care costs; Internet KeyWords Plus:INFORMATION-SEEKING; ROC CURVE; SURVEILLANCE; QUERIES; PRIVACY; ANXIETY","Categories":"Health Care Sciences & Services; Medical Informatics Web of Science Categories:Health Care Sciences & Services; Medical Informatics","Journal Information":"JOURNAL OF MEDICAL INTERNET RESEARCH Volume: 18 Issue: 9 Article Number: e251 DOI: 10.2196/jmir.6240 Published: SEP 2016","Abstract":"Background: By recent estimates, the steady rise in health care costs has deprived more than 45 million Americans of health care services and has encouraged health care providers to better understand the key drivers of health care utilization from a population health management perspective. Prior studies suggest the feasibility of mining population-level patterns of health care resource utilization from observational analysis of Internet search logs; however, the utility of the endeavor to the various stakeholders in a health ecosystem remains unclear. Objective: The aim was to carry out a closed-loop evaluation of the utility of health care use predictions using the conversion rates of advertisements that were displayed to the predicted future utilizers as a surrogate. The statistical models to predict the probability of user's future visit to a medical facility were built using effective predictors of health care resource utilization, extracted from a deidentified dataset of geotagged mobile Internet search logs representing searches made by users of the Baidu search engine between March 2015 and May 2015. Methods: We inferred presence within the geofence of a medical facility from location and duration information from users' search logs and putatively assigned medical facility visit labels to qualifying search logs. We constructed a matrix of general, semantic, and location-based features from search logs of users that had 42 or more search days preceding a medical facility visit as well as from search logs of users that had no medical visits and trained statistical learners for predicting future medical visits. We then carried out a closed-loop evaluation of the utility of health care use predictions using the show conversion rates of advertisements displayed to the predicted future utilizers. In the context of behaviorally targeted advertising, wherein health care providers are interested in minimizing their cost per conversion, the association between show conversion rate and predicted utilization score, served as a surrogate measure of the model's utility. Results: We obtained the highest area under the curve (0.796) in medical visit prediction with our random forests model and daywise features. Ablating feature categories one at a time showed that the model performance worsened the most when location features were dropped. An online evaluation in which advertisements were served to users who had a high predicted probability of a future medical visit showed a 3.96% increase in the show conversion rate. Conclusions: Results from our experiments done in a research setting suggest that it is possible to accurately predict future patient visits from geotagged mobile search logs. Results from the offline and online experiments on the utility of health utilization predictions suggest that such prediction can have utility for health care providers.","Authors":"Agarwal, V (Agarwal, Vibhu) ; Zhang, LL (Zhang, Liangliang) ; Zhu, J (Zhu, Josh) ; Fang, SY (Fang, Shiyuan) ; Cheng, T (Cheng, Tim) ; Hong, C (Hong, Chloe) ; Shah, NH (Shah, Nigam H.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Agarwal, Vibhu  http://orcid.org/0000-0002-6392-3924 Zhang, Liangliang  http://orcid.org/0000-0001-7862-2414","Title":"Impact of Predicting Health Care Utilization Via Web Search Behavior: A Data-Driven Analysis"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000383218900003 ISSN: 1016-2364","Keywords":"query subtopic mining; non-negative sparse LSA; subtractive clustering; faceted search; digital library KeyWords Plus:WEB-SEARCH","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"JOURNAL OF INFORMATION SCIENCE AND ENGINEERING Volume: 32 Issue: 5 Pages: 1161-1181 Published: SEP 2016","Abstract":"Ambiguous and multifaceted queries widely exist in academic and commercial search engines. Identifying the popular subtopics of queries is an important issue for search engines. In this paper, we propose a novel method to discover the popular subtopics for a given query. Our method first constructs a search behavior tripartite graph based on the search log data. Then, we utilize a subtractive initialized Non-negative Sparse LSA model to mine subtopics from the tripartite graph. The experimental results on two real-world Chinese search logs (i.e., the CADAL search log and the Sogou search log) show that our proposed method can significantly outperform the other comparison methods in term of MAP, alpha-nDCG and S-recall. We also applied our method into the CADAL digital library to provide a novel faceted book search service which can reduce the users' efforts in finding books.","Authors":"Yi, D (Yi, Deng) ; Zhang, Y (Zhang, Yin) ; Wei, BG (Wei, Baogang)","Title":"Query Subtopic Mining via Subtractive Initialization of Non-negative Sparse Latent Semantic Analysis"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000380125800004 ISSN: 0165-5515 eISSN: 1741-6485","Keywords":"Image retrieval; transaction log analysis; user search behaviour KeyWords Plus:WORLD-WIDE-WEB; LOG ANALYSIS; QUERIES; INFORMATION; BEHAVIOR; ENGINE; USERS; ENVIRONMENTS; RETRIEVAL; NETWORKS","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF INFORMATION SCIENCE Volume: 42 Issue: 4 Pages: 477-491 DOI: 10.1177/0165551515598952 Published: AUG 2016","Abstract":"Three months of server transaction logs containing complete clickstream data for an image collection digital library were analysed for usage patterns to better understand user searching and browsing behaviour in this environment. Eleven types of user actions were identified from the log content. The study is novel in its combined analytical techniques and use of clickstream data from an image-based digital library. Three analytical techniques were used to analyse the data: (a) network analysis to better understand the relationship between sequential actions; (b) sequential pattern mining to identify frequent action sequences; and (c) k-means cluster analysis to identify groups of session patterns. The analysis revealed strong ties between several pairs of actions, relatively short pattern sequences that frequently duplicate previous actions and largely uniform session behaviour with little individual item browsing within sessions, indicating users are primarily engaged in purposeful and directed searching. Developers of image-based digital libraries should consider design features that support rapid browsing.","Authors":"Han, H (Han, Hyejung) ; Wolfram, D (Wolfram, Dietmar)","Title":"An exploration of search session patterns in an image-based digital library"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000380081200008 ISSN: 0167-9236 eISSN: 1873-5797","Keywords":"Trend surveillance; Learning to rank; Data mining; Feature selection KeyWords Plus:US BUSINESS-CYCLE; PREDICTION; PERFORMANCE","Categories":"Computer Science; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Operations Research & Management Science","Journal Information":"DECISION SUPPORT SYSTEMS Volume: 88 Pages: 85-97 DOI: 10.1016/j.dss.2016.06.001 Published: AUG 2016","Abstract":"Web search engines are becoming a major platform for the general public to access information. It has been suggested that because the search patterns of search engine users are correlated with emerging events, the query log of search engines has the potential for trend surveillance, such as monitoring outbreaks of epidemics. Many trend surveillance studies have investigated the use of query logs and have strived to identify query terms suitable for trend surveillance. Most of these works select representative query terms by consulting domain experts or by preparing a large text corpus for feature selection. The process of these approaches, however, is too costly to make the trend surveillance methods adaptable to different topics. In this paper, we propose an adaptive trend surveillance method. We developed a simple and effective feature selection algorithm, called TF-LTR, which leverages the document returned by search engines and the frequency of the terms in the returned documents to select representative query terms of trending topics. Specifically, we investigated pair-wise learning to rank models in order to measure a term's discriminative power in making a document rank higher in the returned document list. The discriminative power is combined with the term frequency which denotes the on-topic degree of a term to measure a term's representativeness against a trending topic. Representative terms and their query frequencies are applied to a state-of-the-art data mining model to enhance the effectiveness of trend surveillance. The experimental results based on trending topics of different domains show that our trend surveillance method performs well and the ranking information of search engines are helpful for trend surveillance. In light of this, the proposed method can provide effective support for government officials and authorities in order to help them to respond to fast-changing events and topics, and to make appropriate decisions. (C) 2016 Elsevier B.V. All rights reserved.","Authors":"Fang, ZH (Fang, Ze-Han) ; Chen, CC (Chen, Chien Chin)","Title":"A novel trend surveillance system using the information from web search engines"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000385348800001 ISSN: 1540-9589 eISSN: 1544-5976","Keywords":"Search query; microblog posts; suggestion; pesudo relevance KeyWords Plus:SEARCH","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering; Computer Science, Theory & Methods","Journal Information":"JOURNAL OF WEB ENGINEERING Volume: 15 Issue: 3-4 Pages: 181-202 Published: JUL 1 2016","Abstract":"Query suggestion of Web search is an effective approach to help users quickly express their information need and accurately get the information they need. Most of popular web-search engines provide possible query suggestions based on their query log data, which is a kind of implicit relevance based approach. However, it is difficult to give suggestions to search queries that have no or few historical evidences in query logs. To solve this problem, traditional pseudo relevance based approaches directly extract additional keywords from the top-listed search results of a given search query as suggestions. However, for hot topic or event related search queries, users more like to browse the latest and newly appeared contents. In this paper, we follow the direction of pseudo relevance based suggestion approaches by mining microblog data that is inherent in fast information propagation and dissemination. Our graph based rank aggregation approach combines a frequency based ranking with considering words themself and a LDA (Latent Dirichlet Allocation) based ranking by mining hidden topics behinds words. A dataset is crawled from the posts of fourteen micro-topics of Sina microblog platform. The experimental results clearly demonstrate our proposed approach is more effective than traditional pseudo relevance based methods. Moreover, the suggested keywords extracted from the posts published by authenticated users are more effective than two traditional pseudo relevance based approaches, i.e., the posts submitted by all users and the top returned posts returned by Sina search engine. In addition, applying LDA on microbog posts alone is far from satisfactory, but the combination of the frequency based ranking and the LDA based ranking show much better performance.","Authors":"Li, L (Li, Lin) ; Qi, L (Qi, Lu) ; Deng, F (Deng, Fang) ; Xiong, SW (Xiong, Shengwu) ; Yuan, JL (Yuan, Jingling)","Title":"ENHANCING KEYWORD SUGGESTION OF WEB SERACH BY LEVERAGING MICROBLOG DATA"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000381940300060 ISSN: 2158-107X eISSN: 2156-5570","Keywords":"Clustering; K-Means; Log; Network; Cyber Profiling","Categories":"Computer Science Web of Science Categories:Computer Science, Theory & Methods","Journal Information":"INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS Volume: 7 Issue: 7 Pages: 430-435 Published: JUL 2016","Abstract":"The Activities of Internet users are increasing from year to year and has had an impact on the behavior of the users themselves. Assessment of user behavior is often only based on interaction across the Internet without knowing any others activities. The log activity can be used as another way to study the behavior of the user. The Log Internet activity is one of the types of big data so that the use of data mining with K-Means technique can be used as a solution for the analysis of user behavior. This study has been carried out the process of clustering using K-Means algorithm is divided into three clusters, namely high, medium, and low. The results of the higher education institution show that each of these clusters produces websites that are frequented by the sequence: website search engine, social media, news, and information. This study also showed that the cyber profiling had been done strongly influenced by environmental factors and daily activities.","Authors":"Zulfadhilah, M (Zulfadhilah, Muhammad) ; Prayudi, Y (Prayudi, Yudi) ; Riadi, I (Riadi, Imam)","Title":"Cyber Profiling using Log Analysis and K-Means Clustering A Case Study Higher Education in Indonesia"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000379520300004 ISSN: 1007-0214 eISSN: 1878-7606","Keywords":"component testing; security vulnerabilities detection; monitor log; abnormal information; string-searching KeyWords Plus:CHEMICAL ABSTRACT MACHINE","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic","Journal Information":"TSINGHUA SCIENCE AND TECHNOLOGY Volume: 21 Issue: 3 Pages: 281-294 Special Issue: SI Published: JUN 2016","Abstract":"Mass monitor logs are produced during the process of component security testing. In order to mine the explicit and implicit security exception information of the tested component, the log should be searched for keyword strings. However, existing string-searching algorithms are not very efficient or appropriate for the operation of searching monitor logs during component security testing. For mining abnormal information effectively in monitor logs, an improved string-searching algorithm is proposed. The main idea of this algorithm is to search for the first occurrence of a character in the main string. The character should be different and farther from the last character in the pattern string. With this algorithm, the backward moving distance of the pattern string will be increased and the matching time will be optimized. In the end, we conduct an experimental study based on our approach, the results of which show that the proposed algorithm finds strings in monitor logs 11.5% more efficiently than existing approaches.","Authors":"Chen, JF (Chen, Jinfu) ; Cai, SH (Cai, Saihua) ; Zhu, LL (Zhu, Lili) ; Guo, YC (Guo, Yuchi) ; Huang, RB (Huang, Rubing) ; Zhao, XL (Zhao, Xiaolei) ; Sheng, YQ (Sheng, Yunqi)","Title":"An Improved String-Searching Algorithm and Its Application in Component Security Testing"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000379026300003 ISSN: 0269-2821 eISSN: 1573-7462","Keywords":"Business intelligence; Ordered weighted operators; Regression analysis; Web usage mining KeyWords Plus:MULTICRITERIA DECISION-MAKING; WEIGHTED AVERAGING OPERATORS; AGGREGATION OPERATORS; ADDITIVE REGRESSION; DIGITAL LIBRARIES; RETRIEVAL-SYSTEM; SOCIAL NETWORK; INFORMATION; MODEL; PREFERENCE","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence","Journal Information":"ARTIFICIAL INTELLIGENCE REVIEW Volume: 46 Issue: 1 Pages: 59-82 DOI: 10.1007/s10462-015-9456-4 Published: JUN 2016","Abstract":"World Wide Web has emerged as one of the primary modes of information sharing and searching. Its reach has been extended to daily aspects of our life whether it is related to business or education. As the information is going online, and so is the complexity of finding the correct, precise and appropriate information. Many online companies rely heavily on analysis of web data to stay in business, to make strategic decisions, and for their existence. One of the problem in analyzing the web data is the web user. A typical web user exhibits highly uncertain pattern of web browsing and the same is captured in form of web server logs. Various data mining techniques like regression, are used to analyze such kind of data, but the inherent complex nature of web data introduces some outlier values while mining for information. Minimizing these outliers has always been a challenging task for data scientist and researchers. This paper uses an aggregation-based approach based on various ordered weighted averaging operators to reduce the outlier values in regression analysis. In this paper, a regression problem is being formulated followed by solving the problem with the help of concepts of multi-criteria decision making. Results, thus obtained are able to show that outliers can be reduced to a significant amount with the help of this approach.","Authors":"Gupta, A (Gupta, Ankit) ; Kohli, S (Kohli, Shruti)","Title":"An MCDM approach towards handling outliers in web data: a case study using OWA operators"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000379861800001 ISSN: 2220-9964","Keywords":"web usage mining; session identification and reconstruction; crawler detection; semantic search; data discovery KeyWords Plus:DIGITAL EARTH","Categories":"Physical Geography; Remote Sensing Web of Science Categories:Geography, Physical; Remote Sensing","Journal Information":"ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION Volume: 5 Issue: 5 DOI: 10.3390/ijgi5050054 Published: MAY 2016","Abstract":"Big geospatial data are archived and made available through online web discovery and access. However, finding the right data for scientific research and application development is still a challenge. This paper aims to improve the data discovery by mining the user knowledge from log files. Specifically, user web session reconstruction is focused upon in this paper as a critical step for extracting usage patterns. However, reconstructing user sessions from raw web logs has always been difficult, as a session identifier tends to be missing in most data portals. To address this problem, we propose two session identification methods, including time-clustering-based and time-referrer-based methods. We also present the workflow of session reconstruction and discuss the approach of selecting appropriate thresholds for relevant steps in the workflow. The proposed session identification methods and workflow are proven to be able to extract data access patterns for further pattern analyses of user behavior and improvement of data discovery for more relevancy data ranking, suggestion, and navigation.","Authors":"Jiang, YY (Jiang, Yongyao) ; Li, Y (Li, Yun) ; Yang, CW (Yang, Chaowei) ; Armstrong, EM (Armstrong, Edward M.) ; Huang, T (Huang, Thomas) ; Moroni, D (Moroni, David) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Yang, Chaowei  A-9881-2017   li, yun  http://orcid.org/0000-0002-3205-8464 Jiang, Yongyao  http://orcid.org/0000-0002-4591-483X","Title":"Reconstructing Sessions from Data Discovery and Access Logs to Build a Semantic Knowledge Base for Improving Data Discovery"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000372919600007 ISSN: 1386-145X eISSN: 1573-1413","Keywords":"Search engine; Query log; Topic model","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"WORLD WIDE WEB-INTERNET AND WEB INFORMATION SYSTEMS Volume: 19 Issue: 3 Pages: 475-497 DOI: 10.1007/s11280-015-0336-2 Published: MAY 2016","Abstract":"Understanding the users' latent intents behind the search queries is critical for search engines. Hence, there has been an increasing attention on studying how to effectively mine the intents of search queries by analyzing search engine query log. However, we observe that the information richness of query log is not fully utilized so far and the information underuse heavily limits the performance of the existing methods. In this paper, we tackle the problem of query intent mining by taking full advantage of the information richness of query log from a multi-dimensional perspective. Specifically, we capture the latent relations between search queries via three different dimensions: the URL dimension, the session dimension and the term dimension. We first propose the Result-Oriented Framework (ROF), which is easy to implement and significantly improves both the precision and the recall of query intent mining. We further propose the Topic-Oriented Framework (TOF), in order to significantly reduce the online time and memory consumptions for query intent mining. TOF employs the Query Log Topic Model (QLTM) that derives the latent topics from query log to integrate the information of the three dimensions in a principled way. The latent topics that are considered as low-dimensional descriptions of the query relations and serve as the basis of efficient online query intent mining. We conduct extensive experiments on a major commercial search engine query log. Experimental results show that the two frameworks significantly outperform the state-of-the-art methods with respect to a variety of metrics.","Authors":"Jiang, D (Jiang, Di) ; Leung, KWT (Leung, Kenneth Wai-Ting) ; Ng, W (Ng, Wilfred) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Ng, Wilfred Siu Hung  http://orcid.org/0000-0001-6639-0521","Title":"Query intent mining with multiple dimensions of web search data"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000384537900004 ISSN: 2155-6377 eISSN: 2155-6385","Keywords":"Intent Mining; Intent Prediction; Query Logs; Query; Search Engine","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INTERNATIONAL JOURNAL OF INFORMATION RETRIEVAL RESEARCH Volume: 6 Issue: 2 Pages: 66-85 DOI: 10.4018/IJIRR.2016040104 Published: APR-JUN 2016","Abstract":"The users that used search engines are obligated to express their goals in few words (queries). Sometimes search queries are ambiguous. Moreover, the users' intents are dynamically evolving. This paper analyzes the user's query logs to classify the related queries, the related intent topic categories and the related intent types and use this classification to dynamically predict the users' future queries, its intent topic and its intent type. AOL Search Query Log is taken as an experimental data set. Then use evaluation metrics to evaluate the prediction results.","Authors":"Hanna, WK (Hanna, Wael K.) ; Asem, AS (Asem, Aziza Saad) ; Senousy, MB (Senousy, M. B.)","Title":"Dynamic Query Intent Prediction from a Search Log Stream"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000371601700011 ISSN: 0165-5515 eISSN: 1741-6485","Keywords":"User-defined pattern scoring; WaPUPS; web access sequence; web access pattern; web usage mining KeyWords Plus:SEQUENTIAL PATTERNS; TRAVERSAL PATTERNS; DATA STREAMS; PERSONALIZATION; PREDICTION; NAVIGATION","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"JOURNAL OF INFORMATION SCIENCE Volume: 42 Issue: 2 Pages: 261-273 DOI: 10.1177/0165551515593495 Published: APR 2016","Abstract":"Extracting patterns from web usage data helps to facilitate better web personalization and web structure readjustment. The classical frequency-based sequence mining techniques consider only the binary occurrences of web pages in sessions that result in the extraction of many patterns that are not informative for users. To handle this problem, utility-based mining technique has emerged, which assigns non-binary values, called utilities, to web pages and calculates pattern utilities accordingly. However, the utility of a pattern cannot always be determined from distinct web page utilities. For instance, the number of distinct users that traverse an extracted pattern or some demographic data about those users may affect the value of the extracted patterns. However, such information cannot be calculated directly from web page utilities. In this paper, we present a new approach based on a user-defined scoring mechanism so as to extract patterns from web log data. The proposed approach can limit the size of the search space; therefore it has the ability to extract patterns even for large and sparse datasets. The framework is hybrid in the sense that it combines clustering with a heuristic-based pattern extraction algorithm. Substantial experiments on real datasets show that the proposed solution effectively discovers patterns under user-defined evaluation.","Authors":"Alkan, OK (Alkan, Oznur Kirmemis) ; Karagoz, P (Karagoz, Pinar)","Title":"WaPUPS: Web access pattern extraction under user-defined pattern scoring"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000365054800034 ISSN: 0020-0255 eISSN: 1872-6291","Keywords":"Process mining; Process discovery; Workflow net; Petri net; Token; Token log KeyWords Plus:DISCOVERING PROCESS MODELS; PETRI NETS; SIMILARITY SEARCH","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION SCIENCES Volume: 328 Pages: 558-576 DOI: 10.1016/j.ins.2015.08.050 Published: JAN 20 2016","Abstract":"Process mining is to discover, monitor and improve real processes by extracting the knowledge from logs which are available in today's information systems. The existing process mining algorithms are based on the event logs where only the executions of tasks are recorded. In order to reduce the pre-processing efforts and strengthen the mining ability of the existing process mining algorithms, we have proposed a novel perspective to employ the data carried by tokens recorded in token log which tracks the changes of process resources for process mining in this study. The feasibility of the token logs is proved and the results of pairwise t-tests show that there is no big difference between the efforts that are taken by the same workflow system to generate the token log and the event log. Besides, a process mining algorithm (tau) based on the new log is proposed in this paper. With algorithm tau, the mining efficiency as well as the mining capability is improved compared to the traditional event-log-based mining algorithms. We have also developed three plug-ins on top of the existing workflow engine, process modeling and mining platforms (YAWL, PIPE and ProM) for proving the feasibility of token log and realizing the token log generation and algorithm tau. (C) 2015 Elsevier Inc. All rights reserved.","Authors":"Li, CY (Li, Chuanyi) ; Ge, JD (Ge, Jidong) ; Huang, LG (Huang, Liguo) ; Hu, HY (Hu, Haiyang) ; Wu, BD (Wu, Budan) ; Yang, HJ (Yang, Hongji) ; Hu, H (Hu, Hao) ; Luo, B (Luo, Bin)","Title":"Process mining with token carried data"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000396490100010 ISSN: 0812-0099 eISSN: 1440-0952","Keywords":"National Virtual Core Library; HyLogging; HyLogger; Ni-Co laterites; mineralogy; Fe-oxide; clay KeyWords Plus:CHANNEL IRON DEPOSIT; DAM IOCG DEPOSIT; REFLECTANCE SPECTROSCOPY; SOUTH-AUSTRALIA; QUANTITATIVE MINERALOGY; WESTERN-AUSTRALIA","Categories":"Geology Web of Science Categories:Geosciences, Multidisciplinary","Journal Information":"AUSTRALIAN JOURNAL OF EARTH SCIENCES Volume: 63 Issue: 8 Pages: 1053-1067 DOI: 10.1080/08120099.2016.1246476 Published: 2016","Abstract":"The National Virtual Core Library (NVCL) HyLogging core-scanning system generates mineralogical information from visible, short-wave infrared and thermal infrared spectroscopic data. Currently, HyLogging data are freely available for more than 1500 drill holes via the AuScope Discovery Portal and various Geological Survey websites. With any new technology, there is commonly a lag between provision and take-up by users that can be aided by the publication of case studies in the scientific literature. This paper uses the Mt Davies nickel-cobalt (Ni-Co) laterite deposits, located in northwest South Australia, as a case study to assess the accessibility and representation of HyLogger data and provides an example of its application to all aspects of resource mining: exploration, extraction and processing, and remediation. In this study, we combine HyLogger-derived scalars indicating Fe-oxide and clay mineralogy with historical geological logs and assay data. In general, background Ni grades (<0.1 wt%) are linked to the presence of montmorillonite + hematite +/- goethite, moderate grades (0.1-1.0 wt%) are associated with goethite +/- nontronite +/- saponite +/- kaolinite +/- montmorillonite, and higher grades (1.0-2.0 wt%) are coincident with goethite and minimal clay alteration, suggesting that goethite hosts Ni mineralisation. Gibbsite, where it occurs, is found immediately above zones of moderate to high Ni grades and may be an important proximal indicator mineral of nickeliferous laterite. Such a case study serves to suggest opportunities for further data modelling and search and query functionality that could facilitate increased use of this important digital geoscience data resource by the Australian minerals industry for all aspects of resource exploitation: exploration, extraction, processing, and environmental remediation.","Authors":"Cracknell, MJ (Cracknell, M. J.) ; Jansen, NH (Jansen, N. H.)","Title":"National Virtual Core Library HyLogging data and Ni-Co laterites: a mineralogical model for resource exploration, extraction and remediation"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000393168500030 ISBN:978-1-5090-1666-2","Keywords":"Best-effort query answering; Dataspace; Heterogeneous data; Keyword relationship; indexing","Categories":"Automation & Control Systems; Computer Science; Telecommunications Web of Science Categories:Automation & Control Systems; Computer Science, Theory & Methods; Telecommunications","Journal Information":"2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA) Pages: 155-159 Published: 2016","Abstract":"Dataspace is one of the emerging approaches for handling heterogeneous data sources. However, dataspaces differ from conventional data integration approaches. They are a set of best-effort services over heterogeneous data sources with pay-asyou-go integration approach. When dataspaces encounter unstructured data, indexing is the only way of answering queries on a best-effort basis. To the best of our knowledge, no work has been done on providing relevant results to a query beyond those provided by indexing without manual efforts. The approach proposed in this paper stores relationships between keywords extracted from the user queries. These relationships are then used to improve query answering services and add new services like re-ranking of results and search recommendations in dataspace environment. The relationships stored are AND, OR and subsequent relations (one keyword after the other). The proposed work is motivated from how search engines handle the same problem by mining data from query logs.","Authors":"Sheokand, V (Sheokand, Vishal) ; Singh, V (Singh, Vikram) Edited by:Astya, PN; Swaroop, A; Sharma, V; Singh, M","Title":"Best Effort Query Answering in Dataspaces on Unstructured Data"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000393963800001 ISSN: 1554-0669 eISSN: 1554-0677","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"FOUNDATIONS AND TRENDS IN INFORMATION RETRIEVAL Volume: 10 Issue: 4 Pages: 274-+ DOI: 10.1561/1500000055 Published: 2016","Abstract":"In information retrieval, query auto completion (QAC), also known as type-ahead [Xiao et al., 2013, Cai et al., 2014b] and auto-complete suggestion [Jain and Mishne, 2010], refers to the following functionality: given a prefix consisting of a number of characters entered into a search box, the user interface proposes alternative ways of extending the prefix to a full query. Ranking query completions is a challenging task due to the limited length of prefixes entered by users, the large volume of possible query completions matching a prefix, and the broad range of possible search intents. In recent years, a large number of query auto completion approaches have been proposed that produce ranked lists of alternative query completions by mining query logs. In this survey, we review work on query auto completion that has been published before 2016. We focus mainly on web search and provide a formal definition of the query auto completion problem. We describe two dominant families of approaches to the query auto completion problem, one based on heuristic models and the other based on learning to rank. We also identify dominant trends in published work on query auto completion, viz. the use of time-sensitive signals and the use of user-specific signals. We describe the datasets and metrics that are used to evaluate algorithms for query auto completion. We also devote a chapter to efficiency and a chapter to presentation and interaction aspects of query auto completion. We end by discussing related tasks as well as potential research directions to further the area.","Authors":"Cai, F (Cai, Fei) ; de Rijke, M (de Rijke, Maarten)","Title":"A Survey of Query Auto Completion in Information Retrieval"}, {"Categories":"Engineering Web of Science Categories:Engineering, Environmental; Engineering, Mechanical","Journal Information":"PROCEEDINGS OF THE ASME 35TH INTERNATIONAL CONFERENCE ON OCEAN, OFFSHORE AND ARCTIC ENGINEERING , 2016, VOL 7 Article Number: UNSP V007T06A088 Published: 2016","Abstract":"An increasing number of ships are equipped with vessel monitoring systems logging ship data during normal operation. We developed a framework for multivariate time series data mining to extract the information of vessel behavior from an in-service dataset. The approach is established on unsupervised data clustering using Self-Organizing Map (SOM), K-means, and k-Nearest Neighbors Search (K-NNS) for searching specific maneuvers. The results are based on ship monitoring data of NTNU's research vessel, Gunnerus. It is shown that this approach is effective to detect prior unknown ship states with acceptable accuracy. The framework proposed and the results of this work can be of interest to those involved in ship administration, marine traffic flow engineering, ship maneuvering studies and assessment of ship design.","Authors":"Hoseini, AA (Hoseini, Afshin Abbasi) ; Steen, S (Steen, Sverre) Book Group Author(s):ASME","Title":"A DATA MINING APPROACH TO IDENTIFY MANEUVERS IN SHIP IN-SERVICE MEASUREMENTS"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000391251800052 ISBN:978-1-5090-2140-6 ISSN: 1530-2075","Keywords":"Big Data Analytics; KNN; kd-tree; Classification; Parallel Algorithms; and Load Balancing","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2016 IEEE 30TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM (IPDPS 2016) Book Series: International Parallel and Distributed Processing Symposium IPDPS Pages: 494-503 DOI: 10.1109/IPDPS.2016.57 Published: 2016","Abstract":"Computing k-Nearest Neighbors (KNN) is one of the core kernels used in many machine learning, data mining and scientific computing applications. Although kd-tree based O(log n) algorithms have been proposed for computing KNN, due to its inherent sequentiality, linear algorithms are being used in practice. This limits the applicability of such methods to millions of data points, with limited scalability for Big Data analytics challenges in the scientific domain. In this paper, we present parallel and highly optimized kd-tree based KNN algorithms (both construction and querying) suitable for distributed architectures. Our algorithm includes novel approaches for pruning search space and improving load balancing and partitioning among nodes and threads. Using TB-sized datasets from three science applications: astrophysics, plasma physics, and particle physics, we show that our implementation can construct kd-tree of 189 billion particles in 48 seconds on utilizing similar to 50,000 cores. We also demonstrate computation of KNN of 19 billion queries in 12 seconds. We demonstrate almost linear speedup both for shared and distributed memory computers. Our algorithms outperforms earlier implementations by more than order of magnitude; thereby radically improving the applicability of our implementation to state-of-the-art Big Data analytics problems.","Authors":"Patwary, MMA (Patwary, Md. Mostofa Ali) ; Satish, NR (Satish, Nadathur Rajagopalan) ; Sundaram, N (Sundaram, Narayanan) ; Liu, JL (Liu, Jialin) ; Sadowski, P (Sadowski, Peter) ; Racah, E (Racah, Evan) ; Byna, S (Byna, Suren) ; Tull, C (Tull, Craig) ; Bhimji, W (Bhimji, Wahid) ; Prabhat (Prabhat) ; Dubey, P (Dubey, Pradeep) ...More...Less Book Group Author(s):IEEE","Title":"PANDA: Extreme Scale Parallel K-Nearest Neighbor on Distributed Architectures"}, {"Document Information":"Document Type:Review Language:English Accession Number: WOS:000390763400011 ISSN: 1468-4527 eISSN: 1468-4535","Keywords":"Clustering; Pre-processing; Session identification; Sessionization; Web log file; Web usage mining","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"ONLINE INFORMATION REVIEW Volume: 40 Issue: 7 Pages: 1033-1053 DOI: 10.1108/OIR-08-2015-0274 Published: 2016","Abstract":"Purpose - The purpose of this paper is to critically analyze the state-of-the-art session identification techniques used in web usage mining (WUM) process in terms of their limitations, features, and methodologies. Design/methodology/approach - In this research, systematic literature review has been conducted using review protocol approach. The methodology consisted of a comprehensive search for relevant literature over the period of 2005-2015, using four online database repositories (i.e. IEEE, Springer, ACM Digital Library, and ScienceDirect). Findings - The findings revealed that this research area is still immature and existing literature lacks the critical review of recent session identification techniques used in WUM process. Originality/value - The contribution of this study is to provide a structured overview of the research developments, to critically review the existing session identification techniques, highlight their limitations and associated challenges and identify areas where further improvements are required so as to complement the performance of existing techniques.","Authors":"Fatima, B (Fatima, Bahjat) ; Ramzan, H (Ramzan, Huma) ; Asghar, S (Asghar, Sohail)","Title":"Session identification techniques used in web usage mining A systematic mapping of scholarly literature"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390694000020 ISBN:978-1-4673-8594-7","Keywords":"Information Search and Retrieval; Clustering; Information filtering; Query formulation; Relevance feedback; Retrieval models; Search process; Selection process","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON DATA MINING AND ADVANCED COMPUTING (SAPIENCE) Pages: 109-112 Published: 2016","Abstract":"Large amount of content in the websites today has made it difficult for the user to access the data which he wishes to view. Also, if the data is of different types like images, videos etc, the webmasters are bound to load the appropriate content which the user wants instead of loading all the data in any random manner. So, what we can do is, use the web users access logs and evaluate the logs using data mining techniques which can be called Web usage Mining (WUM), and along with that we can rank the data on the basis of the number of views the data has received. Here we are trying to display the content which is most relevant to the user by having a combination of data retrieved using WUM and data which has maximum rank assigned to it. Also in parallel, the most recently viewed data by the user will be displayed on the basis of maximum rank that data has been assigned by other users, and other recommendations which do not belong to users choice will be displayed and a pop up will hint the user to add the domain of that recommended data to his choice list.","Authors":"Chaudhari, DD (Chaudhari, Deptii D.) ; Agnihotri, N (Agnihotri, Nikhil) ; Dandwani, P (Dandwani, Pankaj) ; Nair, S (Nair, Shreejith) ; Kulange, S (Kulange, Swapnil) Edited by:Rajesh, R","Title":"A CHOICE BASED RECOMMENDATION SYSTEM USING WUM AND CLUSTERING"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000390536700084 ISBN:978-1-5090-1496-5","Keywords":"Mobile Learning; Data Analytics; Data Mining; Term Frequency; Information Retrieval; Natural Language Processing; K-12 Education KeyWords Plus:IPAD","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Telecommunications","Journal Information":"2016 IEEE 7TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS MOBILE COMMUNICATION CONFERENCE (UEMCON) Published: 2016","Abstract":"The K-12 learning space is evolving in both the United States and internationally. Students are given increasingly frequent access to the internet through various platforms such as desktop computers, laptops, tablets, and other mobile devices. Some schools are distributing mobile devices to students in order to facilitate the integration of technology in the classroom. These devices have a web filter installed on them to filter inappropriate content irrespective to the Wi-Fi network to which they are connected. These web filters collect logs of student activities on the internet. To date, however, this data has not been systematically analyzed. In this paper we explore data collected from K-12 student generated search queries on different search engines to gain insight into student learning behavior. Term frequency analysis is used to discover the relationship between effective and inappropriate usage of mobile devices in school.","Authors":"Jadav, J (Jadav, Jigar) ; Tappert, C (Tappert, Charles) ; Kollmer, M (Kollmer, Michael) ; Burke, AM (Burke, Andrew M.) ; Dhiman, P (Dhiman, Pratik) Edited by:Chakrabarti, S; Saha, HN","Title":"Using Text Analysis on Web Filter Data to Explore K-12 Student Learning Behavior"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000388117503096 ISBN:978-9-3805-4419-9","Keywords":"Query logs; Search Engine; Rank; Similarity; Clustering","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT Pages: 3387-3393 Published: 2016","Abstract":"Due to the tremendous growth of internet over the past few years, a large repository of data covering almost every area has been formed over the web and as a result of which search engine users are facing a lot of problems in retrieving the most appropriate information out of it which is known as information overkill problem. The main cause of this problem is non-optimization of web pages. This paper is to present a way for investigation of transaction logs obtained by search engines to optimize rank of web pages and then resulting into the topic/subject relevant and user suitable documents at the top of the result pages of search engine. The proposed algorithm starts with query logs maintained by a search engine to get an insight into the exact information need of users. Then, a novel approach is used to find similarity among queries based on two silent features i.e. query keywords and clicked URLs. Further, query cluster making tool is used to form clusters of same kind of queries based on to the value of combined similarity measure which lies between 0 and 1. After that, a relevancy finder tool works onto the URLs associated with each query in these clusters to find their relevancy with respect to the query by eliminating the effect of black hat and several other search optimization techniques. A sorting algorithm is thus applied on each cluster to arrange all the URLs in an increasing order of their relevancy and further the sequential pattern mining algorithm is applied on them in order to find the most frequently accessed sequential pattern. The outcome of this procedure is then improved by again ranking the web pages with the help of weight calculation according to the newly discoveredsequential patterns and the earlier rank associated with the web pages.","Authors":"Kataria, S (Kataria, Shipra) ; Sapra, P (Sapra, Pooja) Edited by:Hoda, MN","Title":"A Novel Approach for Rank Optimization using Search Engine Transaction Logs"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000388117503099 ISBN:978-9-3805-4419-9","Keywords":"search engine; web mining; query logs; query suggestions","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT Pages: 3404-3408 Published: 2016","Abstract":"The key goal of every search engine is to provide the information according to user's need. To achieve this goal, it retrieves the documents from its database based on user's query keywords and applies sophisticated ranking algorithms to sort them. But unfortunately, user submits short, instant and ambiguous queries which sometimes are not enough to clearly specify its need. Due to which wrong result set is formed, sorted and presented to the user. To solve this problem, an efficient query suggestion technique is proposed here which help user in refining its need at early stage of search process.","Authors":"Sethi, S (Sethi, Shilpa) ; Dixit, A (Dixit, Ashutosh) Edited by:Hoda, MN","Title":"An Efficient Personalized Query Suggestion Technique for Providing Relevant Results"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000388117503160 ISBN:978-9-3805-4419-9","Keywords":"User Id; Preprocessing; Personalize; Session","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT Pages: 3724-3730 Published: 2016","Abstract":"Web logs are files created to store data about users and all accesses made to web pages by various users. It stores various details such as User Id, URL accessed. Increasing use of information search on web is leading to increase in size of web log files. Mining web is implementation of mining techniques to these log files stored on client or server. Types of mining are Web usage mining, Web structure mining and Web content mining. Web Usage mining(WUM) uses these log files to discover user patterns. These log files exist in various formats. Web Usage mining is mining of access patterns of users which can then be used to personalize web sites according to user needs. Three main phases of WUM are Preprocessing, Pattern discovery and Pattern analysis. In this paper we focus on Session identification phase of preprocessing We have also done comparative analysis of various session identification algorithms. Methodology has been proposed for session identification. AI the end number of sessions arc identified for each IP address.","Authors":"Verma, P (Verma, Priyanka) ; Kesswani, N (Kesswani, Nishtha) Edited by:Hoda, MN","Title":"Comparitive Analysis of Algorithms for Identification of Session on the Basis of Threshhold Value"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000389411500010 ISBN:978-3-319-39958-4; 978-3-319-39957-7 ISSN: 0302-9743","Keywords":"Multi-class query classification; Large-scale classification; Search log mining; Query clustering KeyWords Plus:LINEAR CLASSIFICATION","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods","Journal Information":"WEB-AGE INFORMATION MANAGEMENT, PT II Book Series: Lecture Notes in Computer Science Volume: 9659 Pages: 120-131 DOI: 10.1007/978-3-319-39958-4_10 Published: 2016","Abstract":"Query classification is a crucial task to understand user search intents. Although this problem has been well studied in the past decades, it is still a big challenge in real-world applications due to the sparse, noisy and ambiguous nature of queries. In this paper, we present another important issue called \"the pomegranate phenomenon\". This phenomenon is named for the gap between manually manageable small taxonomy and massive coherent topics in each category. Furthermore, the fine-grained topics in the same category of the taxonomy may be textually more relevant to the topics in other categories. This phenomenon will hurt the performances of most traditional classification methods. To overcome this problem, we present a practical approach to enhance the performances of traditional query classifiers. First, we detect millions of fine-grained query topics from two years of click logs which can represent different query intents and give them category labels. Second, for a given query, we calculate the K most relevant topics and select the label by majority voting, then try to use this label to improve the results of classical query classification methods. Empirical evaluation confirms that our topic based classification algorithms can significantly enhance the performances of traditional classifiers in read-world query classification tasks.","Authors":"Ye, Q (Ye, Qi) ; Wang, F (Wang, Feng) ; Li, B (Li, Bo) ; Liu, ZM (Liu, Zhimin) Edited by:Cui, B; Zhang, N; Xu, J; Lian, X; Liu, D","Title":"Enhanced Query Classification with Millions of Fine-Grained Topics"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000388437000036 ISBN:978-3-319-46131-1; 978-3-319-46130-4 ISSN: 0302-9743","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES, ECML PKDD 2016, PT III Book Series: Lecture Notes in Artificial Intelligence Volume: 9853 Pages: 284-288 DOI: 10.1007/978-3-319-46131-1_36 Published: 2016","Abstract":"Search behavior, and information seeking behavior more generally, is often motivated by tasks that prompt search processes that are often lengthy, iterative, and intermittent, and are characterized by distinct stages, shifting goals and multitasking. Current search systems do not provide adequate support for users tackling complex tasks due to which the cognitive burden of keeping track of such tasks is placed on the searcher. In this note, we summarize our recent efforts towards extracting search tasks from search logs. Based on recent advancements in Bayesian Nonparametrics and distributional semantics, we propose novel algorithms to extract task and subtasks from a query collection. The models discussed can inform the design of the next generation of task-based search systems that leverage user's task behavior for better support and personalization.","Authors":"Mehrotra, R (Mehrotra, Rishabh) ; Yilmaz, E (Yilmaz, Emine) Edited by:Berendt, B; Bringmann, B; Fromont, E; Garriga, G; Miettinen, P; Tatti, N; Tresp, V","Title":"Query Log Mining for Inferring User Tasks and Needs"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000386483800004 ISBN:978-1-4673-8614-2 ISSN: 2471-125X","Keywords":"Big Data; Analytics; Distributed Computing; Associative Classification Mining; Fault Tolerance","Categories":"Engineering; Telecommunications Web of Science Categories:Engineering, Electrical & Electronic; Telecommunications","Journal Information":"2016 7TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION SYSTEMS (ICICS) Book Series: International Conference on Information and Communication Systems Pages: 20-26 Published: 2016","Abstract":"In this paper, we introduce the fault-tolerant Distributed Analytics System (DAS) for analyzing big data collected from search engines in Arabic. This system consists of three main subsystems: Logging and Archiving Subsystem (LAS), Analytics Subsystem (AS), and a User Interface (UI). We used the data provided by opensooq.com, an online market with Arabic content, and compiled four datasets with sizes: 50 Million, 100 Million, 150 Million, and 200 Million events, in order to assess DAS. The experiments showed that DAS outperformed its sequential counterpart at datasets of 100 Million events and more, with the best speedup being 3.5 at 200 Million events. Additionally, DAS outperformed the well-known analytics system ElasticSearch (ES) in terms of response time for input sizes of 70 Million events and more, as the time per request achieved by DAS was 21% faster than ES's time. Moreover, DAS turned out to be more energy-efficient in terms of CPU utilization, as ES's CPU utilization was 2.4 times more than DAS's utilization, on average.","Authors":"Alqrainy, R (Alqrainy, Ramzi) ; Baddar, SA (Baddar, Sherenaz Al-Haj) Book Group Author(s):IEEE","Title":"DAS: Distributed Analytics System for Arabic Search Engines"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000384532000002 ISSN: 1539-3100 eISSN: 1539-3119","Keywords":"Data Mining; E-Learning; Information Retrieval; Information Visualization; Learning Analytics; Visualization Tools","Categories":"Education & Educational Research Web of Science Categories:Education & Educational Research","Journal Information":"INTERNATIONAL JOURNAL OF DISTANCE EDUCATION TECHNOLOGIES Volume: 14 Issue: 1 Pages: 1-21 Special Issue: SI DOI: 10.4018/IJDET.2016010101 Published: JAN-MAR 2016","Abstract":"This paper presents two interactive visualization tools for learning management systems (LMS) in order to improve learning and teaching in online courses. The first tool was developed at the Intelligent Information Systems Laboratory (IISLab) at the Tampere University of Technology (TUT). The tool is used to analyse students' activity from automatically recorded user log data and to build interactive visualizations. They provide valuable insights into the learning process and participation of students in a course offered to teachers and students. The second tool was developed at the Unitelma Sapienza University. It extends navigation and search functionalities in the discussion forum of an LMS with a topic-driven paradigm. The tool analyses forum content and automatically identifies discussion topics. It then enhances the original forum with a topic-driven navigation structure and an interactive search graph. Both tools have been developed as plug-ins for the Moodle LMS, but their analysis processes and techniques can be adopted into any LMS.","Authors":"Kuosa, K (Kuosa, Kirsi) ; Distante, D (Distante, Damiano) ; Tervakari, A (Tervakari, Anne) ; Cerulo, L (Cerulo, Luigi) ; Fernandez, A (Fernandez, Alejandro) ; Koro, J (Koro, Juho) ; Kailanto, M (Kailanto, Meri) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Tervakari, Anne  http://orcid.org/0000-0002-3313-4326","Title":"Interactive Visualization Tools to Improve Learning and Teaching in Online Learning Environments"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000382167400037 ISBN:978-1-4503-3716-8","Keywords":"IP geolocation; geographic targeting; geotargeting; local search; contextual relevance; geographic personalization KeyWords Plus:INTERNET; WEB","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16) Pages: 347-356 DOI: 10.1145/2835776.2835820 Published: 2016","Abstract":"IP geolocation databases map IP addresses to their geographical locations. These databases are important for several applications such as local search engine relevance, credit card fraud protection, geotargetted advertising, and online content delivery. While they are the most popular method of geolocation, they can have low accuracy at the city level. In this paper we evaluate and improve IP geolocation databases using data collected from search engine logs. We generate a large ground-truth dataset using real time global positioning data extracted from search engine logs. We show that incorrect geolocation information can have a negative impact on implicit user metrics. Using the dataset we measure the accuracy of three state-of-the-art commercial IP geolocation databases. We then introduce a technique to improve existing geolocation databases by mining explicit locations from query logs. We show significant accuracy gains in 44 to 49 out of the top 50 countries, depending on the IP geolocation database. Finally, we validate the approach with a large scale A/B experiment that shows improvements in several user metrics.","Authors":"Dan, O (Dan, Ovidiu) ; Parikh, V (Parikh, Vaibhav) ; Davison, BD (Davison, Brian D.) Book Group Author(s):ACM","Title":"Improving IP Geolocation using Query Logs"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000382762000029 ISBN:978-1-5090-0645-8","Keywords":"clustering; web usage mining KeyWords Plus:SEARCH","Categories":"Engineering Web of Science Categories:Engineering, Electrical & Electronic","Journal Information":"2ND INTERNATIONAL MERCON 2016 MORATUWA ENGINEERING RESEARCH CONFERENCE Pages: 168-173 Published: 2016","Abstract":"Web logs can provide a wealth of information on user access patterns of a corresponding website, when they are properly analyzed. However, finding interesting patterns hidden in the low-level log data is non-trivial due to large log volumes, and the distribution of the log files in cluster environments. This paper presents a novel technique, the application of Density-Based Spatial Clustering of Applications with Noise (DBSCAN) and Expectation Maximization (EM) algorithms in an iterative manner for clustering web user sessions. Each cluster corresponds to one or more web user activities. The unique user access pattern of each cluster is identified by frequent pattern mining and sequential pattern mining techniques. When compared with the clustering output of EM, DBSCAN, and k-means algorithms, this technique shows better accuracy in web session mining, and it is more effective in identifying cluster changes with time. We demonstrate that the implemented system is capable of not only identifying common user behaviors, but also of identifying cyber-attacks.","Authors":"Udantha, M (Udantha, M.) ; Ranathunga, S (Ranathunga, S.) ; Dias, G (Dias, G.) Book Group Author(s):IEEE","Title":"Modelling Website User Behaviors by Combining the EM and DBSCAN Algorithms"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000381976300004 ISBN:978-3-319-30927-9; 978-3-319-30926-2 ISSN: 2190-3018","Keywords":"Search logs; Click-through; Implicit feedback; Search engine; Web search ranking; Search destination; Entropy; Information goal; User behavior; Search history; Learning from user behavior","Categories":"Computer Science; Engineering; Telecommunications Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Telecommunications","Journal Information":"PROCEEDINGS OF FIRST INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY FOR INTELLIGENT SYSTEMS: VOL 2 Book Series: Smart Innovation Systems and Technologies Volume: 51 Pages: 33-45 DOI: 10.1007/978-3-319-30927-9_4 Published: 2016","Abstract":"Search engine process millions of query and collect data of user interaction every day. These huge amount of data contains valuable information through which web search engine can be optimized. Search engine mostly relies on explicit judgement received from domain experts. To survive the competition search engine must understand user's information needs very well. Search logs provide implicit data about user's interaction with search engine. Search logs are noisy, they contain data of both successful search and unsuccessful search. The challenge is to accurately interpret user's feedback to search engine and learning the user access patterns, such that search engine will better be able to cater the user's information needs. User feedback can be used to re-rank the search result, query suggestion and URL recommendation.","Authors":"Bhojawala, V (Bhojawala, Vivek) ; Patel, P (Patel, Pinal) Edited by:Satapathy, SC; Das, S","Title":"Search Logs Mining: Survey"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380371100065 ISBN:978-0-7354-1403-7 ISSN: 0094-243X","Keywords":"Process Mining; Business Processes; FP-Growth; PrefixSpan; Fuzzy time-interval sequential pattern","Categories":"Physics Web of Science Categories:Physics, Applied","Journal Information":"2016 CONFERENCE ON FUNDAMENTAL AND APPLIED SCIENCE FOR ADVANCED TECHNOLOGY (CONFAST 2016) Book Series: AIP Conference Proceedings Volume: 1746 Article Number: 020065 DOI: 10.1063/1.4953990 Published: 2016","Abstract":"Rapid technological developments caused the increasing number of computerized data processing. With the increasing complexity of business processes, business process management technologies such as ERP (Enterprise Resource Planning) are increasingly being used. This resulted in the availability of data more abundant so that excavation and search information from the dataset will be a valuable knowledge. In this paper, we have done the process mining to obtain an interesting pattern of event log data. In this research, data mining method that we are used is the sequential pattern mining algorithm using FP-Growth-Prefix Span. In addition, we are also used the fuzzy approach to handle the time interval of the analyzed data, so that the sequential pattern that produced become fuzzy time-interval sequential pattern. The application of these methods in a business processes that produce fuzzy time interval sequential pattern. From the analysis, the result shown that there is a minimum effect on the pattern of the resulting support. Furthermore, the results of the analysis can be used as consideration in the analysis of business processes.","Authors":"Mukhlash, I (Mukhlash, Imam) ; Muntaha, AMAMS (Muntaha, M. Sidratul A. M. A.) ; Iqbal, M (Iqbal, Mohammad) ; Saikhu, A (Saikhu, Ahmad) ; Sarno, R (Sarno, Riyanarto) Edited by:Kusuma, DY","Title":"Mining Fuzzy Time Interval Sequential Pattern on Event Log Data using FP-Growth-Prefix-Span Algorithms"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000376017200015 ISSN: 1742-6588","Keywords":"Log file; Pattern analysis; Pattern discovery; Pre-processing KeyWords Plus:AGENTS","Categories":"Crystallography; Engineering; Physics Web of Science Categories:Crystallography; Engineering, Multidisciplinary; Physics, Multidisciplinary","Journal Information":"4TH INTERNATIONAL CONFERENCE ON SCIENCE & ENGINEERING IN MATHEMATICS, CHEMISTRY AND PHYSICS 2016 (SCIETECH 2016) Book Series: Journal of Physics Conference Series Volume: 710 Article Number: 012015 DOI: 10.1088/1742-6596/710/1/012015 Published: 2016","Abstract":"The Web usage mining is the application of data mining, which is used to extract useful information from the online community. The World Wide Web contains at least 4.73 billion pages according to Indexed Web and it contains at least 228.52 million pages according Dutch Indexed web on 6th august 2015, Thursday. It's difficult to get needed data from these billions of web pages in World Wide Web. Here is the importance of web usage mining. Personalizing the search engine helps the web user to identify the most used data in an easy way. It reduces the time consumption; automatic site search and automatic restore the useful sites. This study represents the old techniques to latest techniques used in pattern discovery and analysis in web usage mining from 1996 to 2015. Analyzing user motif helps in the improvement of business, e-commerce, personalisation and improvement of websites.","Authors":"Alphy, M (Alphy, Meera) ; Sharma, A (Sharma, Ajay) Edited by:Gaol, FL","Title":"Study on online community user motif using web usage mining"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000373007500053 ISBN:978-81-322-2755-7; 978-81-322-2753-3 ISSN: 2194-5357","Keywords":"Data mining; Web data mining; Association rule mining; Negative association rule mining; Data analysis","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"INFORMATION SYSTEMS DESIGN AND INTELLIGENT APPLICATIONS, VOL 1, INDIA 2016 Book Series: Advances in Intelligent Systems and Computing Volume: 433 Pages: 513-518 DOI: 10.1007/978-81-322-2755-7_53 Published: 2016","Abstract":"Today era is combination of information and communication technology (ICT), everyone wants to share and store their information through the internet, so there is huge amount of data is searched every day, there is lots of web data is collected in every seconds and with the help of web usage mining, we can discover useful pattern from the web databases. For analyzing this huge amount of web data, we required one of the useful concepts is web site managements. In which we discover the useful pattern, discover or analyzing the useful information from the web database. Here we used the concept of negative association rule mining for analyzing the web log files, for finding the strong association between the web data's.","Authors":"Kumar, R (Kumar, Raghvendra) ; Pattnaik, PK (Pattnaik, Prasant Kumar) ; Sharma, Y (Sharma, Yogesh) Edited by:Satapathy, SC; Mandal, JK; Udgata, SK; Bhateja, V","Title":"Web Data Analysis Using Negative Association Rule Mining"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000369219800004 PubMed ID: 25888696 ISSN: 1467-5463 eISSN: 1477-4054","Keywords":"Amazon Mechanical Turk; big data mining; biomedicine; community challenges; crowdsourcing; games KeyWords Plus:PROTEIN-STRUCTURE PREDICTION; AMAZON MECHANICAL TURK; MEDICAL-EDUCATION; NORMALIZATION; TEXT; KNOWLEDGE; TRENDS; CANCER; TERMS; GAME","Categories":"Biochemistry & Molecular Biology; Mathematical & Computational Biology Web of Science Categories:Biochemical Research Methods; Mathematical & Computational Biology","Journal Information":"BRIEFINGS IN BIOINFORMATICS Volume: 17 Issue: 1 Pages: 23-32 Special Issue: SI DOI: 10.1093/bib/bbv021 Published: JAN 2016","Abstract":"The use of crowdsourcing to solve important but complex problems in biomedical and clinical sciences is growing and encompasses a wide variety of approaches. The crowd is diverse and includes online marketplace workers, health information seekers, science enthusiasts and domain experts. In this article, we review and highlight recent studies that use crowdsourcing to advance biomedicine. We classify these studies into two broad categories: (i) mining big data generated from a crowd (e.g. search logs) and (ii) active crowdsourcing via specific technical platforms, e.g. labor markets, wikis, scientific games and community challenges. Through describing each study in detail, we demonstrate the applicability of different methods in a variety of domains in biomedical research, including genomics, biocuration and clinical research. Furthermore, we discuss and highlight the strengths and limitations of different crowdsourcing platforms. Finally, we identify important emerging trends, opportunities and remaining challenges for future crowdsourcing research in biomedicine.","Authors":"Khare, R (Khare, Ritu) ; Good, BM (Good, Benjamin M.) ; Leaman, R (Leaman, Robert) ; Su, AI (Su, Andrew I.) ; Lu, ZY (Lu, Zhiyong) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Su, Andrew I.  http://orcid.org/0000-0002-9859-4104","Title":"Crowdsourcing in biomedicine: challenges and opportunities"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000369440500006 ISSN: 0264-0473 eISSN: 1758-616X","Keywords":"Data mining; Information needs; Query analysis; Science and technology; Search behaviors; User study KeyWords Plus:TRANSACTION LOG ANALYSIS; USERS","Categories":"Information Science & Library Science Web of Science Categories:Information Science & Library Science","Journal Information":"ELECTRONIC LIBRARY Volume: 34 Issue: 1 Pages: 83-98 DOI: 10.1108/EL-04-2014-0058 Published: 2016","Abstract":"Purpose - This study aims at a longitudinal understanding of the user-system interactions from the context of science and technology at a query level. Design/methodology/approach - The authors quantitatively analyzed log data sets culled from more than 24,820,416 queries submitted by users of a national scientific and technical information system, collected in 2008-2011. Findings - In the fields of science and technology, the user search behaviors and patterns have remained stable. User queries are short and simple. In all, 80 per cent of the queries are made up of one-three terms. The length of query on a scholarly information system in the fields of science and technology is different from that of Web search. The former is longer than the latter. Search topics have shifted fast. \"FUEL BATTERY\", \"NANO\", \"OLED\", \"CAR\", \"ROBOT\" and \"SMARTPHONE\" were high-ranked queries from 2008 to 2011. It was found that the time to determine whether the users will stay on the site took about 10 seconds on average from the time of visit. If the users viewed the results of a list generated by the search query and took any action, such as detailed view, export or full-text download, most of them stayed more than 10 minutes on average. Originality/value - Longitudinal user research using a query analysis helps to understand the information needs and behavioral patterns of users on information systems related to a specific field and those based on the Web. It also brings insights into the past, present and future events of a field. In other words, it plays a role as a mirror that reflects the flow of time. In the long run, it will be an historic asset. In the future, user studies using a query analysis need to be carried out from various (e.g. social, cultural or other academic disciplines) long-term perspectives on a continuous basis.","Authors":"Park, M (Park, Minsoo) ; Lee, TS (Lee, Tae-Seok)","Title":"A longitudinal study of information needs and search behaviors in science and technology A query analysis"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000368188500008 ISSN: 1550-4859 eISSN: 1550-4867","Keywords":"GPS; text query; semantic compression; activity recognition; mobile device","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Information Systems; Telecommunications","Journal Information":"ACM TRANSACTIONS ON SENSOR NETWORKS Volume: 11 Issue: 4 DOI: 10.1145/2814569 Published: DEC 2015","Abstract":"This article describes iDiary, a system that takes as input GPS data streams generated by users' phones and turns them into textual descriptions of the trajectories. The system features a user interface similar to Google Search that allows users to type text queries on their activities (e.g., \"Where did I buy books?\") and receive textual answers based on their GPS signals. iDiary uses novel algorithms for semantic compression and trajectory clustering of massive GPS signals in parallel to compute the critical locations of a user. We encode these problems as follows. The k-segment mean is a k-piecewise linear function that minimizes the regression distance to the signal. The (k, m)-segment mean has an additional constraint that the projection of the k segments on R-d consists of only m <= k segments. A coreset for this problem is a smart compression of the input signal that allows computation of a (1 + epsilon)-approximation to its k-segment or (k, m)-segment mean in O(nlog n) time for arbitrary constants e, k, and m. We use coresets to obtain a parallel algorithm that scans the signal in one pass, using space and update time per point that is polynomial in log n. Using an external database, we then map these locations to textual descriptions and activities so that we can apply text mining techniques on the resulting data (e.g., LSA or transportation mode recognition). We provide experimental results for both the system and algorithms and compare them to existing commercial and academic state of the art. This is the first GPS system that enables text-searchable activities from GPS data.","Authors":"Feldman, D (Feldman, Dan) ; Sung, C (Sung, Cynthia) ; Sugaya, A (Sugaya, Andrew) ; Rus, D (Rus, Daniela)","Title":"iDiary: From GPS Signals to a Text-Searchable Diary"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000365876500002 ISSN: 1386-4564 eISSN: 1573-7659","Keywords":"Information retrieval; Query understanding; Intent mining; Intent ranking; NTCIR-11 IMine task KeyWords Plus:AFFINITY PROPAGATION; WEB SEARCH","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems","Journal Information":"INFORMATION RETRIEVAL Volume: 18 Issue: 6 Pages: 504-529 DOI: 10.1007/s10791-015-9271-1 Published: DEC 2015","Abstract":"How to understand intents behind user queries is crucial towards improving the performance of Web search systems. NTCIR-11 IMine task focuses on this problem. In this paper, we address the NTCIR-11 IMine task with two phases referred to as Query Intent Mining (QIM) and Query Intent Ranking (QIR). (I) QIM is intended to mine users' potential intents by clustering short text fragments related to the given query. (II) QIR focuses on ranking those mined intents in a proper way. Two challenges exist in handling these tasks. (II) How to precisely estimate the intent similarity between user queries which only consist of a few words. (2) How to properly rank intents in terms of multiple factors, e.g. relevance, diversity, intent drift and so on. For the first challenge, we first investigate two interesting phenomena by analyzing query logs and document datasets, namely \"Same-Intent-Co-Click\" (SICC) and \"Same-Intent-Similar-Rank\" (SISR). SICC means that when users issue different queries, these queries represent the same intent if they click on the same URL. SISR means that if two queries denote the same intent, we should get similar search results when issuing them to a search engine. Then, we propose similarity functions for QIM based on the two phenomena. For the second challenge, we propose a novel intent ranking model which considers multiple factors as a whole. We perform extensive experiments and an interesting case study on the Chinese dataset of NTCIR-11 IMine task. Experimental results demonstrate the effectiveness of our proposed approaches in terms of both QIM and QIR.","Authors":"Ren, PJ (Ren, Pengjie) ; Chen, ZM (Chen, Zhumin) ; Ma, J (Ma, Jun) ; Wang, SQ (Wang, Shuaiqiang) ; Zhang, ZW (Zhang, Zhiwei) ; Ren, ZC (Ren, Zhaochun)","Title":"Mining and ranking users' intents behind queries"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000366161800019 ISSN: 1567-4223 eISSN: 1873-7846","Keywords":"Lean Marketing; Negative keyword match; Search advertising","Categories":"Business & Economics; Computer Science Web of Science Categories:Business; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications","Journal Information":"ELECTRONIC COMMERCE RESEARCH AND APPLICATIONS Volume: 14 Issue: 6 Pages: 631-640 DOI: 10.1016/j.elerap.2015.09.004 Published: OCT-NOV 2015","Abstract":"Internet users search the web for more and more relevant information, such as where to find the best online deals, where to go for vacation, what to wear to a wedding, and many others. Online search advertisers target these users based on their search queries. Targeting the right set of users is important as each user clicking on an online search ad costs money to the advertiser. Savvy advertisers usually pick keywords that are niche and \"non-intuitive\" because such keywords are cheaper than more popular keywords due to lesser number of advertisers competing for them. In order to find such keywords, multiple information sources such as web ontologies open to the public, search engine results, and search query logs were mined in the past. In these studies, the universe of all relevant keywords was approximated as the relevant keywords of all techniques combined. A given keyword selection technique was then evaluated based on the relevance of the keywords it selected to the target page that is to be advertised. Since the universe of relevant keywords was approximate, it had implications for advertising efficiency. For the campaign dataset we used in this study, out of a total of $75K spent on the campaign, 10% of this total budget was spent on the irrelevant queries. Our primary goal in this work is to reduce this excess budget spent on the irrelevant queries. For this purpose, we learn the characteristics of the \"irrelevant\" queries using the campaign's past performance data. Words and phrases that occur frequently in queries, which are not likely to convert, are used as a proxy to decide who not to advertise to. In this way, we plan to preserve more of the marketing budget for queries that are more likely to convert. In our empirical study, we used a logistic regressor for identifying negative words, which distinguished the non-converting queries from the converting ones, and pruned the non-converting queries using the negatives identified. Our approach decreased the average customer acquisition cost of a live search campaign by 25% and cut the overall campaign spend by 28.6%. (C) 2015 Elsevier B.V. All rights reserved.","Authors":"Bulut, A (Bulut, Ahmet)","Title":"Lean Marketing: Know who not to advertise to!"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000360306600007 PubMed ID: 26293444 ISSN: 1438-8871","Keywords":"Internet log analysis; data mining; physicians; information-seeking behavior; drug safety surveillance KeyWords Plus:UNITED-STATES; QUERY DATA; SEARCH; WEB; PHYSICIANS; HOSPITALS; INTERNET; DOCTORS; GOOGLE; NEEDS","Categories":"Health Care Sciences & Services; Medical Informatics Web of Science Categories:Health Care Sciences & Services; Medical Informatics","Journal Information":"JOURNAL OF MEDICAL INTERNET RESEARCH Volume: 17 Issue: 8 Article Number: e204 DOI: 10.2196/jmir.4427 Published: AUG 2015","Abstract":"Background: Patterns in general consumer online search logs have been used to monitor health conditions and to predict health-related activities, but the multiple contexts within which consumers perform online searches make significant associations difficult to interpret. Physician information-seeking behavior has typically been analyzed through survey-based approaches and literature reviews. Activity logs from health care professionals using online medical information resources are thus a valuable yet relatively untapped resource for large-scale medical surveillance. Objective: To analyze health care professionals' information-seeking behavior and assess the feasibility of measuring drug-safety alert response from the usage logs of an online medical information resource. Methods: Using two years (2011-2012) of usage logs from UpToDate, we measured the volume of searches related to medical conditions with significant burden in the United States, as well as the seasonal distribution of those searches. We quantified the relationship between searches and resulting page views. Using a large collection of online mainstream media articles and Web log posts we also characterized the uptake of a Food and Drug Administration (FDA) alert via changes in UpToDate search activity compared with general online media activity related to the subject of the alert. Results: Diseases and symptoms dominate UpToDate searches. Some searches result in page views of only short duration, while others consistently result in longer-than-average page views. The response to an FDA alert for Celexa, characterized by a change in UpToDate search activity, differed considerably from general online media activity. Changes in search activity appeared later and persisted longer in UpToDate logs. The volume of searches and page view durations related to Celexa before the alert also differed from those after the alert. Conclusions: Understanding the information-seeking behavior associated with online evidence sources can offer insight into the information needs of health professionals and enable large-scale medical surveillance. Our Web log mining approach has the potential to monitor responses to FDA alerts at a national level. Our findings can also inform the design and content of evidence-based medical information resources such as UpToDate.","Authors":"Callahan, A (Callahan, Alison) ; Pernek, I (Pernek, Igor) ; Stiglic, G (Stiglic, Gregor) ; Leskovec, J (Leskovec, Jure) ; Strasberg, HR (Strasberg, Howard R.) ; Shah, NH (Shah, Nigam Haresh) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Callahan, Alison  http://orcid.org/0000-0001-5163-380X","Title":"Analyzing Information Seeking and Drug-Safety Alert Response by Health Care Professionals as New Methods for Surveillance"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000358233000008 ISSN: 1520-9210 eISSN: 1941-0077","Keywords":"Attribute; click-through log; matrix factorization; topic modeling KeyWords Plus:OBJECT CLASSES","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications","Journal Information":"IEEE TRANSACTIONS ON MULTIMEDIA Volume: 17 Issue: 8 Pages: 1213-1224 DOI: 10.1109/TMM.2015.2438712 Published: AUG 2015","Abstract":"Attribute-based image representation, which represents an image by projecting it into a space spanned by attributes, has attracted increasing attention from both computer vision and multimedia communities for its compactness and potential to bridge the semantic gap. While many works focus on learning attribute models and utilizing them in image recognition and retrieval, few touch on the problem of how to effectively construct a vocabulary of attributes, which is an essential part of effective attribute-based representation. Most existing approaches define the attribute vocabulary by human experts or through existing ontology, which is often limited in coverage of general concept space. In this paper, we propose automatically constructing the attribute vocabulary by mining latent topics from the click-through log of a commercial image search engine. These attributes are referred to as latent topic attributes (LTA), which take advantage of tens of millions of interactions between user submitted queries and images, thereby providing better coverage for the concept space than existing approaches. The mining of latent topics from the click log is formulated as a matrix factorization problem, and further improved by weighted terms-based matrix factorization to address the extreme sparsity of the click-through matrix. Both qualitative results of the mined LTA and quantitative results on the standard image recognition benchmark demonstrate the mined LTA's effectiveness.","Authors":"Lu, YJ (Lu, Yi-Jie) ; Yang, LJ (Yang, Linjun) ; Yang, KY (Yang, Kuiyuan) ; Rui, Y (Rui, Yong)","Title":"Mining Latent Attributes From Click-Through Logs for Image Recognition"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000354380200003 ISSN: 1385-951X eISSN: 1573-7667","Keywords":"Data mining; Change mining; Sequential patterns; Quantitative data; Fuzzy sets KeyWords Plus:QUANTITATIVE SEQUENTIAL PATTERNS; DISCOVERED ASSOCIATION RULES; LARGE DATABASES; KNOWLEDGE; INTERESTINGNESS; UNEXPECTEDNESS","Categories":"Information Science & Library Science; Business & Economics Web of Science Categories:Information Science & Library Science; Management","Journal Information":"INFORMATION TECHNOLOGY & MANAGEMENT Volume: 16 Issue: 2 Pages: 117-138 DOI: 10.1007/s10799-014-0197-x Published: JUN 2015","Abstract":"Identification of changes in customer behavior is a major challenge that must be tackled in order to survive in a rapidly changing business environment. For example, because information technology has advanced and data-storage costs have declined, for the purpose of serving customers, numerous enterprises have employed information systems and have directly logged customer behavior in databases. This trend has motivated the development of data mining applications. Fuzzy quantitative sequential pattern mining is a functional data mining technique that is used for discovering customer behavioral patterns over time and determining the quantities of goods or services they purchase. The example term used in shopping aOE (c)[(Beer, Low)(Milk, High)] (Cola, Middle)> means that customers will first buy Beer and Milk in Low and High quantities, respectively, and then purchase Cola in Middle quantities on their next shopping trip, where Low, Middle, and High are predefined linguistic terms assigned by managers. A term such as this one provides managers with general and concise knowledge related to customer behavior and allows them to rapidly make decisions in response, especially in a competitive setting. However, literature searches indicate that no previous study has addressed the issue of changes in fuzzy quantitative sequential patterns. The aforementioned example pattern might have been available last year but might not be used this year, and it could have been substituted by aOE (c)(Beer, Middle) {(Cola, Low)(Milk, Low)}>. If this knowledge is not renewed, managers might develop inappropriate marketing plans for their products or services and use inventory strategies that are outdated with respect to time and quantities. To solve this problem, we propose a novel change-mining model that can be used for detecting changes in fuzzy quantitative sequential patterns. We conducted experiments in which we used real-world and synthetic datasets in order to evaluate the proposed model. When the pattern change was detected using the real-world dataset, the results showed that the model reveals 3 considerations that can help managers with their handling of products' marketing and production. When we studied the model's scalability by using the synthetic dataset, the results showed that even though all run times increased when parameter values were decreased, the model remained scalable.","Authors":"Huang, CK (Huang, Cheng-Kui) ; Chang, TY (Chang, Ting-Yi) ; Narayanan, BG (Narayanan, Badri G.)","Title":"Mining the change of customer behavior in dynamic markets"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000352748900004 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Process comparison; Graph edit distance; Process mining; Stroke management KeyWords Plus:EDIT DISTANCE; BUSINESS; MODEL; RETRIEVAL; FRAMEWORK; WORKFLOWS; SUPPORT; SEARCH","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 42 Issue: 9 Pages: 4207-4215 DOI: 10.1016/j.eswa.2015.01.027 Published: JUN 1 2015","Abstract":"Process model comparison and similar processes retrieval are key issues to be addressed in many real world situations, and particularly relevant ones in some applications (e.g., in medicine), where similarity quantification can be exploited in a quality assessment perspective. Most of the process comparison techniques described in the literature suffer from two main limitations: (1) they adopt a purely syntactic (vs. semantic) approach in process activity comparison, and/or (2) they ignore complex control flow information (i.e., other than sequence). These limitations oversimplify the problem, and make the results of similarity-based process retrieval less reliable, especially when domain knowledge is available, and can be adopted to quantify activity or control flow construct differences. In this paper, we aim at overcoming both limitations, by introducing a framework which allows to extract the actual process model from the available process execution traces, through process mining techniques, and then to compare (mined) process models, by relying on a novel distance measure. The novel distance measure, which represents the main contribution of this paper, is able to address issues (1) and (2) above, since: (1) it provides a semantic, knowledge-intensive approach to process activity comparison, by making use of domain knowledge; (2) it explicitly, takes into account complex control flow constructs (such as AND and XOR splits/joins), thus fully considering the different semantic meaning of control flow connections in a reliable way. The positive impact of the framework in practice has been tested in stroke management, where our approach has outperformed a state-of-the art literature metric on a real world event log, providing results that were closer to those of a human expert. Experiments in other domains are foreseen in the future. (C) 2015 Elsevier Ltd. All rights reserved.","Authors":"Montani, S (Montani, Stefania) ; Leonardi, G (Leonardi, Giorgio) ; Quaglini, S (Quaglini, Silvana) ; Cavallini, A (Cavallini, Anna) ; Micieli, G (Micieli, Giuseppe) Group Author(s): Stroke Unit Network SUN Collaborat Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Cavallini, Anna  http://orcid.org/0000-0002-5227-1502","Title":"A knowledge-intensive approach to process similarity calculation"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000355670300007 ISSN: 2157-6904 eISSN: 2157-6912","Keywords":"Algorithms; Theory; Measurement; Correlation pattern; smart home; sequential pattern; time interval-based data; usage representation KeyWords Plus:INTERVAL-BASED EVENTS; TEMPORAL PATTERNS; SEQUENTIAL PATTERNS; ASSOCIATION RULES; DISCOVERY","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY Volume: 6 Issue: 3 Article Number: 35 DOI: 10.1145/2700484 Published: MAY 2015","Abstract":"Owing to the great advent of sensor technology, the usage data of appliances in a house can be logged and collected easily today. However, it is a challenge for the residents to visualize how these appliances are used. Thus, mining algorithms are much needed to discover appliance usage patterns. Most previous studies on usage pattern discovery are mainly focused on analyzing the patterns of single appliance rather than mining the usage correlation among appliances. In this article, a novel algorithm, namely Correlation Pattern Miner (CoPMiner), is developed to capture the usage patterns and correlations among appliances probabilistically. CoPMiner also employs four pruning techniques and a statistical model to reduce the search space and filter out insignificant patterns, respectively. Furthermore, the proposed algorithm is applied on a real-world dataset to show the practicability of correlation pattern mining.","Authors":"Chen, YC (Chen, Yi-Cheng) ; Peng, WC (Peng, Wen-Chih) ; Huang, JL (Huang, Jiun-Long) ; Lee, WC (Lee, Wang-Chien)","Title":"Significant Correlation Pattern Mining in Smart Homes"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000360877600028 PubMed ID: 26025101 ISSN: 1929-0748","Keywords":"health literacy; information literacy; computing literacy; consumer health; health informatics; K-12 education; adolescents; informal education; vulnerable populations; literacy programs KeyWords Plus:EHEALTH LITERACY; INFORMATION; FRAMEWORK; SKILLS; VALIDATION; CHILDREN; WORLD; WANT","Categories":"Health Care Sciences & Services Web of Science Categories:Health Care Sciences & Services","Journal Information":"JMIR RESEARCH PROTOCOLS Volume: 4 Issue: 2 Article Number: e62 DOI: 10.2196/resprot.4058 Published: APR-JUN 2015","Abstract":"Background: Although a low health literacy level has been found to be among the most powerful predictors of poor health outcomes, there is very little research focused on assessing and improving the health literacy skills of adolescents, particularly those from socioeconomically disadvantaged backgrounds. The vast majority of existing research focuses solely on reading comprehension, despite the fact that health literacy is actually a multifaceted concept, which entails many different types of skills. Objective: The aim of this paper is to first mine existing literature to identify the many different skills that have been posited to constitute health literacy, and then, using this collection of skills as an overarching structure, to highlight the challenges that disadvantaged youth participating in our HackHealth after-school program encounter as they identify and articulate their health-related information needs, search for health-related information online, assess the relevance and credibility of this information, and manage and make use of it. Methods: We utilized the design-based research method to design, implement, and revise our HackHealth program. To collect data regarding HackHealth participants' health literacy skills and associated challenges, we used a variety of methods, including participant observation, surveys, interviews, focus groups, and logging of Web browser activities. We also collected data through specialized instructional activities and data collection forms that we developed for this purpose. Quantitative and qualitative techniques were used to analyze this data, as well as all of the artifacts that each student produced, including their final projects. Results: We identified the various challenges that the 30 HackHealth participants faced in completing various health-related information activities during the course of the program. Based on these findings, we describe important implications for working with youth from socioeconomically disadvantaged backgrounds, how to assess and improve their health literacy skills, and offer specific recommendations for health literacy instruction aimed at this population. Conclusions: With an increased societal focus on health and a shift from viewing patients as passive recipients of medical care to viewing them as active arbiters of their own health, today's youth need to possess an array of health literacy skills to ensure that they can live long and healthy lives. Working with adolescents to help them develop and practice these skills will also help to break the cycle between poor health literacy and poor health outcomes, thereby reducing health disparities and improving the long-term outlook for the health of our nation.","Authors":"Subramaniam, M (Subramaniam, Mega) ; St Jean, B (St Jean, Beth) ; Taylor, NG (Taylor, Natalie Greene) ; Kodama, C (Kodama, Christie) ; Follman, R (Follman, Rebecca) ; Casciotti, D (Casciotti, Dana)","Title":"Bit by Bit: Using Design-Based Research to Improve the Health Literacy of Adolescents"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000354532200002 ISSN: 1570-8268","Keywords":"Semantic relationships; Search logs; Social annotations; Large-scale web data KeyWords Plus:MODEL","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"JOURNAL OF WEB SEMANTICS Volume: 31 Pages: 27-38 DOI: 10.1016/j.websem.2014.11.004 Published: MAR 2015","Abstract":"With the emergence of Web 2.0, the amount of user-generated web data has sharply increased. Thus, many studies have proposed techniques to extract wisdom from these user-generated datasets. Some of these works have focused on extracting semantic relationships through the use of search logs or social annotations, but only hierarchical relationships have been considered. The goal of this paper is to detect various semantic relationships (hierarchical and non-hierarchical) between concepts using search logs and social annotations. The experimental results demonstrate that our proposed approach constructs adequate relationships. (C) 2014 Elsevier B.V. All rights reserved.","Authors":"Hsu, PL (Hsu, Pei-Ling) ; Hsieh, HS (Hsieh, Hsiao-Shan) ; Liang, JH (Liang, Jheng-He) ; Chen, YS (Chen, Yi-Shin)","Title":"Mining various semantic relationships from unstructured user-generated web data"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380559200026 ISBN:978-1-4799-1919-2","Keywords":"menu optimization; automated teller machine; ATM; mixed integer programming","Categories":"Computer Science Web of Science Categories:Computer Science, Software Engineering","Journal Information":"2015 IEEE INTERNATIONAL SYMPOSIUM ON SYSTEMS ENGINEERING (ISSE) PROCEEDINGS Pages: 163-169 Published: 2015","Abstract":"The use of optimal ATM menu structuring for different customer profiles is essential because of usability, efficiency, and customer satisfaction. Especially in competitive industries such as banking, having optimal user interface (UI) is a must. Determining the optimal menu structure is generally accomplished through manual adjustment of the menu elements. However, such an approach is inherently flawed due to the overwhelming size of the optimization variables' search space. Previous studies on menu optimization either are based on customer questionnaires or made for only a specific menu type using heuristic approaches (i.e., not generic). In this paper, we propose an systematic optimization method for menu structuring problem through a novel Mixed Integer Programming (MIP) framework. Our optimization approach is not specific to a predetermined menu class, on the contrary, the MIP model is designed to be a generic optimization framework that can be applied to a wide range of menu optimization problems. We evaluated the performance gains on a dataset of actual ATM usage logs for a period of 18 months consisting of 40 million transactions. We validated our results with both simulation application and mining of existing data logs. The results show that the proposed optimization approach provides significant reduction in the average transaction completion time and the overall click count.","Authors":"Karimov, J (Karimov, Jeyhun) ; Ozbayoglu, M (Ozbayoglu, Murat) ; Tavli, B (Tavli, Bulent) ; Dogdu, E (Dogdu, Erdogan) Book Group Author(s):IEEE","Title":"Generic Menu Optimization for Multi-profile Customer Systems"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380573800059 ISBN:978-1-4673-9781-0","Keywords":"Community mining; pattern clustering; text snippets; page count KeyWords Plus:LOGS","Categories":"Science & Technology - Other Topics; Engineering Web of Science Categories:GREEN & SUSTAINABLE SCIENCE & TECHNOLOGY; Engineering, Multidisciplinary; Engineering, Electrical & Electronic","Journal Information":"PROCEEDINGS OF 2015 ONLINE INTERNATIONAL CONFERENCE ON GREEN ENGINEERING AND TECHNOLOGIES (IC-GET) Published: 2015","Abstract":"Web mining involve activities such as document clustering, community mining etc., to be performed on web. Such tasks need measuring semantic similarity between word. This helps in performing web mining activities easily in many applications. The accurate measures of semantic similarity between any two words is the difficult task. A new approach to measure similarity between words is based on text snippets and page count. These two measures are taken from the results of a search engine like Google. The lexical patterns are extracted from text snippets and word co-occurrence measures are defined using page count. The results of these two are combined. Moreover, the pattern clustering and pattern extraction algorithm are used to find various relationships between any two given words. Support Vector Machines is used to optimize the result. The empirical results reveal that the techniques are finding the best results that can be compared with human ratings and accuracy in web mining activity. Semantic similarity refers to the concept by which a set of document or words within the document are assigned a weight based on their meaning. The accurate measurement of such similarity plays an important role in Natural language Processing.","Authors":"Murugesan, P (Murugesan, P.) ; Malathi, K (Malathi, K.) Book Group Author(s):IEEE","Title":"Efficient Search Engine Approach for Measuring Similarity between words Using Page Count and Snippets"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380581601107 ISBN:978-1-5108-1790-6","Keywords":"conversational understanding systems; relation detection; search query click logs; unsupervised learning; semantic graph","Categories":"Acoustics; Computer Science Web of Science Categories:Acoustics; Computer Science, Interdisciplinary Applications","Journal Information":"16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5 Pages: 2714-2718 Published: 2015","Abstract":"Traditional methods for building spoken language understanding systems require manual rules or annotated data, which are expensive. In this work, we present an unsupervised method for bootstrapping a relation classifier, which identifies the knowledge graph relations present in an input query. Unlike existing work, we utilize only one knowledge graph entity instead of two for mining relevant query patterns from query click logs. As a result, the mined patterns can be used to infer both explicit relations (where the objects of the relations are expressed in the queries) and implicit relations (where the objects of the relations are being asked about). Using only the mined queries, the final classifier achieves an F-measure of 55.5%, which is significantly higher than the previous unsupervised learning baselines.","Authors":"Pasupat, P (Pasupat, Panupong) ; Hakkani-Tur, D (Hakkani-Tur, Dilek) Book Group Author(s):ISCA-INT SPEECH COMMUN ASSOC","Title":"Unsupervised Relation Detection using Automatic Alignment of Query Patterns Extracted from Knowledge Graphs and Query Click Logs"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380462000251 ISBN:978-1-4799-6818-3","Keywords":"SERP; Top K-query; World Wide Web; Data-based approach; Web mining","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic","Journal Information":"2015 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS) Published: 2015","Abstract":"In recent years, it has been witnessed that the ever-interesting and upcoming publishing medium is the World Wide Web. Much of the web content is unstructured so gathering and making sense of such data is very tedious. Web servers worldwide generate a vast amount of information on web users' browsing activities. Several researchers have studied these so-called web access log data to better understand and characterize web users. Data can be enriched with information about the content of visited pages and the origin (e.g., geographic, organizational) of the requests. The goal of this project is to analyze user behavior by mining enriched web access log data. The several web usage mining methods for extracting useful features is discussed and employ all these techniques to cluster the users of the domain to study their behaviors comprehensively. The contributions of this thesis are a data enrichment that is content and origin based and a treelike visualization of frequent navigational sequences. This visualization allows for an easily interpretable tree-like view of patterns with highlighted relevant information. The results of this project can be applied on diverse purposes, including marketing, web content advising, (re-) structuring of web sites and several other E-business processes, like recommendation and advertiser systems. It also rank the best relevant documents based on Top K query for effective and efficient data retrieval system. It filters the web documents by providing the relevant content in the search engine result page (SERP).","Authors":"Dhivya, G (Dhivya, G.) ; Deepika, K (Deepika, K.) ; Kavitha, J (Kavitha, J.) ; Kumari, VN (Kumari, V. Nithya) Edited by:Nagaraj, B; Francis, GA","Title":"ENRICHED CONTENT MINING FOR WEB APPLICATIONS"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380462000197 ISBN:978-1-4799-6818-3","Keywords":"Video surveillance; face detection; quality filters; video event analysis; face log KeyWords Plus:HEAD POSE ESTIMATION","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic","Journal Information":"2015 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS) Published: 2015","Abstract":"Video Surveillance system records the events happens 24 hours, every day. Investigator needs to search video streams manually for evidence when an incident occurs. Log of interesting events is useful for investigator for analysis of video events. Face logging system consists of face image of individuals entering in surveillance area. The aim of system proposed in this paper, is to maintain log of visitor faces entering in surveillance area. System consists of face detection[4] and extraction, face log maintenance in database. For face detection Haar features are used and adaboost is used to get strong classifier for detection. Before applying Haar features, Probability based face mask prefiltering(PFMPF)[2] is used which can filter out more than 85% nonface images from an video frame. Use of PFMPF helps to reduce training period for face detection. Saving only the best face images of each target ensures that forensic analysis will not be overwhelmed with many redundant images of the same target. After face detection, quality filters are applied of face images to get best quality face image. Also log can be used to classify authenticated and unauthenticated faces entering in surveillance area if face recognition is implemented.","Authors":"Momin, BF (Momin, B. F.) ; Jere, YR (Jere, Y. R.) Edited by:Nagaraj, B; Francis, GA","Title":"Mining Visitors in Video Surveillance System"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000381554300040 ISBN:978-9-3805-4416-8","Keywords":"Search engines; QA system; Data mining; Association rule mining; A-priori algorithm","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Software Engineering","Journal Information":"2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM) Pages: 211-215 Published: 2015","Abstract":"In a Question Answering system, the user submits a question and waits for the answer as the response. If the system is capable of predicting the user's future interest as the next question, its performance will improve greatly. This paper predicts users' future questions based on the current interaction records of the user with the system. Their current interactions with the system show what they are interested in. These interaction records are maintained in the form of Questions log from which the user sessions are extracted. Based on the user sessions, the system predicts the next question for which the user may become interested in near future. A sample Questions Log is selected for the purpose of performing experiments. The model of Association rule mining is applied to predict the future question of the user","Authors":"Madaan, R (Madaan, Rosy) ; Sharma, AK (Sharma, A. K.) ; Dixit, A (Dixit, Ashutosh) Edited by:Hoda, MN","Title":"A Data Mining approach to predict users' Next Question in QA system"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000382307300028 ISBN:978-1-4503-3621-5","Keywords":"Entity aspects; Query intent; Semantic search KeyWords Plus:QUERIES","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL Pages: 263-272 DOI: 10.1145/2766462.2767724 Published: 2015","Abstract":"Entity queries constitute a large fraction of web search queries and most of these queries are in the form of an entity mention plus some context terms that represent an intent in the context of that entity. We refer to these entity-oriented search intents as entity aspects. Recognizing entity aspects in a query can improve various search applications such as providing direct answers, diversifying search results, and recommending queries. In this paper we focus on the tasks of identifying, ranking, and recommending entity aspects, and propose an approach that mines, clusters, and ranks such aspects from query logs. We perform large-scale experiments based on users' search sessions from actual query logs to evaluate the aspect ranking and recommendation tasks. In the aspect ranking task, we aim to satisfy most users' entity queries, and evaluate this task in a query-independent fashion. We find that entropy-based methods achieve the best performance compared to maximum likelihood and language modeling approaches. In the aspect recommendation task, we recommend other aspects related to the aspect currently being queried. We propose two approaches based on semantic relatedness and aspect transitions within user sessions and find that a combined approach gives the best performance. As an additional experiment, we utilize entity aspects for actual query recommendation and find that our approach improves the effectiveness of query recommendations built on top of the query-flow graph.","Authors":"Reinanda, R (Reinanda, Ridho) ; Meij, E (Meij, Edgar) ; de Rijke, M (de Rijke, Maarten) Book Group Author(s):ACM","Title":"Mining, Ranking and Recommending Entity Aspects"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380557400113 ISBN:978-1-4799-6959-3","Keywords":"Click-through Data Mining; Named Entity Mining","Categories":"Engineering; Telecommunications Web of Science Categories:Engineering, Electrical & Electronic; Telecommunications","Journal Information":"2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC) Pages: 618-624 Published: 2015","Abstract":"Nowadays, search engines have become indispensable parts of modern human life, which create hundreds and thousands of search logs every second throughout the world. With the explosive growth of online information, a key issue for web search service is to better understand user's need through the short search query to match the user's preference as much as possible. However, due to the lack of the personal information in some scenario and the huge calculation when seeking for relevant user group, personalized search becomes a quite a challenging problem. In this work, we propose a novel scalable framework based on multimodal Restricted Boltzmann Machine (RBM) to do the user intent mining and prediction. This scalable framework works in an unsupervised manner, and is flexible to various situations regardless of the amount of individual information, in other words, it can handles scenarios without personal history information or limited personal history information, the more individual data the better accuracy of user intent prediction and more capable to reflect the individual's interests changing. The framework outputs a binary representation for each query log, thus to some extent, could solve data sparsity problem and reduce the computation complexity when looking for users with similar interests. The experiment results shown that, the model can learn reasonable user intent category during the learning procedure, according to the qualitative analysis of the top ranked context and websites for each class. And it can get a competitive performance when no individual data is offered. Moreover, by offering more individual data (10 history queries), the overall performance improves up to 10% of precision.","Authors":"Shang, Y (Shang, Yue) ; Ding, WY (Ding, Wanying) ; Liu, MW (Liu, Mengwen) ; Song, XL (Song, Xiaoli) ; Hu, T (Hu, Tony) ; An, Y (An, Yuan) ; Wang, HH (Wang, Haohong) ; Guo, LF (Guo, Lifan) Book Group Author(s):IEEE","Title":"Scalable User Intent Mining using a Multimodal Restricted Boltzmann Machine"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380613500073 ISBN:978-1-4503-3552-2","Keywords":"Web Search; Personalization; Web Usage; Clustering; Classification; Data mining; Web logs KeyWords Plus:RETRIEVAL EFFECTIVENESS","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015) Pages: 376-383 DOI: 10.1145/2818567.2818677 Published: 2015","Abstract":"The increases in the information resources on the World Wide Web in search of the necessary information, as users navigate the Web with multiple sites. When user surfing the web which is a huge and complicated often miss their required searching pages. Web personalization is based on the Web usage logs of user's makes advantage of the knowledge required for the analysis of the content and structure of web sites promising to solve this problem by supporting one of the procedures. The search engine can affect the effectiveness of existing approaches, depending on the user profile, which is building more and more on the web pages or documents. In this paper, we propose an efficient and novel web search based on the individual classification and clustering method. The proposed approach classified the cluster data using frequent pattern mining and multilevel association rules for recurring relationship and cluster the web usage using Hierarchical methods with the navigating site and user interest for personalization. This approach process in advance to support the real time personalization and minimizes the cost reduction of preparation personalization resource in real time. The proposed approach is an effective personalization to the user's interest; in experimental research it has shown high precision measures.","Authors":"Vijayalakshmi, K (Vijayalakshmi, K.) ; Jena, S (Jena, Sudarson) Book Group Author(s):ACM","Title":"Web Usage Classification and Clustering Approach for Web Search Personalization"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380514500299 ISBN:978-1-5090-0154-5","Keywords":"proxy; mining; logs; AGD; botnet; heuristics","Categories":"Computer Science Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods","Journal Information":"CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING Pages: 1990-1997 DOI: 10.1109/CIT/IUCC/DASC/PICOM.2015.295 Published: 2015","Abstract":"Botnets are considered one of the most dangerous species of network-based attack today because they involve the use of very large coordinated groups of hosts simultaneously. The behavioral analysis of computer networks is at the basis of the modern botnet detection methods, in order to intercept traffic generated by malwares for which signatures do not exist yet. Defining a pattern of features to be placed at the basis of behavioral analysis, puts the emphasis on the quantity and quality of information to be caught and used to mark data streams as normal or abnormal. The problem is even more evident if we consider extensive computer networks or clouds. With the present paper we intend to show how heuristics applied to large-scale proxy logs, considering a typical phase of the life cycle of botnets such as the search for C&C Servers through AGDs (Algorithmically Generated Domains), may provide effective and extremely rapid results. The present work will introduce some novel paradigms. The first is that some of the elements of the supply chain of botnets could be completed without any interaction with the Internet, mostly in presence of wide computer networks and/or clouds. The second is that behind a large number of workstations there are usually \"human beings\" and it is unlikely that their behaviors will cause marked changes in the interaction with the Internet in a fairly narrow time frame. Finally, AGDs can highlight, at the moment, common lexical features, detectable quickly and without using any black/white list.","Authors":"Bottazzi, G (Bottazzi, Giovanni) ; Italiano, GF (Italiano, Giuseppe F.) Edited by:Wu, YL; Min, GY; Georgalas, N; Hu, J; Atzori, L; Jin, XL; Jarvis, S; Liu, L; Calvo, RA","Title":"Fast Mining of Large-Scale Logs for Botnet Detection: A Field Study"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380570600050 ISBN:978-1-4799-7904-2 ISSN: 1550-445X","Keywords":"Traffic Flow Extraction; Entropy; Traffic Flow Classification; Behavior Analysis","Categories":"Computer Science; Telecommunications Web of Science Categories:Computer Science, Hardware & Architecture; Computer Science, Information Systems; Telecommunications","Journal Information":"2015 IEEE 29th International Conference on Advanced Information Networking and Applications (IEEE AINA 2015) Book Series: International Conference on Advanced Information Networking and Applications Pages: 358-364 DOI: 10.1109/AINA.2015.207 Published: 2015","Abstract":"This paper presents an iterative visualization technique including the timeline and parallel coordinates to illustrate network communication for forensic analysis. In primarily analysis process, the timeline of events is reconstructed from traffic logs. An analyst can track the related anomaly event on-demand. In addition the details of abnormal and normal activities are shown in multiple dimensions of parallel coordinates. The novelty of this research is not a presentation of the timeline and parallel coordinates technique, but iterative visualization framework to illustrate both anomaly traffic and application traffic pattern. We applied frequent item-set mining to search dominant traffic flow and classify them by traffic flow shape and entropy. Although some studies have been applied frequent itemset mining with traffic dataset, but as we have known, this is the first research to 1) take advantages of the frequent item-set mining and parallel coordinates, which allow us to find both the anomaly traffic and application traffic and it can easily understand the patterns of traffic flow with the multi-dimensional visualization, and 2) classify the application traffic from the entropy values of traffic flow discovered by frequent item-set mining. This method is able to classify the encrypted traffic data and it does not violate a user privacy. The results of this research and development of a visual network communication tool can: 1) show abnormalities and normal communication activities, 2) have application traffic classification 92% accurate, 3) be a visual network communication prototype which helps an analyst to find the cause of the network malfunction.","Authors":"Promrit, N (Promrit, Nuttachot) ; Mingkhwan, A (Mingkhwan, Anirach) Edited by:Barolli, L; Takizawa, M; Xhafa, F; Enokido, T; Park, JH","Title":"Traffic Flow Classification and Visualization for Network Forensic Analysis"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380479200001 ISBN:978-1-4799-7935-6 ISSN: 2325-6516","Keywords":"Web Services; Discovery; Ranking; Association Rule Mining; Semantic FP-Growth; Semantic Logs","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems","Journal Information":"2015 IEEE 9TH INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC) Book Series: IEEE International Conference on Semantic Computing Pages: 1-8 Published: 2015","Abstract":"Ranking and Adaptation (used interchangeably) is often carried out using functional and non-functional information of Web Services. Such approaches are dependent on heavy and rich semantic descriptions as well as unstructured and scattered information about any past interactions between clients and Web Services. Existing approaches are either found to be focusing on semantic modeling and representation only, or using data mining and machine learning based approaches on unstructured and raw data to perform discovery and ranking. We propose a novel approach to allow semantically empowered representation of logs during Web Service execution and then use such logs to perform ranking and adaptation of discovered Web Services. We have found that combining both approaches together into a hybrid approach would enable formal representation of Web Services data which would boost data mining as well as machine learning based solutions to process such data. We have built Semantic FP-Trees based technique to perform association rule learning on functional and non-functional characteristics of Web Services. The process of automated execution of Web Services is improved in two steps, i.e., (1) we provide semantically formalized logs that maintain well-structured and formalized information about past interactions of Services Consumers and Web Services, (2) we perform an extended association rule mining on semantically formalized logs to find out any possible correlations that can used to pre-filter Web Services and reduce search space during the process of automated ranking and adaptation of Web Services. We have conducted comprehensive evaluation to demonstrate the efficiency, effectiveness and usability of our proposed approach.","Authors":"Shafiq, O (Shafiq, Omair) ; Alhajj, R (Alhajj, Reda) ; Rokne, JG (Rokne, Jon G.) Edited by:Kankanhalli, MS; Li, T; Wang, W","Title":"Reducing Search Space for Web Service Ranking using Semantic Logs and Semantic FP-Tree based Association Rule Mining"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380493300134 ISBN:978-1-4799-8047-5 ISSN: 2164-8263","Keywords":"Indexing; Tweets; Text Mining; Searching; Apache Lucene; Opinion Mining; Document Analysis","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2015 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE (IACC) Book Series: IEEE International Advance Computing Conference Pages: 681-685 Published: 2015","Abstract":"This paper presents analysis of text based data retrieval system and opinion mining on social networking website. This data is collected from various sources like local machine, email accounts, social networking accounts of respective user. Multiple users can use this system by providing log in credentials. This paper explains significance of Inverse Document Frequency and Term Frequency in Lucene scoring formula. Most of the people express their correct reviews on social networking websites than any other discussion forums. This paper discusses an approach to classify each tweet from Twitter into positive, negative or neutral category. This paper also presents techniques to improve performance of Lucene by modifying certain parameters of document scoring formula. Lucene performance also can be improved by modifying algorithm for incremental indexing and parallel processing. The purpose of developing such system is to reduce manual efforts of searching to greater extent. This system is portable and secure.","Authors":"Wani, SS (Wani, Saurabh S.) ; Patil, YN (Patil, Y. N.) Book Group Author(s):IEEE","Title":"Analysis of Data Retrieval and Opinion Mining System"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380470400084 ISBN:978-1-5090-1949-6","Keywords":"Adaptive Web Sites; Navigation Pattern Mining; Recommender System; Web-Based Recommendation Systems; Web Log; Web Mining; Web Personalization; Web Usage Mining KeyWords Plus:INFORMATION; SYSTEMS","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic","Journal Information":"2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS) Pages: 552-560 Published: 2015","Abstract":"Nowadays, users rely on the web for information gathering. Accordingly, web usage mining becomes one important subject of research. Such research area covers prediction of user near future intentions, web-based personalized services, customer profiling, and adaptive web sites. Web page prediction is strongly limited by the nature of web logs, the intrinsic complexity of the problem and the tight efficiency requirements. This paper proposes a hybrid page ranking model based on web usage mining technique by exploiting session data of users, to enhance the recommendations of the next candidate web page to be accessed. The proposed approach represents a combination between two page ranking approaches. The first one computes the frequency ratio indicating the number of occurrences of each page in the search result. On the other hand, the second approach computes the coverage ratio from similar behavior patterns. As a result of the proposed approach, a set of candidate pages are ranked and the page with highest rate is recommended. The proposed approach has been tested on real data collected and extracted from the web server log file of CTI main web server.","Authors":"Al-Yazeed, NMA (Al-Yazeed, No'aman M. Abo) ; Gadallah, AM (Gadallah, Ahmed M.) ; Hefny, HA (Hefny, Hesham A.) Book Group Author(s):IEEE","Title":"A Hybrid Recommendation Model for Web Navigation"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380528400017 ISBN:978-1-4799-1819-5","Keywords":"Semantic Web; Web usage mining; Log ontology; hybrid knowledge base; frequent pattern","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic","Journal Information":"2015 International Conference on Computer and Computational Sciences (ICCCS) Pages: 105-109 Published: 2015","Abstract":"Discovering frequent patterns from ontologies has become a central topic in the Semantic Web. To find more efficient frequent web access patterns, the hybrid reasoning framework Datalog(SHIQ(D)) is defined to express log ontology knowledge base, in which DL language SHIQ(D) and restricted datalog rules are combined with the basic datalog safeness. After introducing the expression of web access pattern and the tasks to the mining problem, an ILP approach is illustrated to generate the candidate frequent web access pattern set by breadth-first expansion. The experimental results show that our approach can discover more expressive web usage information without increasing calculation complexity compared with previous work.","Authors":"Sun, M (Sun, Ming) ; Kang, WJ (Kang, Wen Jie) ; Chen, B (Chen, Bo) Book Group Author(s):IEEE","Title":"A Level-wise Search Approach to Frequent WebAccess Pattern Discovery with Hybrid Reasoning"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380407300125 ISBN:978-1-4799-6272-3","Keywords":"(Average Precision); CAP (Classified Average Precision); data mining; feedback session; goal; log; Query Suggestion","Categories":"Engineering Web of Science Categories:Engineering, Electrical & Electronic","Journal Information":"2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC) Published: 2015","Abstract":"The goal of the user at the time of searching the data is unknown to the system. The important aspect of searching process is to first recognize the user goal. On the basis of the recognized goal results are shown to the user. The goal identification requirement can be fulfilled by using pseudo document and feedback session. Click through logs are used to create feedback session. Pseudo document is the revised version of feedback session for clustering the websites. This paper reviews many web mining techniques for inferring the user goals. Query suggestion techniques are examined in this. It also studies the comparison of list and category methods of search result which helps to select the best method.","Authors":"Bhambure, H (Bhambure, Harshada) ; Mokashi, M (Mokashi, Mandar) Book Group Author(s):IEEE","Title":"A Survey on Inferring User Search Goals using Feedback Session"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380547600006","Keywords":"Weighted Bipartite Network; User Access Permeability; User Usage Rate; User Access Viscosity; Web Geographic Information Systems KeyWords Plus:MODEL","Categories":"Computer Science; Physical Geography; Remote Sensing; Imaging Science & Photographic Technology Web of Science Categories:Computer Science, Interdisciplinary Applications; Geography, Physical; Remote Sensing; Imaging Science & Photographic Technology","Journal Information":"ISPRS International Workshop on Spatiotemporal Computing Pages: 137-141 DOI: 10.5194/isprsannals-II-4-W2-137-2015 Published: 2015","Abstract":"With the rapid development of geographic information services, Web Geographic Information Systems (WebGIS) have become an indispensable part of everyday life; correspondingly, map search engines have become extremely popular with users and WebGIS sites receive a massive volume of requests for access. These WebGIS users and the content accessed have regional characteristics; to understand regional patterns, we mined regional WebGIS user access patterns based on a weighted bipartite network. We first established a weighted bipartite network model for regional user access to a WebGIS. Then, based on the massive user WebGIS access logs, we clustered geographic information accessed and thereby identified hot access areas. Finally we quantitatively analyzed the access interests of regional users and the visitation volume characteristics of regional user access to these hot access areas in terms of user access permeability, user usage rate, and user access viscosity. Our research results show that regional user access to WebGIS is spatially aggregated, and the hot access areas that regional users accessed are associated with specific periods of time. Most regional user contact with hot accessed areas is variable and intermittent but for some users, their access to certain areas is continuous as it is associated with ongoing or recurrent objectives. The weighted bipartite network model for regional user WebGIS access provides a valid analysis method for studying user behaviour in WebGIS and the proposed access pattern exhibits access interest of regional user is spatiotemporal aggregated and presents a heavy-tailed distribution. Understanding user access patterns is good for WebGIS providers and supports better operational decision-making, and helpful for developers when optimizing WebGIS system architecture and deployment, so as to improve the user experience and to expand the popularity of WebGIS.","Authors":"Li, R (Li, R.) ; Shen, Y (Shen, Y.) ; Huang, W (Huang, W.) ; Wu, H (Wu, H.) Edited by:Yang, C; Clarke, K; Yuan, M; Yu, M; Li, M; Guan, W; Sun, M; Huang, B","Title":"Regional WebGIS User Access Patterns based on a Weighted Bipartite Network"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380393400039 ISBN:978-1-4799-8488-6 ISSN: 2327-0632","Keywords":"clickstream; e-commerce; mining techniques; search engine; personalised recommendations; banking; webpage importance; user session; mobile search engine","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"2015 5TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING & COMMUNICATION TECHNOLOGIES ACCT 2015 Book Series: International Conference on Advanced Computing & Communication Technologies Pages: 208-211 DOI: 10.1109/ACCT.2015.115 Published: 2015","Abstract":"the ongoing increase in the usage of web has led to accumulation of large amounts of data every second. This has in turn made the research industry to grow and focus towards employing web usage mining for increasing the revenues for businesses, carrying out analysis on browsing behavior of web users, improving website layout and much more. Web usage mining is becoming increasingly popular due to the huge amounts of benefits it offers. The most significant amount of information about the web usage by the users is contained in log files usually called as server log files. The clicks made by the user, the order in which they are made and the time spent on each web page is all contained in these logs and is referred to as clickstream data or clickpath data. An attempt has been made through this paper to provide a holistic view as to what clickstream data analysis is, how mining techniques are applied on such data to generate useful information and what kind of applications exploit it to get useful information.","Authors":"Aggarwal, S (Aggarwal, Saloni) ; Mangat, V (Mangat, Veenu) Book Group Author(s):IEEE","Title":"Application Areas of Web Usage Mining"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380472200121 ISBN:978-1-5090-0022-7","Keywords":"query recommendation; log mining; irrelevant feedback; machine learning KeyWords Plus:USER LOGS","Categories":"Engineering Web of Science Categories:Engineering, Biomedical","Journal Information":"2015 8TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI) Pages: 644-648 Published: 2015","Abstract":"Similarity computation among queries is a central step of query recommendation based on click information in search log. In this step, weights of clicked URLs or clicked document terms, which may have a large influence on similarity computation results, are mostly counted based on co-occurrence. However, counting weights based on co-occurrence are unusually disturbed by irrelevant feedbacks in search log, which may decrease the precision of query similarity computation. This paper proposes a method that computes similarity among queries based on \"Query - Clicked Sequence\" model, which counts weight of clicked document term by density of documents containing this term on clicked sequence, and filters content of irrelevant documents during similarity computation. A series of experiment results show that this method can precisely count the weights of terms, and increase the precision of query similarity computation, accordingly increase the precision of query recommendation.","Authors":"Zhang, B (Zhang, Bo) ; Zhang, B (Zhang, Bin) ; Zhang, SB (Zhang, Shubo) ; Ma, C (Ma, Chao) Edited by:Bai, L; Wang, L; Shao, L; Sun, J; Tao, Z; Lin, S","Title":"Query Recommendation Based on Irrelevant Feedback Analysis"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380486400014 ISBN:978-1-4673-7272-5","Keywords":"missing events; heuristic recovery; Petri nets; process decomposition; trace replaying KeyWords Plus:CONFORMANCE CHECKING; WORKFLOW; NETS","Categories":"Engineering Web of Science Categories:Engineering, Electrical & Electronic","Journal Information":"2015 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS) Pages: 105-112 DOI: 10.1109/ICWS.2015.24 Published: 2015","Abstract":"Event logs are of paramount significance for process mining and complex event processing. Yet, the quality of event logs remains a serious problem. Missing events of logs are usually caused by omitting manual recording, system failures, and hybrid storage of executions of different processes. It has been proved that the problem of minimum recovery based on a priori process specification is NP-hard. State-of-the-art approach is still lacking in efficiency because of the large search space. To address this issue, in this paper, we leverage the technique of process decomposition and present heuristics to efficiently prune the unqualified sub-processes that fail to generate the minimum recovery. We employ real-world processes and their incomplete sequences to evaluate our heuristic approach. The experimental results demonstrate that our approach achieves high accuracy as the state-of-the-art approach does, but it is more efficient.","Authors":"Song, W (Song, Wei) ; Xia, XX (Xia, Xiaoxu) ; Jacobsen, HA (Jacobsen, Hans-Arno) ; Zhang, PC (Zhang, Pengcheng) ; Hu, H (Hu, Hao) Book Author(s):Zhu, H (Zhu, H) Edited by:Miller, JS","Title":"Heuristic Recovery of Missing Events in Process Logs"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000380404600401 ISBN:978-1-4799-9925-5","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA Pages: 2951-2953 Published: 2015","Abstract":"As the ability to store and process massive amounts of user behavioral data increases, new approaches continue to arise for leveraging the wisdom of the crowds to gain insights that were previously very challenging to discover by text mining alone. For example, through collaborative filtering, we can learn previously hidden relationships between items based upon users' interactions with them, and we can also perform ontology mining to learn which keywords are semantically-related to other keywords based upon how they are used together by similar users as recorded in search engine query logs. The biggest challenge to this collaborative filtering approach is the variety of noise and outliers present in the underlying user behavioral data. In this paper we propose a novel approach to improve the quality of semantic relationships extracted from user behavioral data. Our approach utilizes millions of documents indexed into an inverted index in order to detect and remove noise and outliers.","Authors":"AlJadda, K (AlJadda, Khalifeh) ; Korayem, M (Korayem, Mohammed) ; Grainger, T (Grainger, Trey) Edited by:Ho, H; Ooi, BC; Zaki, MJ; Hu, XH; Haas, L; Kumar, V; Rachuri, S; Yu, SP; Hsiao, MHI; Li, J; Luo, F; Pyne, S; Ogan, K","Title":"Improving the Quality of Semantic Relationships Extracted from Massive User Behavioral Data"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000368452404152 ISBN:978-1-4673-6997-8 ISSN: 1520-6149","Keywords":"speech recognition; pronunciation learning; data extraction; logistic regression","Categories":"Acoustics; Engineering Web of Science Categories:Acoustics; Engineering, Electrical & Electronic","Journal Information":"2015 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING (ICASSP) Book Series: International Conference on Acoustics Speech and Signal Processing ICASSP Pages: 4619-4623 Published: 2015","Abstract":"The pronunciation dictionary, or lexicon, is an essential component in an automatic speech recognition (ASR) system in that incorrect pronunciations cause systematic misrecognitions. It typically consists of a list of word-pronunciation pairs written by linguists, and a grapheme-to-phoneme (G2P) engine to generate pronunciations for words not in the list. The hand-generated list can never keep pace with the growing vocabulary of a live speech recognition system, and the G2P is usually of limited accuracy. This is especially true for proper names whose pronunciations may be influenced by various historical or foreign-origin factors. In this paper, we propose a language-independent approach to detect misrecognitions and their corrections from voice search logs. We learn previously unknown pronunciations from this data, and demonstrate that they significantly improve the quality of a production-quality speech recognition system.","Authors":"Kou, ZZ (Kou, Zhenzhen) ; Stanton, D (Stanton, Daisy) ; Peng, FC (Peng, Fuchun) ; Beaufays, F (Beaufays, Francoise) ; Strohman, T (Strohman, Trevor) Book Group Author(s):IEEE","Title":"FIX IT WHERE IT FAILS: PRONUNCIATION LEARNING BY MINING ERROR CORRECTIONS FROM SPEECH LOGS"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000373207200064 ISBN:978-1-4799-8322-3","Keywords":"Bayesian approach; Bayesian statistics; cluster analysis; correlation analysis; data mining; Web mining; Web server; Web traffic; log file analysis; e-commerce; Internet robot; Web bot; Web robot detection; Matlab KeyWords Plus:WEB; CLASSIFICATION","Categories":"Computer Science Web of Science Categories:Computer Science, Cybernetics","Journal Information":"2015 IEEE 2ND INTERNATIONAL CONFERENCE ON CYBERNETICS (CYBCONF) Pages: 365-370 Published: 2015","Abstract":"A large part of Web traffic on e-commerce sites is generated not by human users but by Internet robots: search engine crawlers, shopping bots, hacking bots, etc. In practice, not all robots, especially the malicious ones, disclose their identities to a Web server and thus there is a need to develop methods for their detection and identification. This paper proposes the application of a Bayesian approach to robot detection based on characteristics of user sessions. The method is applied to the Web traffic from a real e-commerce site. Results show that the classification model based on the cluster analysis with the Ward's method and the weighted Euclidean metric is very effective in robot detection, even obtaining accuracy of above 90%.","Authors":"Suchacka, G (Suchacka, Grazyna) ; Sobkow, M (Sobkow, Mariusz) Edited by:Jedrzejowicz, P; Nguyen, NT; Hong, TP; Czarnowski, I","Title":"Detection of Internet Robots Using a Bayesian Approach"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000372140603048 ISSN: 1742-6588","Categories":"Physics Web of Science Categories:Physics, Nuclear; Physics, Particles & Fields","Journal Information":"21ST INTERNATIONAL CONFERENCE ON COMPUTING IN HIGH ENERGY AND NUCLEAR PHYSICS (CHEP2015), PARTS 1-9 Book Series: Journal of Physics Conference Series Volume: 664 Article Number: 082036 DOI: 10.1088/1742-6596/664/8/082036 Published: 2015","Abstract":"A flexible monitoring system has been designed for the CMS File-based Filter Farm making use of modern data mining and analytics components. All the metadata and monitoring information concerning data flow and execution of the HLT are generated locally in the form of small documents using the JSON encoding. These documents are indexed into a hierarchy of elasticsearch (es) clusters along with process and system log information. Elasticsearch is a search server based on Apache Lucene. It provides a distributed, multitenant-capable search and aggregation engine. Since es is schema-free, any new information can be added seamlessly and the unstructured information can be queried in non-predetermined ways. The leaf es clusters consist of the very same nodes that form the Filter Farm thus providing natural horizontal scaling. A separate central\" es cluster is used to collect and index aggregated information. The fine-grained information, all the way to individual processes, remains available in the leaf clusters. The central es cluster provides quasi-real-time high-level monitoring information to any kind of client. Historical data can be retrieved to analyse past problems or correlate them with external information. We discuss the design and performance of this system in the context of the CMS DAQ commissioning for LHC Run 2.","Authors":"Andre, JM (Andre, J-M) ; Andronidis, A (Andronidis, A.) ; Behrens, U (Behrens, U.) ; Branson, J (Branson, J.) ; Chaze, O (Chaze, O.) ; Cittolin, S (Cittolin, S.) ; Darlea, GL (Darlea, G-L) ; Deldicque, C (Deldicque, C.) ; Dobson, M (Dobson, M.) ; Dupont, A (Dupont, A.) ; Erhan, S (Erhan, S.) ; Gigi, D (Gigi, D.) ; Glege, F (Glege, F.) ; Gomez-Ceballos, G (Gomez-Ceballos, G.) ; Hegeman, J (Hegeman, J.) ; Holzner, A (Holzner, A.) ; Jimenez-Estupinan, R (Jimenez-Estupinan, R.) ; Masetti, L (Masetti, L.) ; Meijers, F (Meijers, F.) ; Meschi, E (Meschi, E.) ; Mommsen, RK (Mommsen, R. K.) ; Morovic, S (Morovic, S.) ; Nunez-Barranco-Fernandez, C (Nunez-Barranco-Fernandez, C.) ; O'Dell, V (O'Dell, V.) ; Orsini, L (Orsini, L.) ; Paus, C (Paus, C.) ; Petrucci, A (Petrucci, A.) ; Pieri, M (Pieri, M.) ; Racz, A (Racz, A.) ; Roberts, P (Roberts, P.) ; Sakulin, H (Sakulin, H.) ; Schwick, C (Schwick, C.) ; Stieger, B (Stieger, B.) ; Sumorok, K (Sumorok, K.) ; Veverka, J (Veverka, J.) ; Zaza, S (Zaza, S.) ; Zejdl, P (Zejdl, P.) ...More...Less Book Group Author(s):IOP","Title":"A scalable monitoring for the CMS Filter Farm based on elasticsearch"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000371696701152 ISBN:978-1-4799-7929-5 ISSN: 2153-6996","Keywords":"Content-Based Retrieval; Remote Sensing; Elastic Cloud Computing; Big Data; Polarimetric SAR","Categories":"Engineering; Geology; Remote Sensing Web of Science Categories:Engineering, Electrical & Electronic; Geosciences, Multidisciplinary; Remote Sensing","Journal Information":"2015 IEEE INTERNATIONAL GEOSCIENCE AND REMOTE SENSING SYMPOSIUM (IGARSS) Book Series: IEEE International Symposium on Geoscience and Remote Sensing IGARSS Pages: 1488-1491 Published: 2015","Abstract":"Image mining consists of the procedures that allow to access, search and explore very large databases of data. Institutions like spatial agencies have to manage huge archives of Earth Observation (EO) images and need solutions to make data available to users from both the algorithmic and the infrastructural point of views. On the other side, users would need to explore the variety of images not just based on metadata, like time of acquisition or sensor parameters, but also by getting knowledge of their content. In this contribution, we investigate methodologies for content-based EO image retrieval via example-based queries. In particular, we present a procedure for the indexing of large-scale unstructured archives, built on top of a cluster analytics framework, Apache Spark. The procedure is based on a hierarchical and scalable implementation of a space partitioning algorithm and allows O(log n) response query times. Scalability analyses are conducted on polarimetric data from NASA/JPL archives, by using virtualized computing resources distributed over the Internet. In particular, the effects of the cluster size and of the hardware scale-up are demonstrated. The results also reveal the applicative potential of using on-demand cloud-based resources.","Authors":"Mascolo, L (Mascolo, Luigi) ; Quartulli, M (Quartulli, Marco) ; Nico, G (Nico, Giovanni) ; Guccione, P (Guccione, Pietro) ; Olaizola, IG (Olaizola, Igor G.) Book Group Author(s):IEEE","Title":"OPTIMISED DATA STRUCTURES FOR LARGE SCALE CONTENT-BASED GEO-INDEXING"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000369388300002 ISSN: 1468-4527 eISSN: 1468-4535","Keywords":"Information retrieval; Controlled vocabularies; Indexing languages; Keywords; Query logs KeyWords Plus:INFORMATION; TEXT; SEARCH; SYSTEM","Categories":"Computer Science; Information Science & Library Science Web of Science Categories:Computer Science, Information Systems; Information Science & Library Science","Journal Information":"ONLINE INFORMATION REVIEW Volume: 39 Issue: 7 Pages: 870-884 DOI: 10.1108/OIR-06-2015-0180 Published: 2015","Abstract":"Purpose - Controlled vocabularies play an important role in information retrieval. Numerous studies have shown that conceptual searches based on vocabularies are more effective than keyword searches, at least in certain contexts. Consequently, new ways must be found to improve controlled vocabularies. The purpose of this paper is to present a semi-automatic model for updating controlled vocabularies through the use of a text corpus and the analysis of query logs. Design/methodology/approach - An experimental development is presented in which, first, the suitability of a controlled vocabulary to a text corpus is examined. The keywords entered by users to access the text corpus are then compared with the descriptors used to index it. Finally, both the query logs and text corpus are processed to obtain a set of candidate terms to update the controlled vocabulary. Findings - This paper describes a model applicable both in the context of the text corpus of an online academic journal and to repositories and intranets. The model is able to: first, identify the queries that led users from a search engine to a relevant document; and second, process these queries to identify candidate terms for inclusion in a controlled vocabulary. Research limitations/implications - Ideally, the model should be used in controlled web environments, such as repositories, intranets or academic journals. Social implications - The proposed model directly improves the indexing process by facilitating the maintenance and updating of controlled vocabularies. It so doing, it helps to optimise access to information. Originality/value - The proposed model takes into account the perspective of users by mining queries in order to propose candidate terms for inclusion in a controlled vocabulary.","Authors":"Vallez, M (Vallez, Mari) ; Pedraza-Jimenez, R (Pedraza-Jimenez, Rafael) ; Codina, L (Codina, Lluis) ; Blanco, S (Blanco, Saul) ; Rovira, C (Rovira, Cristofol) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Fortes, Saul  Q-5723-2016 http://orcid.org/0000-0003-4581-414X Codina, Lluis  B-6369-2008 http://orcid.org/0000-0001-7020-1631 Pedraza-Jimenez, Rafael  B-1718-2008 http://orcid.org/0000-0002-6918-6910 Vallez, Mari  http://orcid.org/0000-0002-3284-2590","Title":"Updating controlled vocabularies by analysing query"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000367360300008 ISSN: 0860-7001 eISSN: 1689-0469","Keywords":"neural networks; applications in mining sciences; process modeling; systems modeling; machine learning; modeling of the oil mining process; forecasting of reservoir properties KeyWords Plus:WELL-LOGS; CLASSIFICATION","Categories":"Mining & Mineral Processing Web of Science Categories:Mining & Mineral Processing","Journal Information":"ARCHIVES OF MINING SCIENCES Volume: 60 Issue: 4 Pages: 971-984 DOI: 10.1515/amsc-2015-0064 Published: 2015","Abstract":"The many difficult problems that must now be addressed in mining sciences make us search for ever newer and more efficient computer tools that can be used to solve those problems. Among the numerous tools of this type, there are neural networks presented in this article which, although not yet widely used in mining sciences, are certainly worth consideration. Neural networks are a technique which belongs to so called artificial intelligence, and originates from the attempts to model the structure and functioning of biological nervous systems. Initially constructed and tested exclusively out of scientific curiosity, as computer models of parts of the human brain, neural networks have become a surprisingly effective calculation tool in many areas: in technology, medicine, economics, and even social sciences. Unfortunately, they are relatively rarely used in mining sciences and mining technology. The article is intended to convince the readers that neural networks can be very useful also in mining sciences. It contains information how modern neural networks are built, how they operate and how one can use them. The preliminary discussion presented in this paper can help the reader gain an opinion whether this is a tool with handy properties, useful for him, and what it might come in useful for. Of course, the brief introduction to neural networks contained in this paper will not be enough for the readers who get convinced by the arguments contained here, and want to use neural networks. They will still need a considerable portion of detailed knowledge so that they can begin to independently create and build such networks, and use them in practice. However, an interested reader who decides to try out the capabilities of neural networks will also find here links to references that will allow him to start exploration of neural networks fast, and then work with this handy tool efficiently. This will be easy, because there are currently quite a few ready-made computer programs, easily available, which allow their user to quickly and effortlessly create artificial neural networks, run them, train and use in practice. The key issue is the question how to use these networks in mining sciences. The fact that this is possible and desirable is shown by convincing examples included in the second part of this study. From the very rich literature on the various applications of neural networks, we have selected several works that show how and what neural networks are used in the mining industry, and what has been achieved thanks to their use. The review of applications will continue in the next article, filed already for publication in the journal \"Archives of Mining Sciences\". Only studying these two articles will provide sufficient knowledge for initial guidance in the area of issues under consideration here.","Authors":"Tadeusiewicz, R (Tadeusiewicz, Ryszard)","Title":"NEURAL NETWORKS IN MINING SCIENCES-GENERAL OVERVIEW AND SOME REPRESENTATIVE EXAMPLES"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000367591500037 ISBN:978-3-319-25159-2; 978-3-319-25158-5 ISSN: 0302-9743","Keywords":"Feature selection; Location intention; Query classification","Categories":"Computer Science; Robotics; Telecommunications Web of Science Categories:Computer Science, Artificial Intelligence; Robotics; Telecommunications","Journal Information":"KNOWLEDGE SCIENCE, ENGINEERING AND MANAGEMENT, KSEM 2015 Book Series: Lecture Notes in Artificial Intelligence Volume: 9403 Pages: 407-420 DOI: 10.1007/978-3-319-25159-2_37 Published: 2015","Abstract":"Much attention has been paid to web search personalization and query optimization over the past decade. With the prevalence of smart phones, the mobile search results for the same query may vary in regard to the user's location. In order to provide more precise results for users, it's essential to take geographic location into account along with the user's input query. In this paper, we try to identify queries that have location intentions. For example, query \"weather forecast\" has a location intention of local city while \"The Statue of Liberty\" has a location intention of \"New York city\". To identify the location intention behind a query, we propose a novel method to extract a set of features and use neural network to classify queries. In the classification of queries without explicit location names, our experiment shows that our approach achieves 82.5% at F1 measure and outperforms baselines by 4.2%.","Authors":"Sun, YF (Sun, Yifan) ; Li, X (Li, Xin) ; Li, L (Li, Lin) ; Liu, Q (Liu, Qi) ; Chen, EH (Chen, Enhong) ; Ma, HP (Ma, Haiping) Edited by:Zhang, S; Wirsing, M; Zhang, Z","Title":"Mining User's Location Intention from Mobile Search Log"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000366756600023 ISBN:978-3-319-25013-7 ISSN: 0302-9743","Keywords":"FLOSS learning processes; Learning activities in open source; Mining software repositories; Process mining; Semantic search","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods","Journal Information":"OPEN AND BIG DATA MANAGEMENT AND INNOVATION, I3E 2015 Book Series: Lecture Notes in Computer Science Volume: 9373 Pages: 287-298 DOI: 10.1007/978-3-319-25013-7_23 Published: 2015","Abstract":"Evidence suggests that Free/Libre Open Source Software (FLOSS) environments provide unlimited learning opportunities. Community members engage in a number of activities both during their interaction with their peers and while making use of these environments. As FLOSS repositories store data about participants' interaction and activities, we analyze participants' interaction and knowledge exchange in emails to trace learning activities that occur in distinct phases of the learning process. We make use of semantic search in SQL to retrieve data and build corresponding event logs which are then fed to a process mining tool in order to produce visual workflow nets. We view these nets as representative of the traces of learning activities in FLOSS as well as their relevant flow of occurrence. Additional statistical details are provided to contextualize and describe these models.","Authors":"Mukala, P (Mukala, Patrick) ; Cerone, A (Cerone, Antonio) ; Turini, F (Turini, Franco) Edited by:Janssen, M; Mantymaki, M; Hidders, J; Klievink, B; Lamersdorf, W; VanLoenen, B; Zuiderwijk, A","Title":"Mining Learning Processes from FLOSS Mailing Archives"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000364990400024 ISBN:978-3-319-19069-3; 978-3-319-19068-6 ISSN: 0302-9743","Keywords":"Business process mining; Trace clustering; Greedy algorithm; Business process extension KeyWords Plus:PROCESS MODELS","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods","Journal Information":"ADVANCED INFORMATION SYSTEMS ENGINEERING, CAISE 2015 Book Series: Lecture Notes in Computer Science Volume: 9097 Pages: 331-345 DOI: 10.1007/978-3-319-19069-3_21 Published: 2015","Abstract":"In the last years workflow discovery has become an important research topic in the business process mining area. However, existing workflow discovery techniques encounter challenges while dealing with event logs stemming from highly flexible environments because such logs contain many different behaviors. As a result, inaccurate and complex process models might be obtained. In this paper we propose a new technique which searches for the optimal way for clustering traces among all of the possible solutions. By applying the existing workflow discovery techniques on the traces for each discovered cluster by our method, more accurate and simpler sub-models can be obtained.","Authors":"Sun, YG (Sun, Yaguang) ; Bauer, B (Bauer, Bernhard) Edited by:Zdravkovic, J; Kirikova, M; Johannesson, P","Title":"A Novel Top-Down Approach for Clustering Traces"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000363764800016 ISBN:978-3-319-21042-1; 978-3-319-21041-4 ISSN: 0302-9743","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods","Journal Information":"WEB-AGE INFORMATION MANAGEMENT (WAIM 2015) Book Series: Lecture Notes in Computer Science Volume: 9098 Pages: 193-206 DOI: 10.1007/978-3-319-21042-1_16 Published: 2015","Abstract":"Using query logs to enhance user experience has been extensively studied in the Web IR literature. However, in the area of keyword search on structured data (relational databases in particular), most existing work has focused on improving search result quality through designing better scoring functions, without giving explicit consideration to query logs. Our work presented in this paper taps into the wealth of information contained in query logs, and aims to enhance the search effectiveness by explicitly taking into account the log information when ranking the query results. To concretize our discussion, we focus on schema-graph-based approaches to keyword search (using the seminal work DISCOVER as an example), which usually proceed in two stages, candidate network (CN) generation and CN evaluation. We propose a query-log-aware ranking strategy that uses the frequent patterns mined from query logs to help rank the CNs generated during the first stage. Given the frequent patterns, we show how to compute the maximal score of a CN using a dynamic programming algorithm. We prove that the problem of finding the maximal score is NP-hard. User studies on a real dataset validate the effectiveness of the proposed ranking strategy.","Authors":"Zhou, J (Zhou, Jing) ; Liu, Y (Liu, Yang) ; Yu, ZQ (Yu, Ziqiang) Edited by:Dong, XL; Yu, X; Li, J; Sun, Y","Title":"Improving the Effectiveness of Keyword Search in Databases Using Query Logs"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000363212500001 ISSN: 1024-123X eISSN: 1563-5147","Categories":"Engineering; Mathematics Web of Science Categories:Engineering, Multidisciplinary; Mathematics, Interdisciplinary Applications","Journal Information":"MATHEMATICAL PROBLEMS IN ENGINEERING Article Number: 985204 DOI: 10.1155/2015/985204 Published: 2015","Abstract":"For the search engine, error-input query is a common phenomenon. This paper uses web log as the training set for the query error checking. Through the n-gram language model that is trained by web log, the queries are analyzed and checked. Some features including query words and their number are introduced into the model. At the same time data smoothing algorithm is used to solve data sparseness problem. It will improve the overall accuracy of the n-gram model. The experimental results show that it is effective.","Authors":"Duan, JY (Duan, Jianyong) ; Mi, P (Mi, Peng) ; Liu, H (Liu, Hui) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Liu, Hui  http://orcid.org/0000-0003-1679-6560","Title":"Error Checking for Chinese Query by Mining Web Log"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000361702100024 ISBN:978-3-319-15934-8; 978-3-319-15933-1 ISSN: 0302-9743","Categories":"Computer Science Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Theory & Methods","Journal Information":"EVOLUTIONARY MULTI-CRITERION OPTIMIZATION, PT I Book Series: Lecture Notes in Computer Science Volume: 9018 Pages: 351-365 DOI: 10.1007/978-3-319-15934-8_24 Published: 2015","Abstract":"The interest in attribute-based access control policies is increasingly growing due to their ability to accommodate the complex security requirements of modern computer systems. With this novel paradigm, access control policies consist of attribute expressions which implicitly describe the properties of subjects and protection objects and which must be satisfied for a request to be allowed. Since specifying a policy in this framework may be very complex, approaches for policy mining, i.e., for inferring a specification automatically from examples in the form of logs of authorized and denied requests, have been recently proposed. In this work, we propose a multi-objective evolutionary approach for solving the policy mining task. We designed and implemented a problem representation suitable for evolutionary computation, along with several search-optimizing features which have proven to be highly useful in this context: a strategy for learning a policy by learning single rules, each one focused on a subset of requests; a custom initialization of the population; a scheme for diversity promotion and for early termination. We show that our approach deals successfully with case studies of realistic complexity.","Authors":"Medvet, E (Medvet, Eric) ; Bartoli, A (Bartoli, Alberto) ; Carminati, B (Carminati, Barbara) ; Ferrari, E (Ferrari, Elena) Edited by:GasparCunha, A; Antunes, CH; Coello, CC Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Medvet, Eric  http://orcid.org/0000-0001-5652-2113","Title":"Evolutionary Inference of Attribute-Based Access Control Policies"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000360172200043 ISBN:978-3-319-11312-8 ISSN: 2194-5357","Keywords":"process mining; cuckoo search; simulated annealing; tabu search; genetic algorithm KeyWords Plus:OPTIMIZATION; MODELS","Categories":"Computer Science; Robotics Web of Science Categories:Computer Science, Artificial Intelligence; Robotics","Journal Information":"INTELLIGENT SYSTEMS'2014, VOL 1: MATHEMATICAL FOUNDATIONS, THEORY, ANALYSES Book Series: Advances in Intelligent Systems and Computing Volume: 322 Pages: 487-498 DOI: 10.1007/978-3-319-11313-5_43 Published: 2015","Abstract":"In this paper, we analyze the impact of hybridization on the Cuckoo Search algorithm as applied in the context of business process mining. Thus, we propose six hybrid variants for the algorithm, as obtained by combining the Cuckoo Search algorithm with genetic, Simulated Annealing, and Tabu Search-based components. These components are integrated into the Cuckoo Search algorithm at the steps that correspond to generating the new business process models. The hybrid algorithm variants proposed have been comparatively evaluated on a set of event logs of different complexities. Our experimental results obtained have been compared with the ones as provided by the state of the art Genetic Miner algorithm.","Authors":"Chifu, VR (Chifu, Viorica R.) ; Pop, CB (Pop, Cristina Bianca) ; Salomie, I (Salomie, Ioan) ; Chifu, ES (Chifu, Emil St.) ; Rad, V (Rad, Victor) ; Antal, M (Antal, Marcel) Edited by:Angelov, P; Atanassov, KT; Doukovska, L; Hadjiski, M; Jotsov, V; Kacprzyk, J; Kasabov, N; Sotirov, S; Szmidt, E; Zadrozny, S","Title":"Hybrid Cuckoo Search-Based Algorithms for Business Process Mining"}, {"Keywords":"search engine advertising; ad keywords; query logs; knapsack problem; genetic algorithm KeyWords Plus:SUGGESTION","Categories":"Engineering Web of Science Categories:Engineering, Industrial; Engineering, Manufacturing","Journal Information":"INTERNATIONAL JOURNAL OF INDUSTRIAL ENGINEERING-THEORY APPLICATIONS AND PRACTICE Volume: 22 Issue: 1 Pages: 62-79 Published: 2015","Abstract":"Online advertisers who want their website to be shown in the web search pages need to bid for relevant keywords. Selecting such keywords in advertising is challenging because they need to find relevant keywords of different click volumes and costs. Recent works focused on merely generating a list of words by using semantic or statistical methodologies. However, limited previous studies do not guarantee that those keywords will be used by customers and subsequently provide large traffic volume with lower costs. In this study, we propose a novel approach of generating relevant keywords by combining search log mining and proximity-based approach. Subsequently the optimal set of keywords with a higher volume while minimizing costs was determined. Experiment results show that our method generate an optimal set of keywords that are not only accurate, but also attract more click volume with less cost.","Authors":"Hur, M (Hur, Minhoe) ; Han, S (Han, Songwon) ; Kim, H (Kim, Hongtae) ; Cho, S (Cho, Sungzoon)","Title":"SELECTING AN OPTIMAL SET OF KEYWORDS FOR SEARCH ENGINE ADVERTISING"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000358004600009 ISBN:978-1-62841-615-2 ISSN: 0277-786X","Keywords":"Topic periodicity; text data; time dependent topic modeling KeyWords Plus:TIME-SERIES DATABASES; ALGORITHM; PATTERNS","Categories":"Engineering; Optics Web of Science Categories:Engineering, Electrical & Electronic; Optics","Journal Information":"NEXT-GENERATION ANALYST III Book Series: Proceedings of SPIE Volume: 9499 Article Number: 94990A DOI: 10.1117/12.2180097 Published: 2015","Abstract":"Although history may not repeat itself, many human activities are inherently periodic, recurring daily, weekly, monthly, yearly or following some other periods. Such recurring activities may not repeat the same set of keywords, but they do share similar topics. Thus it is interesting to mine topic periodicity from text data instead of just looking at the temporal behavior of a single keyword/phrase. Some previous preliminary studies in this direction prespecify a periodic temporal template for each topic. In this paper, we remove this restriction and propose a simple yet effective framework Torpedo to mine periodic/recurrent patterns from text, such as news articles, search query logs, research papers, and web blogs. We first transform text data into topic-specific time series by a time dependent topic modeling module, where each of the time series characterizes the temporal behavior of a topic. Then we use time series techniques to detect periodicity. Hence we both obtain a clear view of how topics distribute over time and enable the automatic discovery of periods that are inherent in each topic. Theoretical and experimental analyses demonstrate the advantage of Torpedo over existing work.","Authors":"Wang, JJ (Wang, Jingjing) ; Deng, HB (Deng, Hongbo) ; Han, JW (Han, Jiawei) Edited by:Broome, BD; Hanratty, TP; Hall, DL; Llinas, J","Title":"Torpedo: Topic Periodicity Discovery from Text Data"}, {"Document Information":"Document Type:Proceedings Paper Language:English Accession Number: WOS:000347779500004 ISBN:978-3-319-11932-8 ISSN: 2194-5357","Keywords":"Query groups; user search sessions; search goals; click sequence KeyWords Plus:LOGS","Categories":"Computer Science; Robotics Web of Science Categories:Computer Science, Artificial Intelligence; Robotics","Journal Information":"PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON FRONTIERS OF INTELLIGENT COMPUTING: THEORY AND APPLICATIONS (FICTA) 2014, VOL 1 Book Series: Advances in Intelligent Systems and Computing Volume: 327 Pages: 27-36 DOI: 10.1007/978-3-319-11933-5_4 Published: 2015","Abstract":"Now a day's web mining is very important area. When user issues a query on the search engine, it gives relevant and irrelevant information to the user. If the query issued by the user is ambiguous then different users may get different search results and they have different search goals. The analysis of user search results according to their user goals can be very useful in improving search engine experience, usage and relevance. In this paper, we propose to infer user search goals by clustering the proposed user search sessions. User search sessions are constructed from user search logs and these can efficiently reflects the information needed by the users. An Online Clustering algorithm is used for clustering the pseudo documents, and then we use another appoarch to generate pseudo documents for better representation of the user search sessions for clustering. Finally we are using Classified Average Precision to evaluate the performance of inferring user search goals.","Authors":"Pavani, M (Pavani, M.) ; Teja, GR (Teja, G. Ravi) Edited by:Satapathy, SC; Biswal, BN; Udgata, SK; Mandal, JK","Title":"Online Clustering Algorithm for Restructuring User Web Search Results"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000345688500009 ISSN: 1742-2876 eISSN: 1873-202X","Keywords":"Text mining; Chat logs mining; Digital forensics; Social graph generation; Cyber crime investigation KeyWords Plus:COMPUTER-MEDIATED COMMUNICATION; CLASSIFICATION","Categories":"Computer Science Web of Science Categories:Computer Science, Information Systems; Computer Science, Interdisciplinary Applications","Journal Information":"DIGITAL INVESTIGATION Volume: 11 Issue: 4 Pages: 349-362 DOI: 10.1016/j.diin.2014.10.001 Published: DEC 2014","Abstract":"This paper presents a unified social graph based text mining framework to identify digital evidences from chat logs data. It considers both users' conversation and interaction data in group-chats to discover overlapping users' interests and their social ties. The proposed framework applies n-gram technique in association with a self-customized hyperlink-induced topic search (HITS) algorithm to identify key-terms representing users' interests, key-users, and key-sessions. We propose a social graph generation technique to model users' interactions, where ties (edges) between a pair of users (nodes) are established only if they participate in at least one common group-chat session, and weights are assigned to the ties based on the degree of overlap in users' interests and interactions. Finally, we present three possible cyber-crime investigation scenarios and a user-group identification method for each of them. We present our experimental results on a data set comprising 1100 chat logs of 11,143 chat sessions continued over a period of 29 months from January 2010 to May 2012. Experimental results suggest that the proposed framework is able to identify key-terms, key-users, key-sessions, and user-groups from chat logs data, all of which are crucial for cyber-crime investigation. Though the chat logs are recovered from a single computer, it is very likely that the logs are collected from multiple computers in real scenario. In this case, logs collected from multiple computers can be combined together to generate more enriched social graph. However, our experiments show that the objectives can be achieved even with logs recovered from a single computer by using group-chats data to draw relationships between every pair of users. (C) 2014 Elsevier Ltd. All rights reserved.","Authors":"Anwar, T (Anwar, Tarique) ; Abulaish, M (Abulaish, Muhammad)","Title":"A social graph based text mining framework for chat log investigation"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000344993900018 ISSN: 1041-4347 eISSN: 1558-2191","Keywords":"Search log mining; task trail; task evaluation; log analysis KeyWords Plus:WEB SEARCH","Categories":"Computer Science; Engineering Web of Science Categories:Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic","Journal Information":"IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING Volume: 26 Issue: 12 Pages: 3090-3102 DOI: 10.1109/TKDE.2014.2316794 Published: DEC 2014","Abstract":"In this paper, we introduce \"task trail\" to understand user search behaviors. We define a task to be an atomic user information need, whereas a task trail represents all user activities within that particular task, such as query reformulations, URL clicks. Previously, web search logs have been studied mainly at session or query level where users may submit several queries within one task and handle several tasks within one session. Although previous studies have addressed the problem of task identification, little is known about the advantage of using task over session or query for search applications. In this paper, we conduct extensive analyses and comparisons to evaluate the effectiveness of task trails in several search applications: determining user satisfaction, predicting user search interests, and suggesting related queries. Experiments on large scale data sets of a commercial search engine show that: (1) Task trail performs better than session and query trails in determining user satisfaction; (2) Task trail increases webpage utilities of end users comparing to session and query trails; (3) Task trails are comparable to query trails but more sensitive than session trails in measuring different ranking functions; (4) Query terms from the same task are more topically consistent to each other than query terms from different tasks; (5) Query suggestion based on task trail is a good complement of query suggestions based on session trail and click-through bipartite. The findings in this paper verify the need of extracting task trails from web search logs and enhance applications in search and recommendation systems.","Authors":"Liao, Z (Liao, Zhen) ; Song, Y (Song, Yang) ; Huang, Y (Huang, Yalou) ; He, LW (He, Li-Wei) ; He, Q (He, Qi)","Title":"Task Trail: An Effective Segmentation of User Search Behavior"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000340689700028 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Business process management; Process mining; Event log merging; Inter-organizational process modeling KeyWords Plus:INFORMATION-SYSTEMS RESEARCH; BUSINESS PROCESSES; DESIGN SCIENCE; WORKFLOW; PERSPECTIVE; MODELS","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 41 Issue: 16 Pages: 7291-7306 DOI: 10.1016/j.eswa.2014.06.012 Published: NOV 15 2014","Abstract":"In an inter-organizational setting the manual construction of process models is challenging because the different people involved have to put together their partial knowledge about the overall process. Process mining, an automated technique to discover and analyze process models, can facilitate the construction of inter-organizational process models. This paper presents a technique to merge the input data of the different partners of an inter-organizational process in order to serve as input for process mining algorithms. The technique consists of a method for configuring and executing the merge and an algorithm that searches for links between the data of the different partners and that suggests rules to the user on how to merge the data. Tool support is provided in the open source process mining framework ProM. The method and the algorithm are tested using two artificial and three real life datasets that confirm their effectiveness and efficiency. (C) 2014 Elsevier Ltd. All rights reserved.","Authors":"Claes, J (Claes, Jan) ; Poels, G (Poels, Geert) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Poels, Geert  D-1130-2013 http://orcid.org/0000-0001-9247-6150 Claes, Jan  A-8283-2010 http://orcid.org/0000-0001-7236-4952","Title":"Merging event logs for process mining: A rule based merging method and rule suggestion algorithm"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000340689700042 ISSN: 0957-4174 eISSN: 1873-6793","Keywords":"Social network mining; Ranking algorithm; Tag expansion and prediction; SPTF","Categories":"Computer Science; Engineering; Operations Research & Management Science Web of Science Categories:Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science","Journal Information":"EXPERT SYSTEMS WITH APPLICATIONS Volume: 41 Issue: 16 Pages: 7455-7465 DOI: 10.1016/j.eswa.2014.05.050 Published: NOV 15 2014","Abstract":"With the development of social networks, more and more users have a great need to search for people to follow (SPTF) to receive their tweets. According to our experiments, approximately 50% of social networks' lost users leave due to a lack of people to follow. In this paper, we define the problem of SPTF and propose an approach to give users tags and then deliver a ranked list of valuable accounts for them to follow. In the proposed approach, we first seek accounts related to keywords via expanding and predicting tags for users. Second, we propose two algorithms to rank relevant accounts: the first mines the forwarded relationship, and the second incorporates the following relationship into PageRank. Accordingly, we have built a search system(1) that to date, has received more than 1.7 million queries from 0.2 million users. To evaluate the proposed approach, we created a crowd-sourcing organization and crawled 0.25 billion profiles, 15 billion messages and 20 billion links representing following relationships on Sina Microblog. The empirical study validates the effectiveness of our algorithms for expanding and predicting tags compared to the baseline. From query logs, we discover that hot queries include keywords related to academics, occupations and companies. Experiments on those queries show that PageRank-like algorithms perform best for occupation-related queries, forward-relationship-like algorithms work best for academic-related queries and domain-related headcount algorithms work best for company-related queries. (C) 2014 Elsevier Ltd. All rights reserved.","Authors":"Liang, B (Liang, Bin) ; Liu, YQ (Liu, Yiqun) ; Zhang, M (Zhang, Min) ; Ma, SP (Ma, Shaoping) ; Ru, LY (Ru, Liyun) ; Zhang, K (Zhang, Kuo)","Title":"Searching for people to follow in social networks"}, {"Document Information":"Document Type:Article Language:English Accession Number: WOS:000344615300005 PubMed ID: 25151493 ISSN: 0114-5916 eISSN: 1179-1942","Categories":"Public, Environmental & Occupational Health; Pharmacology & Pharmacy; Toxicology Web of Science Categories:Public, Environmental & Occupational Health; Pharmacology & Pharmacy; Toxicology","Journal Information":"DRUG SAFETY Volume: 37 Issue: 10 Pages: 777-790 DOI: 10.1007/s40264-014-0218-z Published: OCT 2014","Abstract":"Text mining is the computational process of extracting meaningful information from large amounts of unstructured text. It is emerging as a tool to leverage underutilized data sources that can improve pharmacovigilance, including the objective of adverse drug event (ADE) detection and assessment. This article provides an overview of recent advances in pharmacovigilance driven by the application of text mining, and discusses several data sources-such as biomedical literature, clinical narratives, product labeling, social media, and Web search logs-that are amenable to text mining for pharmacovigilance. Given the state of the art, it appears text mining can be applied to extract useful ADE-related information from multiple textual sources. Nonetheless, further research is required to address remaining technical challenges associated with the text mining methodologies, and to conclusively determine the relative contribution of each textual source to improving pharmacovigilance.","Authors":"Harpaz, R (Harpaz, Rave) ; Callahan, A (Callahan, Alison) ; Tamang, S (Tamang, Suzanne) ; Low, Y (Low, Yen) ; Odgers, D (Odgers, David) ; Finlayson, S (Finlayson, Sam) ; Jung, K (Jung, Kenneth) ; LePendu, P (LePendu, Paea) ; Shah, NH (Shah, Nigam H.) Hide ResearcherID and ORCIDView ResearcherID and ORCID Author ResearcherID ORCID Number Callahan, Alison  http://orcid.org/0000-0001-5163-380X","Title":"Text Mining for Adverse Drug Events: the Promise, Challenges, and State of the Art"}]